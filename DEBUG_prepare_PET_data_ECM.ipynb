{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas\n",
    "import math\n",
    "from nilearn import image, input_data\n",
    "from copy import deepcopy\n",
    "import nibabel as ni\n",
    "import scipy.stats as stats\n",
    "from scipy.io import savemat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "from sklearn.feature_extraction.image import grid_to_graph\n",
    "import statsmodels.distributions.empirical_distribution as ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_PET_data(files_in, atlas, ref = None, msk = None, dimension_reduction = False,\n",
    "                     ECDF_in = None, output_type = 'py', out_dir = './', out_name = 'PET_data', \n",
    "                     save_matrix = False, save_ECDF = False, save_images = False, ref_index = [],\n",
    "                    voxyreg = False):\n",
    "    ''' This is a function that will take several PET images and an atlas and will\n",
    "    return a subject X region matrix. If specified, the function will also calculate \n",
    "    probabilities (via ECDF) either voxelwise, or using a specified reference region\n",
    "    \n",
    "    files_in = input can either be \n",
    "        - a path to a directory full of (only) nifti images OR\n",
    "        - a \"search string\" using wildcards\n",
    "        - a list of subject paths OR\n",
    "        - a subject X image matrix\n",
    "        \n",
    "    altas = a path to a labeled regional atlas in the same space as the PET data\n",
    "    \n",
    "    ref = multiple options:\n",
    "        - If None, no probabilities will be calculated, and script will simply extract\n",
    "        regional PET data using the atlas.\n",
    "        - If a path to a reference region mask (MUST BE BINARY), will calculate voxelwise \n",
    "        probabilities based on values within the reference region. Mask must be in the same \n",
    "        space as PET data and atlas\n",
    "        - If a path to an atlas image (between 3 and 1002 distinct values), will calucalte\n",
    "        region-wise probabilities for each region in the atlas.\n",
    "        - If a list of integers, will combine these atlas labels with these integers to \n",
    "        make reference region out of input of atlas argument\n",
    "        - if 'voxelwise', voxelwise (or atom-wise from dimension reduction) probabilities\n",
    "        will be estimated. In other words, each voxel or atom will use serve as its own\n",
    "        reference. Also, see ref_index argument.\n",
    "        \n",
    "    msk = A path to a binary mask file in the same space as PET data and atlas. If None,\n",
    "        mask will be computed as a binary mask of the atlas.\n",
    "        ** PLEASE NOTE: The mask will be used to mask the reference region! **\n",
    "    \n",
    "    dimension_reduction = whether or not to first reduce dimensions of data using\n",
    "    hierarchical clustering. This results in an initial step that will be very slow, but \n",
    "    will may result in an overall speedup for the script, but perhaps only if ref is set \n",
    "    to 'voxelwise'.\n",
    "        - If None, do not perform dimension reduction\n",
    "        - If integer, the number of atoms (clusters) to reduce to\n",
    "    \n",
    "    ECDF_in = If the user wishes to apply an existing ECDF to the PET data instead of\n",
    "        generating one de novo, that can be done here. This crucial if the user wishes to\n",
    "        use multiple datasets. Think of it like scaling in machine learning.\n",
    "        - If None, will generate ECDF de novo.\n",
    "        - If np.array, will use this array to generate the ECDF.\n",
    "        - If statsmodel ECDF object, will use this as ECDF\n",
    "        - If a path, will use the\n",
    "    \n",
    "    output_type = type of file to save final subject x region matrix into. multiple options:\n",
    "        -- 'py' will save matrix into a csv\n",
    "        -- 'mat' will save matrix into a matfile\n",
    "    \n",
    "    out_dir = location to save output files. Defaults to current directory\n",
    "    \n",
    "    out_name = the prefix for all output files\n",
    "    \n",
    "    save_matrix = Whether to save or return subject x image matrix. Useful if running multiple \n",
    "        times, as this matrix can be set as files_in, bypassing the costly data import\n",
    "        -- if 'return', will return subject x image matrix to python environment\n",
    "        -- if 'save', will write subject x image matrix to file. \n",
    "        -- if None, matrix will not be stored\n",
    "    \n",
    "    save_ECDF = whether to save the ECDF used to create the probabilities. This is crucial if \n",
    "        using multiple datasets. The resulting output can be used as input for the ECDF argument.\n",
    "        -- if 'return, will return np.array to python environment\n",
    "        -- if 'save', will write array to file\n",
    "        -- if None, array will not be stored\n",
    "    \n",
    "    save_images = whether to save PET probability (output) images. If True, data will be written\n",
    "        to a 4D nifti file, specified by out_dir and out_name\n",
    "    \n",
    "    ref_index = whether to use a subset of input data as a reference group to use to create the\n",
    "        ECDF, which will subsequently be applied to all subject data. \n",
    "        -- Input should be a list of indices corresponding to the order of the subjects in files_in. \n",
    "        For instance, if you have 6 subjects and want to use the 2nd and 4th as reference, \n",
    "        input would be [1,3]. \n",
    "        -- Passing an empty list will skip this and use the whole sample for the ECDF.\n",
    "        * NOTE * this argument will only have an effect if ref is set to voxelwise.\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    # Check input arguments\n",
    "    print('initiating...')\n",
    "\n",
    "    if output_type != 'py' and output_type != 'mat':\n",
    "        raise IOError('output_type must be set to py or mat')\n",
    "    \n",
    "    if not os.path.isdir(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    \n",
    "    # Load data\n",
    "    print('loading data...')\n",
    "    i4d = load_data(files_in) # load PET data\n",
    "    if save_matrix == 'save':\n",
    "        otpt = os.path.join(out_dir,'%s_4d_data'%out_name)\n",
    "        print('saving 4d subject x scan to nifti image: \\n',otpt)\n",
    "        i4d.to_filename(otpt)\n",
    "    \n",
    "    # load atlas\n",
    "    atlas = ni.load(atlas).get_data().astype(int) \n",
    "    if atlas.shape != i4d.shape[:3]:\n",
    "        raise ValueError('atlas dimensions do not match PET data dimensions')\n",
    "    \n",
    "    # load reference region\n",
    "    regionwise = False\n",
    "    if type(ref) == str and ref != 'voxelwise': \n",
    "        print('looking for reference image...')\n",
    "        if not os.path.isfile(ref):\n",
    "            raise IOError('Please enter a valid path for ref, or select a different option for this argument')\n",
    "        else:\n",
    "            ref_msk = ni.load(ref).get_data()\n",
    "            if ref_msk.shape != i4d.shape[:3]:\n",
    "                raise ValueError('ref region image dimensions do not match PET data dimensions')\n",
    "            ref_uvals = len(np.unique(ref_msk))\n",
    "            if ref_uvals > 2 and ref_uvals < 1003:\n",
    "                print('found reference atlas. Using for region-wise probability calculation')\n",
    "                regionwise = True\n",
    "            elif ref_uvals < 2 or ref_uvals > 1002:\n",
    "                raise ValueError(\n",
    "                        'reference image is either empty or has too many unique values for an atlas.')\n",
    "            else:\n",
    "                print('found binary reference region mask. Using for probability calculation')\n",
    "                \n",
    "    elif type(ref) == list:\n",
    "        ref_msk = np.zeros_like(atlas)\n",
    "        for i in ref:\n",
    "            ref_msk[atlas == i] = 1\n",
    "    else:\n",
    "        ref_msk = None\n",
    "    \n",
    "    \n",
    "    # Mask data\n",
    "    print('masking data...')\n",
    "    if msk == None:\n",
    "        img_mask = deepcopy(atlas)\n",
    "        img_mask[img_mask<1] = 0\n",
    "        img_mask[img_mask>0] = 1\n",
    "    else:\n",
    "        img_mask = ni.load(msk).get_data()\n",
    "        atlas[img_mask < 1] = 0\n",
    "    \n",
    "    if type(ref_msk) != type(None):\n",
    "        ref_msk[img_mask < 1] = 0\n",
    "    \n",
    "    mask_tfm = input_data.NiftiMasker(ni.Nifti1Image(img_mask,i4d.affine))\n",
    "    mi4d = mask_tfm.fit_transform(i4d)\n",
    "    \n",
    "    # dimension reduction (IN BETA!)\n",
    "    if dimension_reduction:\n",
    "        print('reducing dimensions...')\n",
    "        dm_mask = mask_tfm.mask_img_.get_data().astype(bool)\n",
    "        shape = dm_mask.shape\n",
    "        connectivity = grid_to_graph(n_x=shape[0], n_y=shape[1],\n",
    "                                   n_z=shape[2], mask=dm_mask)\n",
    "        mi4d, labels, ward = dim_reduction(mi4d, connectivity, dimension_reduction)\n",
    "        labels_img = mask_tfm.inverse_transform(labels)\n",
    "        \n",
    "    # main ECDF calculation\n",
    "    skip = False\n",
    "    if ref != 'voxelwise':\n",
    "        if type(ECDF_in) != type(None): \n",
    "            print('generating ECDF...')\n",
    "            print('using user-supplied data...')\n",
    "            if type(ECDF_in) == ed.ECDF:\n",
    "                mi4d_ecdf, ecref = ecdf_simple(mi4d, ECDF_in)\n",
    "                input_distribution = 'not generated'\n",
    "            elif type(ECDF_in) == np.ndarray:\n",
    "                mi4d_ecdf, ecref = ecdf_simple(mi4d, ECDF_in)\n",
    "                input_distribution = ECDF_in\n",
    "            elif type(ECDF_in) == str:\n",
    "                if not os.path.isfile(ECDF_in):\n",
    "                    raise ValueError('input for ECDF_in is not a valid path')\n",
    "                if '.npy' not in ECDF_in:\n",
    "                    raise ValueError('this function currently only accepts .npy files as inputs for ECDF_in')\n",
    "                input_distribution = np.load(ECDF_in)\n",
    "                mi4d_ecdf, ecref = ecdf_simple(mi4d, input_distribution)\n",
    "                \n",
    "            else:\n",
    "                try:\n",
    "                    mi4d_ecdf, ecref = ecdf_simple(mi4d, ECDF_in)\n",
    "                    print('Could not understand ECDF input, but ECDF successful')\n",
    "                    input_distribution = 'not generated'\n",
    "                except:\n",
    "                    raise IOError(\n",
    "                            'Invalid argument for ECDF in. Please enter an ndarray, an ECDF object, or a valid path')\n",
    "        else:\n",
    "            if type(ref_msk) != type(None):\n",
    "                if not regionwise:\n",
    "                    print('generating ECDF...')\n",
    "                    ref_tfm = input_data.NiftiMasker(ni.Nifti1Image(ref_msk,i4d.affine))\n",
    "                    refz = ref_tfm.fit_transform(i4d)\n",
    "                    mi4d_ecdf, ecref = ecdf_simple(mi4d, refz)\n",
    "                    input_distribution = refz.flat\n",
    "                else:\n",
    "                    print('generating region-wise ECDF...')\n",
    "                    if not voxyreg:\n",
    "                        reg_mat = generate_matrix_from_atlas(i4d, ref_msk)\n",
    "                        mi4d_ecdf, ECDF_array = ecdf_voxelwise(np.array(reg_mat),ref_index, save_ECDF)\n",
    "                        f_mat = pandas.DataFrame(mi4d_ecdf,\n",
    "                                                 columns = ['roi_%s'%x for x in np.unique(ref_msk.astype(int))[1:]]\n",
    "                                                )\n",
    "                        input_distribution = 'not_generated'\n",
    "                    else:\n",
    "                        # FIX THIS UP\n",
    "                        f_images = ecdf_regionwise(i4d, ref_index, save_ECDF, ref_msk)\n",
    "                        ECDF_array = None\n",
    "                        input_distribution = 'not_generated'\n",
    "            else:\n",
    "                print('skipping ECDF...')\n",
    "                skip = True\n",
    "    \n",
    "    else:\n",
    "        print('generating voxelwise ECDF...')\n",
    "        mi4d_ecdf, ECDF_array = ecdf_voxelwise(mi4d, ref_index, save_ECDF)\n",
    "        input_distribution = 'not generated'\n",
    "        \n",
    "    if not skip:\n",
    "        if save_ECDF:\n",
    "            if type(input_distribution) == np.ndarray:\n",
    "                flnm = os.path.join(out_dir, '%s_input_distribution'%out_name)\n",
    "                print('saving ECDF to',flnm)\n",
    "                np.save(flnm, input_distribution)\n",
    "            else:\n",
    "                print('Due to the arguments passed, ECDF array was not generated and therefore cannot be saved')\n",
    "        \n",
    "        # transform back to image-space\n",
    "        if not regionwise and not dimension_reduction:\n",
    "            print('transforming back into image space')\n",
    "            f_images = mask_tfm.inverse_transform(mi4d_ecdf)\n",
    "        elif dimension_reduction:\n",
    "            print('transforming back into image space')\n",
    "            labels_img = mask_tfm.inverse_transform(labels)\n",
    "            tfmd = ward.inverse_transform(mi4d_ecdf)\n",
    "            f_images = mask_tfm.inverse_transform(tfmd)\n",
    "            #nimgs = rebuild_image_from_atlas(i4d.get_data)\n",
    "    else:\n",
    "        print('transforming back into image space')\n",
    "        f_images = mask_tfm.inverse_transform(mi4d)\n",
    "    \n",
    "    if voxyreg:\n",
    "        regionwise = False\n",
    "    \n",
    "    if save_images:\n",
    "        if regionwise:\n",
    "                print('transforming back into image space')\n",
    "                nimgs = rebuild_image_from_atlas(i4d.get_data(), ref_msk, f_mat)\n",
    "                f_images = ni.Nifti1Image(nimgs, i4d.affine)\n",
    "                flnm = os.path.join(out_dir, '%s_4D_probability_data'%out_name)\n",
    "                print('saving 4D probability image to', flnm)\n",
    "                f_images.to_filename(flnm)\n",
    "        else:\n",
    "            flnm = os.path.join(out_dir, '%s_4D_probability_data'%out_name)\n",
    "            print('saving 4D probability image to', flnm)\n",
    "            f_images.to_filename(flnm)\n",
    "    \n",
    "    # generate output matrix\n",
    "    \n",
    "    print('generating final subject x region matrix')\n",
    "    if not regionwise:\n",
    "        f_mat = generate_matrix_from_atlas(f_images, atlas)\n",
    "    \n",
    "    # compile (and save) outputs\n",
    "    print('preparing outputs')\n",
    "    output = {}\n",
    "    if output_type == 'py':\n",
    "        f_mat.to_csv(os.path.join(out_dir, '%s_roi_data.csv'%out_name))\n",
    "        output.update({'roi_matrix': f_mat})\n",
    "    else:\n",
    "        output.update({'roi_matrix': fmat.values})\n",
    "        output.update({'roi_matrix_columns': fmat.columns})\n",
    "    if save_matrix == 'return':\n",
    "        output.update({'4d_image_matrix': i4d})\n",
    "    if save_ECDF == 'return':\n",
    "        if output_type == 'py':\n",
    "            output.update({'ECDF_function': ECDF_array})\n",
    "        else:\n",
    "            output.update({'input_distribution': input_distribution})\n",
    "    \n",
    "    if output_type == 'py':\n",
    "        return output\n",
    "    else:\n",
    "        savemat(os.path.join(out_dir,'%s_output'%out_name), output)\n",
    "        return None\n",
    "        \n",
    "    \n",
    "def load_data(files_in):\n",
    "    \n",
    "    fail = False\n",
    "    \n",
    "    if type(files_in) == str:\n",
    "        if os.path.isdir(files_in):\n",
    "            print('It seems you passed a directory')\n",
    "            search = os.path.join(files_in,'*')\n",
    "            num_f = len(glob(search))\n",
    "            if num_f == 0:\n",
    "                raise IOError('specified directory did not contain any files')\n",
    "            else:\n",
    "                print('found %s images!'%num_f)\n",
    "            i4d = image.load_img(search)\n",
    "        elif '*' in files_in:\n",
    "            print('It seems you passed a search string')\n",
    "            num_f = len(glob(files_in))\n",
    "            if num_f == 0:\n",
    "                raise IOError('specified search string did not result in any files')\n",
    "            else:\n",
    "                print('found %s images'%num_f)\n",
    "            i4d = image.load_img(files_in)\n",
    "        else:\n",
    "            fail = True\n",
    "    elif type(files_in) == list:\n",
    "        print('processing %s subjects'%len(files_in))\n",
    "        i4d = ni.concat_images(files_in)\n",
    "    elif type(files_in) == ni.nifti1.Nifti1Image:\n",
    "        print('processing %s subjects'%files_in.shape[-1])\n",
    "        i4d = files_in\n",
    "    else:\n",
    "        fail = True\n",
    "        \n",
    "    if fail:\n",
    "        print('files_in not recognized.', \n",
    "                    'Please enter a search string, valid directory, list of subjects, or matrix')\n",
    "        raise ValueError('I do not recognize the files_in input.')\n",
    "    \n",
    "    return i4d\n",
    "\n",
    "def dim_reduction(mi4d, connectivity, dimension_reduction):\n",
    "    ward = FeatureAgglomeration(n_clusters=int(dimension_reduction/2),\n",
    "            connectivity=connectivity, linkage='ward', memory='nilearn_cache')\n",
    "    ward.fit(mi4d)\n",
    "    ward = FeatureAgglomeration(n_clusters=dimension_reduction,\n",
    "            connectivity=connectivity, linkage='ward', memory='nilearn_cache')\n",
    "    ward.fit(mi4d)                                                         \n",
    "    mi4d = ward.transform(mi4d)\n",
    "    labels = ward.labels_ + 1\n",
    "    \n",
    "    return mi4d, labels, ward\n",
    "\n",
    "def ecdf_simple(mi4d, refz):\n",
    "\n",
    "    if type(refz) == ed.ECDF:\n",
    "        ecref = refz\n",
    "    else:\n",
    "        if len(refz.shape) > 1:\n",
    "            ecref = ed.ECDF(refz.flat)\n",
    "        else:\n",
    "            ecref = ed.ECDF(refz)\n",
    "    print('transforming images...')\n",
    "    mi4d_ecdf = ecref(mi4d.flat).reshape(mi4d.shape[0],mi4d.shape[1])\n",
    "\n",
    "    return mi4d_ecdf, ecref   \n",
    "\n",
    "def ecdf_voxelwise(mi4d, ref_index, save_ECDF):\n",
    "    \n",
    "    X,y = mi4d.shape\n",
    "\n",
    "    if len(ref_index) == 0:\n",
    "        if not save_ECDF:\n",
    "            jnk = np.array([ed.ECDF(mi4d[:,x])(mi4d[:,x]) for x in range(y)])\n",
    "            mi4d_ecdf = np.zeros_like(mi4d)\n",
    "            for x in range(y):\n",
    "                mi4d_ecdf[:,x] = jnk[x]\n",
    "            ECDF_array = None\n",
    "        else:\n",
    "            ECDF_array = [ed.ECDF(mi4d[:,x]) for x in range(y)]\n",
    "            print('transforming data...')\n",
    "            jnk = np.array([ECDF_array[x](mi4d[:,x]) for x in range(y)])\n",
    "            mi4d_ecdf = np.zeros_like(mi4d)\n",
    "            for x in range(y):\n",
    "                mi4d_ecdf[:,x] = jnk[x]\n",
    "            \n",
    "    else:\n",
    "        good_ind = [x for x in list(range(X)) if x not in ref_index]\n",
    "        if not save_ECDF:    \n",
    "            jnk = np.array([ed.ECDF(mi4d[ref_index,x])(mi4d[:,x]) for x in range(y)])\n",
    "            mi4d_ecdf = np.zeros_like(mi4d)\n",
    "            for x in range(y):\n",
    "                mi4d_ecdf[:,x] = jnk[x]\n",
    "            ECDF_array = None\n",
    "        else:\n",
    "            ECDF_array = [ed.ECDF(mi4d[ref_index,x]) for x in range(y)]\n",
    "            print('transforming data...')\n",
    "            jnk = ecdf_voxelwise = np.array([ECDF_array[x](mi4d[:,x]) for x in range(y)]\n",
    "                                     )\n",
    "            mi4d_ecdf = np.zeros_like(mi4d)\n",
    "            for x in range(y):\n",
    "                mi4d_ecdf[:,x] = jnk[x]\n",
    "    \n",
    "    return mi4d_ecdf, ECDF_array\n",
    "\n",
    "def ecdf_regionwise(i4d, ref_index, save_ECDF, atlas):\n",
    "    \n",
    "    i4d_ecdf = np.zeros_like(i4d.get_data())\n",
    "    for i in np.unique(atlas)[1:]:\n",
    "        print('working on region',i)\n",
    "        msk = deepcopy(atlas)\n",
    "        msk[atlas==i] = 1\n",
    "        msk[msk!=1] = 0\n",
    "        roi_tfm = input_data.NiftiMasker(ni.Nifti1Image(msk,i4d.affine))\n",
    "        roi = roi_tfm.fit_transform(i4d)\n",
    "        X,y = roi.shape\n",
    "        rdist = ed.ECDF(roi.flat)\n",
    "        roi_ecdf = np.array([rdist(roi[:,x]) for x in range(y)]).reshape(X,y)\n",
    "        vals = roi_tfm.inverse_transform(roi_ecdf)\n",
    "        i4d_ecdf += vals.get_data()\n",
    "    \n",
    "    i4d_ecdf = ni.Nifti1Image(i4d_ecdf,i4d.affine)\n",
    "        \n",
    "    return i4d_ecdf\n",
    "\n",
    "def generate_matrix_from_atlas(files_in, atlas):\n",
    "    \n",
    "    files_in = np.nan_to_num(files_in.get_data())\n",
    "    atlas = atlas.astype(int)\n",
    "    uni = np.unique(atlas)\n",
    "    atl_map = dict(zip(uni,range(len(uni))))\n",
    "    new_atl = deepcopy(atlas)\n",
    "    for old,new in atl_map.items():\n",
    "        new_atl[atlas==old] = new\n",
    "    \n",
    "    f_mat = pandas.DataFrame(index = range(files_in.shape[-1]),\n",
    "                             columns = ['roi_%s'%x for x in np.unique(atlas) if x != 0])\n",
    "    tot = np.bincount(new_atl.flat)\n",
    "    for sub in range(files_in.shape[-1]):\n",
    "        mtx = files_in[:,:,:,sub]\n",
    "        sums = np.bincount(new_atl.flat, weights = mtx.flat)\n",
    "        rois = (sums/tot)[1:]\n",
    "        f_mat.loc[f_mat.index[sub]] = rois\n",
    "    \n",
    "    \n",
    "    return f_mat\n",
    "\n",
    "def rebuild_image_from_atlas(files_in, atlas, map_mtx):\n",
    "    \n",
    "    for i in range(files_in.shape[-1]):\n",
    "        xs = files_in[:,:,:,i]\n",
    "        for col in map_mtx.columns:\n",
    "            num = int(col.split('_')[-1])\n",
    "            xs[atlas == num] = map_mtx.loc[map_mtx.index[i]][col]\n",
    "            xs[atlas == 0] = 0\n",
    "    \n",
    "    return files_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subs = sorted(glob('/Users/jakevogel/Science/tau/nan_snorm_*'))\n",
    "files_in = subs[:5]\n",
    "atlas = '/Users/jakevogel/Science/tau/dkt_nocereb_1mm.nii.gz'\n",
    "ref = 'voxelwise'\n",
    "msk = '/Users/jakevogel/Science/tau/ADNI_GM_mask_1mm_nocereb.nii.gz'\n",
    "dimension_reduction = False\n",
    "ECDF_in = None\n",
    "output_type = 'py'\n",
    "out_dir = '/Users/jakevogel/Science/tau/ESM_tau/'\n",
    "out_name = 'small_trial'\n",
    "save_matrix = False\n",
    "save_ECDF = False\n",
    "save_images = False\n",
    "ref_index = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "processing 5 subjects\n",
      "masking data...\n"
     ]
    }
   ],
   "source": [
    "if output_type != 'py' and output_type != 'mat':\n",
    "    raise IOError('output_type must be set to py or mat')\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "\n",
    "# Load data\n",
    "print('loading data...')\n",
    "i4d = load_data(files_in) # load PET data\n",
    "if save_matrix == 'save':\n",
    "    otpt = os.path.join(out_dir,'%s_4d_data'%out_name)\n",
    "    print('saving 4d subject x scan to nifti image: \\n',otpt)\n",
    "    i4d.to_filename(otpt)\n",
    "\n",
    "# load atlas\n",
    "atlas = ni.load(atlas).get_data().astype(int) \n",
    "if atlas.shape != i4d.shape[:3]:\n",
    "    raise ValueError('atlas dimensions do not match PET data dimensions')\n",
    "\n",
    "# load reference region\n",
    "regionwise = False\n",
    "if type(ref) == str and ref != 'voxelwise': \n",
    "    print('looking for reference image...')\n",
    "    if not os.path.isfile(ref):\n",
    "        raise IOError('Please enter a valid path for ref, or select a different option for this argument')\n",
    "    else:\n",
    "        ref_msk = ni.load(ref).get_data()\n",
    "        if ref_msk.shape != i4d.shape[:3]:\n",
    "            raise ValueError('ref region image dimensions do not match PET data dimensions')\n",
    "        ref_uvals = len(np.unique(ref_msk))\n",
    "        if ref_uvals > 2 and ref_uvals < 1003:\n",
    "            print('found reference atlas. Using for region-wise probability calculation')\n",
    "            regionwise = True\n",
    "        elif ref_uvals < 2 or ref_uvals > 1002:\n",
    "            raise ValueError(\n",
    "                    'reference image is either empty or has too many unique values for an atlas.')\n",
    "        else:\n",
    "            print('found binary reference region mask. Using for probability calculation')\n",
    "\n",
    "elif type(ref) == list:\n",
    "    ref_msk = np.zeros_like(atlas)\n",
    "    for i in ref:\n",
    "        ref_msk[atlas == i] = 1\n",
    "else:\n",
    "    ref_msk = None\n",
    "\n",
    "\n",
    "# Mask data\n",
    "print('masking data...')\n",
    "if msk == None:\n",
    "    img_mask = deepcopy(atlas)\n",
    "    img_mask[img_mask<1] = 0\n",
    "    img_mask[img_mask>0] = 1\n",
    "else:\n",
    "    img_mask = ni.load(msk).get_data()\n",
    "    atlas[img_mask < 1] = 0\n",
    "\n",
    "if type(ref_msk) != type(None):\n",
    "    ref_msk[img_mask < 1] = 0\n",
    "\n",
    "mask_tfm = input_data.NiftiMasker(ni.Nifti1Image(img_mask,i4d.affine))\n",
    "mi4d = mask_tfm.fit_transform(i4d)\n",
    "\n",
    "# dimension reduction (IN BETA!)\n",
    "if dimension_reduction:\n",
    "    print('reducing dimensions...')\n",
    "    dm_mask = mask_tfm.mask_img_.get_data().astype(bool)\n",
    "    shape = dm_mask.shape\n",
    "    connectivity = grid_to_graph(n_x=shape[0], n_y=shape[1],\n",
    "                               n_z=shape[2], mask=dm_mask)\n",
    "    mi4d, labels, ward = dim_reduction(mi4d, connectivity, dimension_reduction)\n",
    "    labels_img = mask_tfm.inverse_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating voxelwise ECDF...\n"
     ]
    }
   ],
   "source": [
    "skip = False\n",
    "if ref != 'voxelwise':\n",
    "    if type(ECDF_in) != type(None): \n",
    "        print('generating ECDF...')\n",
    "        print('using user-supplied data...')\n",
    "        if type(ECDF_in) == ed.ECDF:\n",
    "            mi4d_ecdf, ecref = ecdf_simple(mi4d, ECDF_in)\n",
    "            input_distribution = 'not generated'\n",
    "        elif type(ECDF_in) == np.ndarray:\n",
    "            mi4d_ecdf, ecref = ecdf_simple(mi4d, ECDF_in)\n",
    "            input_distribution = ECDF_in\n",
    "        elif type(ECDF_in) == str:\n",
    "            if not os.path.isfile(ECDF_in):\n",
    "                raise ValueError('input for ECDF_in is not a valid path')\n",
    "            if '.npy' not in ECDF_in:\n",
    "                raise ValueError('this function currently only accepts .npy files as inputs for ECDF_in')\n",
    "            input_distribution = np.load(ECDF_in)\n",
    "            mi4d_ecdf, ecref = ecdf_simple(mi4d, input_distribution)\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                mi4d_ecdf, ecref = ecdf_simple(mi4d, ECDF_in)\n",
    "                print('Could not understand ECDF input, but ECDF successful')\n",
    "                input_distribution = 'not generated'\n",
    "            except:\n",
    "                raise IOError(\n",
    "                        'Invalid argument for ECDF in. Please enter an ndarray, an ECDF object, or a valid path')\n",
    "    else:\n",
    "        if type(ref_msk) != type(None):\n",
    "            if not regionwise:\n",
    "                print('generating ECDF...')\n",
    "                ref_tfm = input_data.NiftiMasker(ni.Nifti1Image(ref_msk,i4d.affine))\n",
    "                refz = ref_tfm.fit_transform(i4d)\n",
    "                mi4d_ecdf, ecref = ecdf_simple(mi4d, refz)\n",
    "                input_distribution = refz.flat\n",
    "            else:\n",
    "                print('generating region-wise ECDF...')\n",
    "                if not voxyreg:\n",
    "                    reg_mat = generate_matrix_from_atlas(i4d, ref_msk)\n",
    "                    mi4d_ecdf, ECDF_array = ecdf_voxelwise(np.array(reg_mat),ref_index, save_ECDF)\n",
    "                    f_mat = pandas.DataFrame(mi4d_ecdf,\n",
    "                                             columns = ['roi_%s'%x for x in np.unique(ref_msk.astype(int))[1:]]\n",
    "                                            )\n",
    "                    input_distribution = 'not_generated'\n",
    "                else:\n",
    "                    # FIX THIS UP\n",
    "                    f_images = ecdf_regionwise(i4d, ref_index, save_ECDF, ref_msk)\n",
    "                    ECDF_array = None\n",
    "                    input_distribution = 'not_generated'\n",
    "        else:\n",
    "            print('skipping ECDF...')\n",
    "            skip = True\n",
    "\n",
    "else:\n",
    "    print('generating voxelwise ECDF...')\n",
    "    mi4d_ecdf, ECDF_array = ecdf_voxelwise(mi4d, ref_index, save_ECDF)\n",
    "    input_distribution = 'not generated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8,  0.8,  0.6, ...,  0.2,  0.2,  0.2],\n",
       "       [ 0.4,  0.4,  0.4, ...,  0.8,  0.8,  0.8],\n",
       "       [ 1. ,  1. ,  1. , ...,  1. ,  1. ,  1. ],\n",
       "       [ 0.6,  0.6,  0.8, ...,  0.6,  0.6,  0.6],\n",
       "       [ 0.2,  0.2,  0.2, ...,  0.4,  0.4,  0.4]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi4d_ecdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.85238528251647949, 0.80000000000000004),\n",
       " (0.76113224029541016, 0.40000000000000002),\n",
       " (1.2351555824279785, 1.0),\n",
       " (0.81288999319076538, 0.60000000000000009),\n",
       " (0.58321291208267212, 0.20000000000000001)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(mi4d[:,0],mi4d_ecdf[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8,  0.4,  1. ,  0.6,  0.2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed.ECDF(mi4d[:,0])(mi4d[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not save_ECDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def ecdf_voxelwise(mi4d, ref_index, save_ECDF):\n",
    "\n",
    "X,y = mi4d.shape\n",
    "\n",
    "mi4d_ecdf = np.array([ed.ECDF(mi4d[:,x])(mi4d[:,x]) for x in range(y)]).reshape(X,y)\n",
    "ECDF_array = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8,  0.4,  1. ,  0.6,  0.2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 0\n",
    "ed.ECDF(mi4d[:,x])(mi4d[:,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,y = mi4d.shape\n",
    "jnk = np.array([ed.ECDF(mi4d[:,x])(mi4d[:,x]) for x in range(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8,  0.8,  0.6, ...,  0.2,  0.2,  0.2],\n",
       "       [ 0.4,  0.4,  0.4, ...,  0.8,  0.8,  0.8],\n",
       "       [ 1. ,  1. ,  1. , ...,  1. ,  1. ,  1. ],\n",
       "       [ 0.6,  0.6,  0.8, ...,  0.6,  0.6,  0.6],\n",
       "       [ 0.2,  0.2,  0.2, ...,  0.4,  0.4,  0.4]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mtx = np.zeros_like(mi4d)\n",
    "for x in range(y):\n",
    "    new_mtx[:,x] = jnk[x]\n",
    "new_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jnk.reshape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
