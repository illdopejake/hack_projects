{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn import preprocessing, linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from sklearn.utils import check_array\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kfold_feature_learning(train, test, y, t_y, clf = linear_model.LassoCV(cv=10), problem = 'regression', \n",
    "                           folds = 10, scale=True, verbose = True, search = False,\n",
    "                           p_cutoff = None, regcols = None, regdf = None, keep_cols = None, \n",
    "                           out_dir = None,  output='light', save_int = True):\n",
    "    '''\n",
    "    This is a function that will use nested cross validation to generate an average model\n",
    "    that will hopefully generalize better to unseen test data. \n",
    "    \n",
    "    You can must your training and testing data, and your y variable for both, the model you \n",
    "    wish to use for  prediction, and whether the problem is classification or regression.\n",
    "    \n",
    "    The function will run K iterations of prediction on your training set, and will average \n",
    "    the weights across folds for a final model. The final model will then be applied to your \n",
    "    testing data. The validation and testing accuracy will be displayed. \n",
    "    \n",
    "    Several other options exists (see below), and are forthcoming.\n",
    "    \n",
    "    ATTENTION: THIS SCRIPT IS STILL IN DEVELOPMENT. IT IS UGLY AND UNFINISHED, SO DONT JUDGE\n",
    "    \n",
    "    \n",
    "    *** USER-DEFINED ARGUMENTS ***\n",
    "    \n",
    "    -- train is a subjects x variables dataframe (this represents your training data)\n",
    "    -- y is a pandas series with the same index as train. y should not be in train\n",
    "    \n",
    "    # NOTE: train and test indices should just be a range\n",
    "    \n",
    "    -- test is a subjects x variables dataframe (this represents your independent test data)\n",
    "    -- t_y is a pandas seris with the same index as test. y should not be in tets\n",
    "\n",
    "    \n",
    "    *** MODEL OPTIONS ***\n",
    "\n",
    "    -- clf: here, you can put in whatever model you want with whatever parameters you want.\n",
    "    \n",
    "    -- if your model (clf) is a regression model (e.g. Lasso, SVR), leave problem as \"regression\". \n",
    "    If it is a classification model (e.g. SVM, SGD, etc.), change problem to \"classification\"\n",
    "    \n",
    "    -- folds: how many fold cross-validation should occur within the outer loop of the t\n",
    "    raining dataset\n",
    "    \n",
    "    -- scale: if True, train will be scaled with a Standard Scaler, and test will be transformed \n",
    "    to this scale\n",
    "    \n",
    "    -- verbose: if you do not want any output (including scores at the end!!), set this to False.\n",
    "    \n",
    "    -- search: if clf is a model_selector (such as GridSearch), MAKE SURE you set this to True,\n",
    "    or the script will fail.\n",
    "    \n",
    "    \n",
    "    *** FEATURE SELECTION OPTIONS ***\n",
    "    \n",
    "    -- p_cutoff: if you wish to only keep features statistically related to y (through t-test \n",
    "    or correlation), you can control the alpha value here. Leave as None to use all features\n",
    "    \n",
    "    -- reg_cols: a list of column labels in regdf. All labels specified in this list will be \n",
    "    regressed out of all other model features during \"feature selection\" (i.e. when features are\n",
    "    removed via the p_cutoff argument). In other words, this argument can be used if you only\n",
    "    want to include features in your model that are singificant when adjusting for the variables\n",
    "    specified in reg_cols. Leave as None if you don't want this argument active.\n",
    "    \n",
    "    -- regdf: a subject x variables pandas Dataframe that contain anything as long as it has all \n",
    "    (matched) indices in train, and all columns in reg_cols\n",
    "    \n",
    "    -- keep_cols: a list of column labels. These are variables in train that you wish to retain \n",
    "    in your model no matter what, even if they do not pass the feature selection. For example, if\n",
    "    age is not selected by your p_cutoff, but you still want age in your model, you can list in\n",
    "    keep_cols\n",
    "    \n",
    "    *** OUTPUT OPTIONS ***\n",
    "    \n",
    "    -- out_dir: will save your weight matrix and predicted values to a directory you specify\n",
    "    \n",
    "    -- output: decide what you want the function to return:\n",
    "        * 'scores' will only return the r2 (regression) or sensitivity, specificity and accuracy\n",
    "            of you validation and test.\n",
    "        * 'light' will return the weights of your final model, the predicted values of your\n",
    "            validation, the predicted values of your test, and the intercept of the final model, \n",
    "            in that order.\n",
    "        * 'heavy' if problem = regression, will return everything from light, plus a matrix \n",
    "            containing weights from all folds of the validations. Will also return the model \n",
    "            from the most recent fold.\n",
    "            if problem = classification, will return a summary dataframe (with weights) for your\n",
    "            validation, a summary dataframe for your test, your predicted values from validation,\n",
    "            predicted values from test, a matrix containing weights from all folds of the \n",
    "            validation, and the model from the most recent fold.\n",
    "        \n",
    "        '''\n",
    "    \n",
    "    \n",
    "    if problem != 'regression' and problem != 'classification':\n",
    "        raise IOError('please set problem to regression or classification')\n",
    "    \n",
    "    #feature_matrix = pandas.DataFrame(np.zeros_like(train))\n",
    "    \n",
    "    # Initiate variables\n",
    "    predicted = []\n",
    "    all_weights = pandas.DataFrame(np.zeros((folds,len(train.columns))))\n",
    "    if save_int:\n",
    "        ints = []\n",
    "    start = 0\n",
    "    fold = 1\n",
    "    \n",
    "    # scale inputs\n",
    "    if scale:\n",
    "        master_scl = preprocessing.StandardScaler().fit(train)\n",
    "        train = pandas.DataFrame(master_scl.transform(train),\n",
    "                                 index=train.index,columns=train.columns)\n",
    "        test = pandas.DataFrame(master_scl.transform(test),\n",
    "                                 index=test.index,columns=test.columns)\n",
    "    \n",
    "    # strip columns names\n",
    "    tr_cols = train.columns \n",
    "    train.columns = range(len(train.columns))\n",
    "    test.colums = range(len(test.columns))\n",
    "    \n",
    "    \n",
    "    for tr_ix, te_ix in KFold(n_splits=folds).split(train):\n",
    "        tmp_mtx = train.loc[train.index[tr_ix]] # working matrix\n",
    "        \n",
    "        # Build regression statements (if regcols)\n",
    "        if regcols != None: \n",
    "            ref = deepcopy(tmp_mtx)\n",
    "            tmp_mtx.columns = ['x_%s'%x for x in tmp_mtx.columns]\n",
    "            tmp_mtx['y'] = y.loc[tmp_mtx.index]\n",
    "            stmnt = 'y ~'\n",
    "            for z,col in enumerate(regcols):\n",
    "                cov = 'cov_%s'%z\n",
    "                tmp_mtx[cov] = regdf.loc[tmp_mtx.index][col]\n",
    "                if z == 0:\n",
    "                    stmnt += ' %s'%cov\n",
    "                else:\n",
    "                    stmnt += ' + %s'%cov\n",
    "        else:\n",
    "            regcols = []\n",
    "        \n",
    "        # feature selection -- only retain significant features\n",
    "        ps = []\n",
    "        if p_cutoff != None:\n",
    "            if len(regcols) > 0:\n",
    "                if verbose:\n",
    "                    print('running regression for fold %s of %s'%(fold,folds))\n",
    "                for x in range(tmp_mtx.shape[1] - (len(regcols) + 1)):\n",
    "                    n_stmnt = '%s + x_%s'%(stmnt,x)\n",
    "                    ps.append(smf.ols(stmnt,data=temp_mtx).fit().pvalues[-1])\n",
    "                sig_mtx = ref.loc[ref.index[:]]\n",
    "            else:\n",
    "                if problem == 'regression':\n",
    "                    if verbose:\n",
    "                        print('running correlation for fold %s of %s'%(fold,folds))\n",
    "                    for x in range(tmp_mtx.shape[1]):\n",
    "                        ps.append(stats.pearsonr(\n",
    "                                y[tmp_mtx.index].values,tmp_mtx.values[:,x])[1]\n",
    "                             )\n",
    "                else: # classification\n",
    "                    if verbose:\n",
    "                        print('running ttests for fold %s of %s'%(fold,folds))\n",
    "                    for x in range(tmp_mtx.shape[1]):\n",
    "                        ps.append(stats.ttest_ind(\n",
    "                                tmp_mtx.loc[y[tmp_mtx.index][y[tmp_mtx.index]==0].index][tmp_mtx.columns[x]],\n",
    "                                tmp_mtx.loc[y[tmp_mtx.index][y[tmp_mtx.index]==1].index][tmp_mtx.columns[x]]\n",
    "                             )[1])\n",
    "            ps_s = pandas.Series(ps)\n",
    "            sig = ps_s[ps_s < p_cutoff]\n",
    "            if len(sig) == 0:\n",
    "                fold += 1\n",
    "                continue\n",
    "            sig_mtx = tmp_mtx[sig.index]\n",
    "        else:\n",
    "            sig_mtx = tmp_mtx[tmp_mtx.columns[:]]\n",
    "        \n",
    "        # run model\n",
    "        if verbose:\n",
    "            print('running model for fold %s of %s'%(fold,folds))\n",
    "        if type(keep_cols) == list:\n",
    "            for col in keep_cols:\n",
    "                sig_mtx[col] = tmp_mtx.ix[:,col]\n",
    "        if search:\n",
    "            mod_sel = clf.fit(sig_mtx,y[sig_mtx.index])\n",
    "            new_clf = mod_sel.best_estimator_\n",
    "            model = new_clf.fit(sig_mtx,y[sig_mtx.index])\n",
    "        else:\n",
    "            model = clf.fit(sig_mtx,y[sig_mtx.index])\n",
    "        try:\n",
    "            all_weights.loc[(fold-1)][sig_mtx.columns] = model.coef_\n",
    "        except:\n",
    "            all_weights.loc[(fold-1)][sig_mtx.columns] = model.coef_[0,:]\n",
    "        # save predicted values for this validation fold\n",
    "        [predicted.append(x) for x in model.predict(train.loc[train.index[te_ix]][\n",
    "                                                    sig_mtx.columns].values)]\n",
    "        if save_int:\n",
    "            ints.append(model.intercept_)\n",
    "        \n",
    "        # reset variables\n",
    "        fold += 1\n",
    "        if len(regcols) == 0:\n",
    "            regcols = None\n",
    "        \n",
    "        # save output\n",
    "        if out_dir != None and type(out_dir) == str:\n",
    "            print('saving matrix for fold %s of %s'%(fold,folds))\n",
    "            if not os.path.isdir(out_dir):\n",
    "                os.mkdir(out_dir)\n",
    "            feature_matrix.to_csv(os.path.join(out_dir,'lasso_weights.csv'))\n",
    "            pandas.DataFrame(pandas.Series(predicted)).to_csv(\n",
    "                                                    os.path.join(out_dir,'lasso_predicted.csv'))\n",
    "        \n",
    "    # assemble final model\n",
    "    final_weights = all_weights.mean(axis=0)\n",
    "    n_feats = len([i for i in final_weights.index if abs(final_weights[i]) > 0 ])\n",
    "    if verbose:\n",
    "        print(n_feats,'features selected')\n",
    "    \n",
    "    if n_feats == 0:\n",
    "        val_res, t_res = np.nan, np.nan\n",
    "        predicted, t_predicted = [], np.array([])\n",
    "        if save_int:\n",
    "            all_ints = np.mean(ints)\n",
    "        else:\n",
    "            all_ints = np.nan\n",
    "        val_sum, t_sum = pandas.DataFrame(), pandas.DataFrame()\n",
    "    else:\n",
    "    \n",
    "        # run validation\n",
    "        if problem == 'regression':\n",
    "            r,p = stats.pearsonr(y[train.index],predicted)\n",
    "            val_res = (r**2)*100\n",
    "            if verbose:\n",
    "                print('validation prediction accuracy is %s percent \\n p = %s \\n r = %s'%(val_res,p,r))\n",
    "        else:\n",
    "            val_sum, val_res = manual_classification(y[train.index],predicted,verbose,'validation')\n",
    "\n",
    "        # apply model to test data\n",
    "        ntest = check_array(test,accept_sparse='csr')\n",
    "        t_predicted = pandas.Series(safe_sparse_dot(ntest,np.array(final_weights).T,dense_output=True),index=test.index)\n",
    "        if save_int:\n",
    "            all_ints = np.mean(ints)\n",
    "            t_predicted += all_ints\n",
    "        else:\n",
    "            all_ints = []\n",
    "\n",
    "        # run test\n",
    "        if problem == 'regression':\n",
    "            r,p = stats.pearsonr(t_y[test.index],t_predicted)\n",
    "            t_res = (r**2)*100\n",
    "            if verbose:\n",
    "                print('testing prediction accuracy is %s percent \\n p = %s \\n r = %s'%(t_res,p,r))\n",
    "        else: # classification\n",
    "            t_decision_func = t_predicted\n",
    "            t_predicted = pandas.Series(index = test.index)\n",
    "            t_predicted[t_decision_func[t_decision_func<0].index] = 0\n",
    "            t_predicted[t_decision_func[t_decision_func>0].index] = 1\n",
    "            t_sum, t_res = manual_classification(t_y[test.index],t_predicted,verbose,'testing',t_decision_func)\n",
    "\n",
    "    # prepare outputs\n",
    "    \n",
    "    final_weights.columns = tr_cols\n",
    "    all_weights.columns = tr_cols\n",
    "    \n",
    "    if output == 'scores':\n",
    "            return val_res, t_res\n",
    "    elif output == 'light':\n",
    "        return final_weights, predicted, t_predicted, all_ints\n",
    "    else:\n",
    "        if problem == 'regression':\n",
    "            return final_weights, predicted, t_predicted, all_ints, all_weights, model\n",
    "        else:\n",
    "            return val_sum, t_sum, predicted, t_predicted, all_ints, all_weights, model \n",
    "\n",
    "def manual_classification(obs, pred, verbose, mode='validation', weights=None):\n",
    "            \n",
    "    if type(obs) == pandas.core.series.Series:\n",
    "        obs = obs.values\n",
    "    \n",
    "    if type(pred) == pandas.core.series.Series:\n",
    "        pred = pred.values\n",
    "    \n",
    "    summary = pandas.DataFrame(index=range(len(obs)),columns = ['Predicted','Actual'])\n",
    "    summary['Predicted'] = pred\n",
    "    summary['Actual'] = obs\n",
    "    if type(weights) != type(None):\n",
    "        summary['Prediction Function'] = weights\n",
    "    for x in summary.index: \n",
    "        if summary.ix[x,'Predicted'] == summary.ix[x,'Actual']:\n",
    "            summary.ix[x,'Hit'] = 1\n",
    "        else:\n",
    "            summary.ix[x,'Hit'] = 0\n",
    "\n",
    "    tp,tn,fp,fn = [],[],[],[]\n",
    "    for i,row in summary.iterrows():\n",
    "        val = row['Predicted'] - row['Actual']\n",
    "        if val == 0:\n",
    "            if row['Actual'] == 1:\n",
    "                tp.append(i)\n",
    "            else:\n",
    "                tn.append(i)\n",
    "        elif val == 1:\n",
    "            fp.append(i)\n",
    "        elif val == -1:\n",
    "            fn.append(i)\n",
    "        else:\n",
    "            print('something went wrong for ',i)\n",
    "\n",
    "    sens = len(tp)/(len(tp)+len(fn))\n",
    "    spec = len(tn)/(len(tn)+len(fp))\n",
    "    acc = (len(tp)+len(tn))/(len(tp)+len(fn)+len(tn)+len(fp))\n",
    "\n",
    "    if verbose:\n",
    "        print(mode,' sensitivity:' , sens)\n",
    "        print(mode,'specificity:' , spec)\n",
    "        print(mode,'accuracy:', acc)\n",
    "\n",
    "    results = [sens,spec,acc]\n",
    "\n",
    "    return summary, results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET VARIABLES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>RID</th>\n",
       "      <th>PTID</th>\n",
       "      <th>age_r</th>\n",
       "      <th>sex</th>\n",
       "      <th>mean_gm</th>\n",
       "      <th>TIV</th>\n",
       "      <th>EXAMDATE</th>\n",
       "      <th>scan_date</th>\n",
       "      <th>vbm_file</th>\n",
       "      <th>...</th>\n",
       "      <th>score_41</th>\n",
       "      <th>score_42</th>\n",
       "      <th>score_43</th>\n",
       "      <th>score_44</th>\n",
       "      <th>score_45</th>\n",
       "      <th>score_46</th>\n",
       "      <th>score_47</th>\n",
       "      <th>score_48</th>\n",
       "      <th>score_49</th>\n",
       "      <th>score_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject0021</td>\n",
       "      <td>21.0</td>\n",
       "      <td>011_S_0021</td>\n",
       "      <td>72.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290485</td>\n",
       "      <td>1440900.75</td>\n",
       "      <td>10/24/2005</td>\n",
       "      <td>10/10/05</td>\n",
       "      <td>smwrc1rl_T1_scandate_732595_birthdate_705585_0...</td>\n",
       "      <td>...</td>\n",
       "      <td>35.530734</td>\n",
       "      <td>35.859132</td>\n",
       "      <td>32.373150</td>\n",
       "      <td>35.582640</td>\n",
       "      <td>3.597200</td>\n",
       "      <td>20.694638</td>\n",
       "      <td>30.465716</td>\n",
       "      <td>30.551352</td>\n",
       "      <td>17.848491</td>\n",
       "      <td>33.041795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject0023</td>\n",
       "      <td>23.0</td>\n",
       "      <td>011_S_0023</td>\n",
       "      <td>71.700000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.332182</td>\n",
       "      <td>1544985.50</td>\n",
       "      <td>11/8/2005</td>\n",
       "      <td>10/31/05</td>\n",
       "      <td>smwrc1rl_T1_scandate_732616_birthdate_704876_0...</td>\n",
       "      <td>...</td>\n",
       "      <td>46.745997</td>\n",
       "      <td>37.528679</td>\n",
       "      <td>35.017123</td>\n",
       "      <td>46.444176</td>\n",
       "      <td>-0.549843</td>\n",
       "      <td>28.184171</td>\n",
       "      <td>32.632151</td>\n",
       "      <td>51.511630</td>\n",
       "      <td>16.697365</td>\n",
       "      <td>32.914088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject0059</td>\n",
       "      <td>59.0</td>\n",
       "      <td>067_S_0059</td>\n",
       "      <td>78.875359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.282895</td>\n",
       "      <td>1279627.00</td>\n",
       "      <td>12/13/2013</td>\n",
       "      <td>12/13/13</td>\n",
       "      <td>smwrc1rl_T1_scandate_735581_birthdate_707841_0...</td>\n",
       "      <td>...</td>\n",
       "      <td>41.090286</td>\n",
       "      <td>39.981865</td>\n",
       "      <td>31.352580</td>\n",
       "      <td>41.385673</td>\n",
       "      <td>8.823693</td>\n",
       "      <td>29.729746</td>\n",
       "      <td>29.393542</td>\n",
       "      <td>31.002191</td>\n",
       "      <td>17.068733</td>\n",
       "      <td>32.878287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject0069</td>\n",
       "      <td>69.0</td>\n",
       "      <td>100_S_0069</td>\n",
       "      <td>72.900000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.355717</td>\n",
       "      <td>1762411.50</td>\n",
       "      <td>1/17/2006</td>\n",
       "      <td>12/13/05</td>\n",
       "      <td>smwrc1rl_T1_scandate_732659_birthdate_703094_1...</td>\n",
       "      <td>...</td>\n",
       "      <td>40.169767</td>\n",
       "      <td>38.129086</td>\n",
       "      <td>39.121106</td>\n",
       "      <td>55.116683</td>\n",
       "      <td>0.539394</td>\n",
       "      <td>30.381675</td>\n",
       "      <td>39.192471</td>\n",
       "      <td>36.662482</td>\n",
       "      <td>20.824451</td>\n",
       "      <td>44.217368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject0089</td>\n",
       "      <td>89.0</td>\n",
       "      <td>073_S_0089</td>\n",
       "      <td>65.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.349537</td>\n",
       "      <td>1589139.25</td>\n",
       "      <td>1/31/2006</td>\n",
       "      <td>01/26/06</td>\n",
       "      <td>smwrc1rl_T1_scandate_732703_birthdate_708248_0...</td>\n",
       "      <td>...</td>\n",
       "      <td>37.290587</td>\n",
       "      <td>47.598844</td>\n",
       "      <td>43.118446</td>\n",
       "      <td>47.927207</td>\n",
       "      <td>4.419909</td>\n",
       "      <td>33.710410</td>\n",
       "      <td>37.089623</td>\n",
       "      <td>39.986202</td>\n",
       "      <td>20.966313</td>\n",
       "      <td>45.762426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject   RID        PTID      age_r  sex   mean_gm         TIV  \\\n",
       "0  subject0021  21.0  011_S_0021  72.600000  0.0  0.290485  1440900.75   \n",
       "1  subject0023  23.0  011_S_0023  71.700000  1.0  0.332182  1544985.50   \n",
       "2  subject0059  59.0  067_S_0059  78.875359  0.0  0.282895  1279627.00   \n",
       "3  subject0069  69.0  100_S_0069  72.900000  1.0  0.355717  1762411.50   \n",
       "4  subject0089  89.0  073_S_0089  65.100000  1.0  0.349537  1589139.25   \n",
       "\n",
       "     EXAMDATE scan_date                                           vbm_file  \\\n",
       "0  10/24/2005  10/10/05  smwrc1rl_T1_scandate_732595_birthdate_705585_0...   \n",
       "1   11/8/2005  10/31/05  smwrc1rl_T1_scandate_732616_birthdate_704876_0...   \n",
       "2  12/13/2013  12/13/13  smwrc1rl_T1_scandate_735581_birthdate_707841_0...   \n",
       "3   1/17/2006  12/13/05  smwrc1rl_T1_scandate_732659_birthdate_703094_1...   \n",
       "4   1/31/2006  01/26/06  smwrc1rl_T1_scandate_732703_birthdate_708248_0...   \n",
       "\n",
       "     ...       score_41   score_42   score_43   score_44  score_45   score_46  \\\n",
       "0    ...      35.530734  35.859132  32.373150  35.582640  3.597200  20.694638   \n",
       "1    ...      46.745997  37.528679  35.017123  46.444176 -0.549843  28.184171   \n",
       "2    ...      41.090286  39.981865  31.352580  41.385673  8.823693  29.729746   \n",
       "3    ...      40.169767  38.129086  39.121106  55.116683  0.539394  30.381675   \n",
       "4    ...      37.290587  47.598844  43.118446  47.927207  4.419909  33.710410   \n",
       "\n",
       "    score_47   score_48   score_49   score_50  \n",
       "0  30.465716  30.551352  17.848491  33.041795  \n",
       "1  32.632151  51.511630  16.697365  32.914088  \n",
       "2  29.393542  31.002191  17.068733  32.878287  \n",
       "3  39.192471  36.662482  20.824451  44.217368  \n",
       "4  37.089623  39.986202  20.966313  45.762426  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CHANGE PATH ## \n",
    "\n",
    "df = pandas.read_csv('/Users/jakevogel/Downloads/adni_bl_all_ica50_scores_20170922.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subject',\n",
       " 'RID',\n",
       " 'PTID',\n",
       " 'age_r',\n",
       " 'sex',\n",
       " 'mean_gm',\n",
       " 'TIV',\n",
       " 'EXAMDATE',\n",
       " 'scan_date',\n",
       " 'vbm_file',\n",
       " 'CN',\n",
       " 'MCI',\n",
       " 'AD',\n",
       " 'conv_2_AD']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()[:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(477, 64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269, 64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df[df.MCI == 0]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269, 50)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train[train.columns[14:]]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 50)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df[df.MCI == 1]\n",
    "X_test = test[test.columns[14:]]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train.AD\n",
    "y_test = test.conv_2_AD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN IT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a bunch of random settings -- I did not tweak or optimize it. Feel free to use different input data,\n",
    "tweak the parameters (i.e. folds, p-cutoff, clf), or whatever else. However, I am working on an optimizer script\n",
    "right now that I can send when its ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ttests for fold 1 of 10\n",
      "running model for fold 1 of 10\n",
      "running ttests for fold 2 of 10\n",
      "running model for fold 2 of 10\n",
      "running ttests for fold 3 of 10\n",
      "running model for fold 3 of 10\n",
      "running ttests for fold 4 of 10\n",
      "running model for fold 4 of 10\n",
      "running ttests for fold 5 of 10\n",
      "running model for fold 5 of 10\n",
      "running ttests for fold 6 of 10\n",
      "running model for fold 6 of 10\n",
      "running ttests for fold 7 of 10\n",
      "running model for fold 7 of 10\n",
      "running ttests for fold 8 of 10\n",
      "running model for fold 8 of 10\n",
      "running ttests for fold 9 of 10\n",
      "running model for fold 9 of 10\n",
      "running ttests for fold 10 of 10\n",
      "running model for fold 10 of 10\n",
      "39 features selected\n",
      "validation  sensitivity: 0.6352941176470588\n",
      "validation specificity: 0.8695652173913043\n",
      "validation accuracy: 0.7955390334572491\n",
      "testing  sensitivity: 0.6078431372549019\n",
      "testing specificity: 0.8789808917197452\n",
      "testing accuracy: 0.8125\n"
     ]
    }
   ],
   "source": [
    "jnk_weights, jnk_pred, jnk_t_pred, jnk_ints = kfold_feature_learning(\n",
    "                        X_train, X_test, y_train, y_test, \n",
    "                        p_cutoff=0.1,problem = 'classification', folds = 10, \n",
    "                        clf = linear_model.SGDClassifier(loss='modified_huber',penalty='l1',random_state=123), \n",
    "                        output='light', scale=True, regcols = None, regdf = None,\n",
    "                        keep_cols = None, save_int = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now using an embedded grid search into the pipeline! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again I did not mess with the parameters of the feature_learning function -- feel free to do so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params1 = {'loss': ['hinge','log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "          'penalty': ['none', 'l2', 'l1'],\n",
    "          'alpha': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]} \n",
    "params2 = {'loss': ['hinge','log', 'modified_huber', 'squared_hinge'],\n",
    "          'penalty': ['elasticnet'],\n",
    "          'alpha': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "          'l1_ratio': [0.05,0.1,0.15,0.2,0.3,0.5]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selector = model_selection.GridSearchCV(linear_model.SGDClassifier(random_state=123),[params1,params2],cv=10,\n",
    "                                       scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model for fold 1 of 3\n",
      "running model for fold 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model for fold 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 features selected\n",
      "validation  sensitivity: 0.7294117647058823\n",
      "validation specificity: 0.8695652173913043\n",
      "validation accuracy: 0.8252788104089219\n",
      "testing  sensitivity: 0.5294117647058824\n",
      "testing specificity: 0.8280254777070064\n",
      "testing accuracy: 0.7548076923076923\n"
     ]
    }
   ],
   "source": [
    "output = kfold_feature_learning(X_train, X_test, y_train, y_test, clf = selector, search = True,\n",
    "                                p_cutoff=None,problem = 'classification', folds = 3, output='light', \n",
    "                                scale=True, regcols = None, regdf = None, keep_cols = None, save_int = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.141697e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.858519e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.473730e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.156278e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.224115e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Weight\n",
       "0 -1.141697e+11\n",
       "1 -5.858519e+10\n",
       "2 -2.473730e+11\n",
       "3 -1.156278e+11\n",
       "4  1.224115e+11"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wts = pandas.DataFrame(output[0],columns = ['Weight'])\n",
    "#wts = wts.loc[abs(wts).sort_values('Weight',ascending = False).index]\n",
    "wts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAH8CAYAAABCV0cFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3Xl4VOXd//HPmUli9pCwhy0sSmAIEHZohVqtWm1R9FER\nWX5iFVRacWEt4kIR0FqxIFKhlU1R+lhcKpsUV6TITp4BBESWhCWEhAxkISY5vz8o0yDbbMmcZN6v\n6+rVaeb+zv3NIaZ+uM+5b8M0TVMAAAAAAEuyBbsBAAAAAMClEdoAAAAAwMIIbQAAAABgYYQ2AAAA\nALAwQhsAAAAAWBihDQAAAAAsjNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdqC6A9/+INSU1P1/vvv\nV+m8ZWVluuOOO5SamqrDhw97Xf+Xv/xFqampmjNnTiV0BwAAAKAiQluQrF69Wm+//bYMw6jyuV96\n6SXt2LHDp7k3btyo1157LSh9AwAAAKGI0BYEa9as0eOPPy7TNKt87ldeeUXz5s3zqXbjxo0aNmyY\nfvjhh8A2BQAAAOCSwoLdQCgxTVMzZszQ7NmzZZqmTNOsshWrU6dOafTo0fr0009lGIbXgXH+/Pl6\n6aWXVFZWVqV9AwAAAKGOlbYq8uWXX6pv376aNWuWTNOUw+GoknnLysr01ltv6aabbnIHtrZt23pc\nv3nzZvXv319TpkxRWVlZlfUNAAAA4CxW2qrIgw8+KMMwFB4erocffli//vWv9Ytf/MLj+pMnT2re\nvHn67LPPdOjQIZWVlalhw4a69tprNXToUDVo0OCidZs2bdKkSZNkGIbq1KmjZ599VqdOndK4ceM8\nmve3v/2tcnNzZbfbNXjwYD366KPq0qWLx30DAAAA8A+hrYrYbDb94he/0MiRI9W8eXNlZWV5XPvv\nf/9bjz32mPLz88+7LXH//v36/vvvtWTJEr344ou68cYbL1ofFRWlAQMGaPjw4YqLi9PSpUu96vsn\nP/mJnnrqKaWmpqqkpMTjWgAAAAD+I7RVkeXLl6tZs2Ze1+3evVvDhw/XmTNn1KRJEz322GPq1q2b\nwsPDlZGRoRkzZigjI0NPPPGEFi5cqPT09PPqW7durc8//1zx8fE+9b1o0SKf+gYAAAAQGDzTVkV8\nDT7PPfeciouL1bhxY7333nv61a9+pXr16ikxMVG9e/fWW2+9pfbt26usrEzPPffcBfUJCQk+BzZ/\n+gYAAAAQGIQ2C9u7d682bdokwzD06KOPXjR8RUREuI8P+Pbbb7V9+/YgdAoAAACgsnB7pIWtX7/e\n/frqq69WYWHhRce1bt1adrtd5eXl2rx5s9q3b19VLQIAAACoZIS2/ygoKND8+fO1evVqHTp0SGfO\nnFFycrL69OmjBx54QPXq1avynjIzM92v77zzziuONwxDR44cqcyWAAAAAFQxQpukXbt26cEHH9Tx\n48fP253xwIEDmj9/vt5//33NnTtXaWlpVdrX6dOn3a89Pcy6Yg0AAACA6i/kQ1tOTo6GDBkil8ul\n+Ph4Pf744/rZz36m0tJSrVmzRtOnT5fL5dKIESO0fPlyRUdHV1lvkZGR7tfbt29XeHh4lc0NAAAA\nwBpCfiOSKVOmKD8/X9HR0Zo3b57uvfdeNWzYUE2aNNGQIUM0ffp0maap7Oxsvf/++1XaW3Jysvt1\nxVslAQAAAISOkA5tJ06c0IoVK2QYhh5++GG1bdv2gjF9+vRRSkqKwsLCtGPHjirtr0uXLu7X//rX\nvy457tzmIzfffLNWrlxZFa0BAAAAqCIhfXvkihUrVFZWpqioKA0cOPCS4z788ENFRERUYWdnpaWl\nqU2bNtq5c6fmzJmjG2+8UU2bNj1vzJkzZzRt2jSVlJQoKyuLnSMBAACAGiakV9oyMjIkSe3btz/v\n+TFJKi0tdb8ORmA7Z+LEiQoLC1N+fr7uvvtuvfXWW8rKylJubq6++uorDRkyRNu2bZNhGPrNb36j\nhg0bBq1XAAAAAIEX0ittu3fvlmEYatasmaSztyAuWrRIW7duVVFRkerWrasbbrhBDz/8cFC2/Jek\n9PR0zZgxQ0899ZTy8/M1adIkTZo0yf2+YRgyDEN33XWXfve73wWlRwAAAACVJ6RD2/HjxyVJtWrV\n0sSJE7VkyRL31vqGYSgnJ0eLFy/W8uXLNXv2bHXs2DGg858LXFdy3XXXadWqVVqwYIG+/PJLHTp0\nSMXFxUpKSlLHjh3Vv39/9ezZs1Lmvlw9AAAAgMpnmKZpBruJYOnUqZOKiopUp04dHT9+XF27dtUT\nTzwhh8OhgoICLV++XC+//LIKCgpUu3ZtffDBB6pTp06w2wYAAAAQQkI6tLVt21bnvv0ePXpo7ty5\nstvt543ZuHGjBg8eLNM0NWjQII0fPz4YrQIAAAAIUSG9EUlkZKQ7tI0ZM+aCwCad3Xa/T58+Mk1T\nq1atquoWAQAAAIS4kA5tMTExkqS4uDilpqZecly3bt0kSceOHVNBQUGV9AYAAAAAUoiHtsaNG0u6\n8pb+sbGx7tdnzpzx+PND+M5TAAAAAAES0rtHtmnTRlu2bFFeXp4KCwsVHR190XE5OTmSpLCwMCUl\nJXn8+bm5BbLZ2GURAAAACHWJiTE+14Z0aOvTp4/efvttlZeX65NPPtFtt9120XFr166VJHXo0MGr\nzy8vN1VezmobAAAAAN+F9O2RP/3pT5WcnCzTNDV9+nTl5uZeMGbFihXauHGjDMPQHXfcEYQuAQAA\nAISykA5tdrtdkyZNks1m05EjR/Q///M/+vDDD5Wdna3Dhw9r9uzZGjVqlAzDUMeOHdWvX79gtwwA\nAAAgxIT0OW3nLFu2TL///e9VXFx8weYhhmHI4XDotddeU/369b363OPHTwWyTQAAAADVVN26cT7X\nEtr+4+jRo3rzzTf1xRdf6OjRo4qIiFDz5s1122236c4777ziDpMXQ2gDAAAAIBHaLIvQBgAAAEDy\nL7SF9DNtAAAAAGB1hDYAAAAAsDBCGwAAAABYGKENAAAAACyM0AYAAAAAFkZoAwAAAAALI7QBAAAA\ngIUR2gAAAADAwghtAAAAAGBhhDYAAAAAsDBCGwAAAABYGKENAAAAACyM0AYAAAAAFkZoAwAAAAAL\nI7QBAAAAgIUR2gAAAADAwghtAAAAAGBhhDYAAAAAsDBCGwAAAABYGKENAAAAACyM0AYAAAAAFkZo\nAwAAAAALI7QBAAAAgIUR2gAAAADAwghtAAAAAGBhhDYAAAAAsDBCGwAAAABYGKENAAAAACyM0AYA\nAAAAFkZoAwAAAAALI7QBAAAAgIWFBbsBVJ6SkhI5nRle1TgcaYqIiKikjgAAAAB4i9BWgzmdGRr+\n20cUGR3j0fjiwgLNnjFL6emdK7kzAAAAAJ4itNVwkdExio2LD3YbAAAAAHzEM20AAAAAYGGENgAA\nAACwMEIbAAAAAFgYoQ0AAAAALIzQBgAAAAAWRmgDAAAAAAsjtAEAAACAhXFOGypFSUmJnM4Mr2oc\njjRFRERUUkcAAABA9URoQ6VwOjP08MjHFBUb59H4otOn9Pr0V5We3rmSOwMAAACqF0IbKk1UbJxi\n42sFuw0AAACgWuOZtssoKirSTTfdpNTUVM2cOTPY7QAAAAAIQYS2y5gyZYoOHDggwzCC3QoAAACA\nEEVou4TPPvtMS5YsIbABAAAACCpC20Xk5uZqwoQJMgxDpmkGux0AAAAAIYzQdhETJkzQiRMn1K9f\nv2C3AgAAACDEEdp+5O9//7vWrFmjRo0a6fe//32w2wEAAAAQ4ghtFRw8eFBTpkyRzWbT1KlTFRMT\nE+yWAAAAAIQ4Qtt/lJeXa/To0SoqKtKQIUPUpUuXYLcEAAAAAIS2c2bPnq2tW7eqVatWevzxx4Pd\nDgAAAABIIrRJkv7v//5Ps2bNUlhYmF588UVFREQEuyUAAAAAkERo05kzZzRq1CiVlZXpkUceUZs2\nbYLdEgAAAAC4hXxomzZtmr7//nu1b99ew4cPD3Y7AAAAAHCesGA3EExfffWV3n77bUVGRmrq1Kmy\n2QKbYW02QzabEdDP9Ibd7v33Y7fbFBbm/3UI5twAAABATRLSoe3jjz+WJBUXF+uXv/zlJceZpqmZ\nM2dq5syZkqQ1a9YoOTn5ip+flBQjwwheaIuPj/KpJjHR/6MOgjk3AAAAUJOEdGiTdMVQZZrmeeO8\nCWG5uQVBXWlzuYp8qsnLK6jWcwMAAABW48/iREiHtueff14TJ0687Jj09HQZhqGHHnrI/cxbVJRn\nq0jl5abKy02/+/RVWVm5TzWlpd7XWWluAAAAoCYJ6dAWHh6u8PBwj8d6GtYAAAAAIFDY9QEAAAAA\nLIzQBgAAAAAWRmgDAAAAAAsL6WfaPLFr165gtwAAAAAghLHSBgAAAAAWRmgDAAAAAAsjtAEAAACA\nhRHaAAAAAMDCCG0AAAAAYGGENgAAAACwMEIbAAAAAFgYoQ0AAAAALIzQBgAAAAAWRmgDAAAAAAsj\ntAEAAACAhRHaAAAAAMDCCG0AAAAAYGGENgAAAACwMEIbAAAAAFgYoQ0AAAAALCws2A0AOKukpERO\nZ4bXdQ5HmiIiIiqhIwAAAFgBoQ2wCKczQ4+Of0bR8Yke1xS68vTaC88pPb1zJXYGAACAYCK0ARYS\nHZ+ouKS6wW4DAAAAFsIzbQAAAABgYYQ2AAAAALAwQhsAAAAAWBihDQAAAAAsjNAGAAAAABZGaAMA\nAAAACyO0AQAAAICFcU4bUEOUlJTI6czwqsbhSFNEREQldQQAAIBAILQBNYTTmaERE55XdEKSR+ML\n83M18w8TlZ7euZI7AwAAgD8IbUANEp2QpLikel7X+bJKJ7FSBwAAUBUIbQDkdGbotxMne7xKJ51d\nqZvx/O9ZqQMAAKhkhDYAkv6zSle7frDbAAAAwI8Q2gD4jU1QAAAAKg+hDYDfnM4M/fbZqYpJqO3R\n+IL8E5rx7FhurQQAAPAAoQ1AQMQk1FZcnQbBbgMAAKDG4XBtAAAAALAwQhsAAAAAWBihDQAAAAAs\njNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAALCwsGA3YCWff/65\n3nvvPW3btk25ubmKiIhQs2bN1KdPHw0aNEhJSUnBbhEAAABAiCG0SSorK9OYMWP0z3/+U4ZhuL9e\nWlqqnTt3aseOHVqyZIlee+01dezYMYidAgAAAAg13B4p6Y9//KM7sN1www1avHix/v3vf+ujjz7S\nU089pejoaJ04cULDhw9XdnZ2sNsFAAAAEEJCfqUtOztbCxculGEY6tu3r6ZNm+Z+LyEhQa1atVL3\n7t3Vv39/5efn64033tCECROC2DGAikpKSuR0ZnhV43CkKSIiopI6AgAACKyQD22rV69WaWmpDMPQ\nyJEjLzqmXbt2uuGGG7RixQp99tlnhDbAQpzODP3uD39SdGJdj8YX5h3Xnyc8ofT0zpXcGQAAQGCE\nfGjLzs5WVFSUYmNj1bBhw0uOa9asmXs8AGuJTqyr+LrJwW4DAACgUoR8aBs5cqRGjhypgoKCy447\ncOCAJCk+Pr4q2gJQDXBrJgAAqAohH9rOiYmJueR72dnZ+vTTT2UYhjp35pYqAGc5nRl6bOpMxSTV\n92h8Qe4xvTp2hNLTO/sU+CRCHwAAoYjQ5oGnn35aZ86ckWEYGjhwYLDbAWAhMUn1FV+vsdd1TmeG\nRr74umKSGnhcU5B7VNNHP8zzeAAAhBhC2xW88MIL+vzzz2UYhn7961+ra9euwW4JQA0Rk9RA8fWb\nBLsNAABgcZzTdhlTpkzRggULZBiGWrdureeeey7YLQEAAAAIMay0XcQPP/yg8ePH66OPPpJhGGrV\nqpX++te/KioqKtitAQAAAAgxhLYfyc/P16OPPqqNGzfKMAy1a9dOb7zxhhITE73+LJvNkM1mVEKX\nnrHbvV9ItdttCgvzfwE2mHNXV75cs3N1YWE2v655MOf2V3Wd299rDgAAQgehrYKDBw/qwQcf1IED\nB2QYhnr37q3p06f7vMKWlBQjwwheaIuP977v+PgoJSZeeifN6jB3deXLNTtXl5gY49c1D+bc/qqu\nc/t7zQEAQOggtP3Hnj17NGTIEOXm5sowDN1999165plnZLP5/jfaubkFQV1pc7mKfKrJy7v8mXVW\nn7u68uWanavLyyvw65oHc25/Vde5/b3mAACgevHnL10JbZIOHTqk+++/3x3YRo4cqWHDhvn9ueXl\npsrLzQB06JuysnKfakpLva+z0tzVlS/X7FxdaWm5X9c8mHP7q7rO7e81BwAAoSPkQ1tpaalGjhyp\nnJwcGYah8ePHa9CgQcFuCwAAAAAkEdr0zjvvyOl0yjAM/fKXv9Sdd96pwsLCy9ZER0dXUXcAAAAA\nQl3Ih7b58+dLkkzT1LJly7Rs2bIr1uzatauy2wKASlNSUiKnM8PrOocjTREREZXQEQAAuJyQDm15\neXnKzMz0aofHYO4GCQCB4HRm6PE//VUxdRp6XFOQc0SvPPGA0tM7V2JnAADgYkI6tCUmJmrnzp3B\nbgMAqlxMnYZKaNAs2G0AAAAPcEIrAAAAAFhYSK+0AQCqF1+ex+NZPABAdUdoAwBUG05nhp6Y+bZi\n6zb2aPzp45n604gBPIsHAKjWCG0AgGoltm5jJSS3CHYbAABUGZ5pAwAAAAALI7QBAAAAgIUR2gAA\nAADAwghtAAAAAGBhhDYAAAAAsDB2jwQAoJL5cr6cxBlzAICzCG0AAFQypzNDo974h2LrN/W45vSx\ng3rpIXHGHADAv9A2c+ZMSdKtt96q5s2be1y3fft2zZs3T8XFxZo1a5Y/LQAAUC3E1m+qWo2vDnYb\nAIBqyO/QZhiG2rRp41VoO3LkiJYtW6aoqCh/pgcAAACAGi8oG5Hs2LFDkmSaZjCmBwAAAIBqw6OV\ntkWLFmnVqlWXfH/69OmaP3/+FT/HNE3l5+drz549MgxDTZo08bxTAADgNTZBAYDqz6PQdsstt2jm\nzJnKz8+/4D3TNLV3716PJ6y4unbfffd5XAcAALzndGZo/F8/UHwDzzdBcR09qBceOLsJii+hj8AH\nAIHlUWhLSkrS+PHjNX369PO+fvjwYRmGocTEREVGRl7xc2w2m6KiolS/fn3deuut6tevn29dAwAA\nj8U3aKqkJtf4VOt0ZujpNz9UfINmHo13HT2gSff7HvgkQh8A/JjHG5H07dtXffv2Pe9rqampkqRJ\nkybp+uuvD2xnAADAEuIbNFPtpt6HPqczQ8/M/0i1vFjlO3n0oJ4bwiofAFTk1+6RycnJksQukAAA\n4KJqNWiq2s1a+1TrdGbo+YX/VK2Gnq3ynTxyQBMHcbYdgJrHr9C2Zs2aQPUBAABwgVoNm6mOj6EP\nAGqKoGz5DwAAAADwjF8rbRXt2bNHTqdTOTk5OnPmjMdnsI0YMSJQLQAAAABAjeN3aNu/f7/GjRun\nrVu3+lRPaAMAAPgvNmAB8GN+hbaTJ09q6NChOnLkiMcraxUZhuHP9AAAADWO05mhPy5ZqdqNUjwa\nfyJrv566m2MWgJrMr9C2cOFC91ltdevW1T333KM2bdooNjaWQAYAAOCj2o1S1KBFG6/rnM4MvfK/\nq1S7cXOPa05kfq/Hxa6bgJX5FdpWrVol6ezh20uXLlWdOnUC0hQAAAB8U7txczX0IfBJ/t2aySof\nUHn8Cm1ZWVkyDEMDBgwgsAEAAFRzTmeGXn3vE9X1cKXueOb3ekxnV+mczgzNXLpadZt4vsp3/ND3\nGiFW+YAr8Su02e12SVJKSkogegEAAECQ1W3cXA1b+rZSV7dJcyW3bBvgjgD4dU5by5YtJZ1dcQMA\nAAAABJ5foe3WW2+VaZp67733VFpaGqieAAAAAAD/4Vdou/fee5WamqqDBw9q9OjRKiwsDFRfAAAA\nAAB5+Ezb+++/f8n3brnlFu3Zs0fLly/X+vXr1bt3b1199dWKi4tTeHj4FT/79ttv97xbAAAAAAgx\nHoW2sWPHenTu2okTJy4b8H7MMAxCGwAAAABchse7R5qmGdBxAAAAgBX4cz4dUBU8Cm1Tpkyp7D4A\nAACAoHA6MzT3489Uv2kLj8YfO7hPv9HZ8+U4VBxVwaPQ1q9fv8ruAwAAAAia+k1bqMnVDq/rnM4M\n/W3552rQtKXHNUcPfqeh4lBxeM6vw7UBAACAUNegaUs1vcb7wAd4yq8t/wEAAAAAlcuvlbZx48b5\nVGe32xUREaH4+Hg1bNhQbdu2VVpamj+tAAAAAECN5FdoW7p0qUdHAXiiWbNmmjx5sjp35t5eAAAA\n4ErYBCV0+BXaUlJSZBiGjh49qqKiovPeS0hIUGRkpIqLi+VyudxHARiGcdFjAfbv36/Bgwdr1qxZ\n6tOnjz9tAQAAADWe05mhhZ98qeRmnm+CcvjAdxokNkGpbvwKbStWrNCyZcs0evRoSVJ6erqGDh2q\n7t27Kz4+3j3u9OnT2rx5sxYuXKgvv/xSYWFheu6559StWzfl5uZq9erVWrRokYqKijR69GgtX75c\nSUlJ/n1nAAAAQA2X3KylmrVuF+w2UMn82ohk3759GjdunMrKynT//fdr8eLF+sUvfnFeYJOk2NhY\n9e7dW3PmzNETTzyh0tJSTZ48WTabTR06dNCTTz6pOXPmKCwsTC6XSx9++KFf3xQAAAAA1BR+hba5\nc+fqzJkzat++vcaMGeNRzUMPPaRu3bqpsLBQf/nLX9xf79Kli2644QaZpqlVq1b50xYAAAAA1Bh+\nhbavv/5ahmGob9++XtXdeuutkqQvv/zyvK937dpVknT48GF/2vLJ7t27NWrUKPXp00ft2rXTT3/6\nUw0fPvyCHgEAAACgKvn1TFtOTo4kKTEx0au6uLg4SdKJEyfO+/q559h+/PXK9q9//UuPPfaYSktL\n3bthnjhxQp999pk+++wzDR48WOPHj6/SngAAAABcKBR3zfQrtCUkJCg3N1e7du3SLbfc4nHdrl27\n3PUV5efnS5Kuuuoqf9ryys6dO/Xkk0+qrKxMHTp00KhRo3T11VcrMzNTs2fP1ieffKKFCxcqJSVF\nAwYMqLK+AAAAAFzI6czQPz7/txq3aOVxTea+vZKq766ZfoW2Dh06aM2aNXrnnXc0YMAANWjQ4Io1\nx44d07vvvivDMNS+ffvz3tu2bZskqUmTJv605ZXp06eruLhYzZo107x58xQVFSXpbKCcMWOGRo4c\nqRUrVmjGjBm6/fbbFR0dXWW9AQAAALhQ4xat1LJN+ysPrCH8Cm333nuv1qxZo1OnTmngwIF6+eWX\n1aFDh0uOdzqdeuqpp5Sfny/DMHT33Xe739u+fbuWLVsmwzDUvXt3f9ry2L59+/T555/LMAw9/PDD\n7sBW0dixY7Vq1SqdPHlSq1at0u23314lvQEAAAAIPF9urwz2rZV+hbZrr71WAwcO1KJFi5SVlaX+\n/fsrLS1NXbt2VXJysiIjI1VUVKSsrCxt3rxZ27dvd9fedttt7kO0//a3v+nll19WWVmZwsLCdM89\n9/j3XXnoiy++kHT2wO+f/exnFx3ToEEDtWnTRjt27NC//vUvQhsAAABQjTmdGfrgy/Vq3OJqj8Zn\n7tsjKbi3VvoV2iRpwoQJioiI0IIFC1RaWqqMjAxlZFw8uZqmKZvNpkGDBmns2LHur2/fvl1lZWWS\npCeffFLNmzf3ty2PnHu2Ljk5WbVq1brkuLZt28rpdMrpdFZJXwAAAAAqT+MWV6tV2+pze6XfoU2S\nRo8erTvvvFNvvPGGvvjiC+Xl5V0w5qqrrtL111+v+++/X2lpaee9Fx4erhtvvFH9+/dXr169AtGS\nR7KysiRJjRs3vuy45ORkSdLRo0dVXl4um82vkxIAAAAAwGMBCW2S1LJlS02bNk2maWrPnj3Kzs7W\nyZMnFRkZqfr16ys1NVXh4eEXrX3ppZcC1YZX8vLyZBiG4uPjLzvu3BEFpmnK5XJddlUOAAAAAAIp\nYKHtHMMwdM011+iaa64J9EcH3JkzZyRJkZGRlx1X8QiCczUAAAAAUBVC+j4/bnMEAAAAYHUerbTN\nnDnT/XrEiBEX/bqvKn5eVTt35tqVVs8qvn+lVTkAAAAACCSPQ5thGJIuDG3nvu6rYIa2uLg4maap\n06dPX3acy+WSJNntdiUkJHj8+TabodLSH/R//+fdORDt2p09B6KkpMTr2or1drtNxYUFHtcVFxbI\nbrcpLMwWkLmLTp/yuK7o9KmAze1LfaCuuT9z2+02Fbou3MTncgpdee7rZrfbVJif63ltfq7PtRer\nL8g/4XFtQf6JgP6sFeYd97zvvOMBnbsg95jHdQW5x86/ZrlHvZq3IPeoX72f13fOEe/mzjkSkLkD\ncc1PH8/0uO708UxL/G6x2206feygV7Wnjx2U3d4tIH/erqPeze06elB2e2f3z6rr6AEvag/Ibk93\n1570cu6TRw+eX3/E87lPHjkgu71D0P+8A/FzfiJrv8d1J7L2y25v475mJzK/92reE5nfy25v7a4/\n7kX98czvZe91zX9rD3k39/FD38ve/WpL/G45dnCfx3XHDu6TvWOK+/s+evA7r+Y9evA72ds3Dcg/\n34cPeDf34QPfyd6mcdCvub/fd+a+vV7VZu7bq54p9dx/Zue28fesdo+6Ne3p9+8WfximaZpXGpSa\nmnp2sGFo586dF3zd58l/9HlVbeLEiVqyZIlSUlK0YsWKS457+umn9fe//13Jyclas2aNx59vmqY2\nbtyou+/pr6ioaI9qiooKteTdd9S1a1dt2LBB99w7UJHRntVKUnFhod5dvEhdu3ZVSUmJtm3b5nGt\nJHXo0EERERFn5x50v6JiYj2uLSo4rXcXvhmQufvfP0zRsZffIKaiwtMuvfPmX9zX7d4HHvW4vvC0\nS4v/+pq7dsCDv1NUnOfhvOhUvt6e8+f/1g97XFHxnm1WU+Q6qbf/8orP10z673Xz55oHc+4NGzZo\n0OPPKjqxjse1hXk5WvjKswH5WRs06gXFJNbzuLYgL1sLXxrv99z+XvMNGzZoyO9fUWxSQ4/qTuce\n0fzJjwcmHg5gAAAgAElEQVTkZ23Dhg36f8+8ppg6yR7VFeQc1rznHnX/M3L/c7MVU6eRx/MW5GTp\nzWeGB+TPe+jkvym2bhOPa08fP6S//X6ou/ehU+Yrrl5Tj2pPZR/U38YNCdg1f+iltxRX38O5jx3U\nG6PuC/nfLU/OXKLEhike1+Yd2a+XR9zt/vMePevvSkz2rD7v8H69+Mhd7tpxr7+npEaez52btV9T\nHr4z6L9bgv177YV5H6pekxYe1WUf2qfx/6+v+5pPW/BPj2vP1Y8Z/KugX/MNGzZo+jvL1aBpS4/q\njh78TiP7/zJgv1tm/X2lklNaeVR3eP9ePXLXTe5rPvu9VWrkYa0kZe3fq+F33uiun7N0tcf1Wfv3\n6sF+NwT999qGDRu04J+fqkkLz/fvOLRvtwb/6jp17drV25bdPFppW7BggVdfry5at24tScrMzFRB\nQYFiYmIuOs7pdMowDLVt29arz8/NLZDLVaSoqGjFxHoeflyuIuXlna2NjI5WbGycV/Oeq5ekVq28\n67mg4AcVFPxwtu+YWMXGex5eAjl3dGy8YhMSfZrbXV8ryafaqLgExdWq7fPcUfG1FOdFAPHnmkn/\nvW6+1PtTG6i5Xa4iRSfWUXwdz8LHOYH6WYtJrKf4ep4HiEDN7UttxXqXq0ixSQ0V38Czf4mXAvez\n5nIVKaZOshK8+Jfhiv+MxNRppIRk787jDNSfd2zdJkpo5Nm/GP14bperSHH1miqhsef/ghLIax5X\nv6kSm3h2EGwg5/al3iq/WxIbpqhuSmuv6iv+eScmp6heiud/QV2xNqlRiuo39+4vt63wuyWYc7tc\nRarXpIUaefEZFa95vSYt1Phq7+a3wjV3uYrUoGlLNWvdzuPaQP5uSU5ppZRU7+d2uYrUKKWVmqd6\nt4L04/oWbTyvt8LvNZerSE1aXKOrHd6d8eZyFXk1/sc8Cm3dunXz6uvVRe/evSVJZWVl+vzzz3XL\nLbdcMObo0aPuQ7ivvfZarz6/vNxUWVm5132VlZWrtLTcp9qK9f6oznMH85r7M3eoqs4/a8EUzJ+1\nUP29Vl2veaiqzv9fEqpC9ZpX198t1fl3qj/8+b79EdLbJzZp0kSdO3eWaZr685//fNFn26ZMmaLy\n8nIlJibqtttuC0KXAAAAAEJZwM9py8nJkdPp1IkTJ1RQUKBBgwZJko4cOaKoqCjLHUw9btw43X33\n3dq/f78GDBigMWPGqG3btjpy5IhmzZql1atXyzAM/fa3v2XnSAAAACDEHdq32+vxHRv6d4diwELb\n8uXLNXfuXO3YseO8r58Lbe+9955mz56tfv366cknn7RMeGvXrp0mT56sp59+Wnv27NEDDzxw3vuG\nYej+++/XvffeG6QOAQAAAFiBw+H9LpAdG3bzqa4iv0NbaWmpxowZo2XLlkk6u2PiORWPA8jMzFRp\naan+93//V1999ZUWLFigJk0838GrMvXr10/t2rXTX//6V61fv145OTmKjo5WWlqa7rvvPl133XXB\nbhEAAABAkEVERCg9vXOVz+t3aHv66af18ccfS5ISEhJ0ww03yDRN/eMf/zhvXNu2bbV69WqdPn1a\nR44c0fDhw7V06VJFRET420JAXH311Zo6dWqw2wAAAACA8/i1EcmGDRu0dOlSGYah66+/Xp988okm\nT56sn//85xeMHTx4sNasWaNevXpJkvbt26elS5f6Mz0AAAAA1Hh+hbYlS5ZIkho3bqxXXnlF8fGX\nP8w4Pj5es2fPVnLy2QNZly9f7s/0AAAAAFDj+XV75KZNm2QYhu644w6Pb3OMiIjQXXfdpVdffVXf\nfvutP9MDAAAACJKs/Xu9H9+ivk/1Wfv3Sil1vZqvJvErtOXk5EiSUlJSvKpr1qyZJOnUqVP+TA8A\nAAAgCByONN3jbVGL+u5dFL3eTTGlrt87MFZnfoW2qKgo/fDDDxc9lPpy8vLyJEmxsbH+TA8AAAAg\nCPzdRTFYuzBWV34903Zuxezrr7/2qm7VqlWSvF+hAwAAAIBQ41do+9nPfibTNLVq1SqtX7/eo5ol\nS5Zo/fr1MgxDvXv39md6AAAAAKjx/AptgwYNUq1atVReXq7hw4frrbfeUkFBwUXHZmVladKkSXr2\n2Wclnb01csCAAf5MDwAAAAA1nl/PtMXFxenll1/WsGHDVFxcrD/84Q+aMmWKoqKi3GP69++v7Oxs\nHTlyRJJkmqbsdrteeOEF1apVy7/uAQAAAPjssBc7OB7ev1dq1aASu8Gl+BXaJOknP/mJ5s6dqzFj\nxujYsWMqLS3V6dOnZRiGJGnbtm2SzoY1SUpISNDkyZN1ww03+Ds1AAAAAB85HGm615uCVg1CegfH\nYPI7tElSjx49tHLlSn3wwQdauXKltm/fft6OkhEREXI4HLr++ut19913X/EQbgAAACBUHD34nXdj\n2zQKyLzs4Fh9eBTaVq9ere7duysuLu6SYyIjI3XPPffonnvOnthQUFCg06dPKyoqSnFxce6VNwAA\nAABnORxpGuJNQZtGrHaFII9C24gRI2S329WmTRv17NlTPXr0UJcuXXTVVVddsiYmJkYxMTEBaxQA\nAACoaVjtgic8vj2yrKxMTqdTTqdTc+fOVXh4uDp06KCePXuqZ8+eat++vex2e2X2CgAAAAAhx6PQ\nNnDgQG3evFnffvutysrKJEklJSXauHGjNm7cqBkzZig6OlpdunRxr8SlpqZWauMAAAAAEAo8Cm0T\nJkyQJBUWFmrr1q3avHmzNm3apG3btqmwsFDS2WfYvvjiC33xxReSpFq1aql79+7ulbimTZtW0rcA\nAAAAADWXV7tHRkdHq1evXurVq5ckqby8XDt37tSmTZu0efNmbd68WdnZ2ZKkvLw8rVy5UitXrpQk\nNWzY8LwQV7du3QB/KwAAAABQ8/i15b/NZpPD4ZDD4dDgwYMlSYcOHXKvxG3ZskV79+6VaZo6fPiw\nli5dqvfff1+S1KJFC/Xs2dO9igcAAAAAuFBAzmmrqEmTJmrSpIluu+02SdKpU6e0detWbdu2TRkZ\nGcrIyFBubq6+++477du3j9AGAAAAv2Uf2uf9+I7NKqkbILACHtoqOnPmjJxOp3bv3q3MzEwdP35c\nhYWFMgxDpmlW5tQAAAAIEQ5Hmh7ytqhjM847Q7UR0NBWXFysDRs26JtvvtGGDRvkdDpVWlrqfv9c\nUIuKilKnTp3Us2fPQE4PAACAasyb1bLsQ/ukTs0lcdYZaj6/QptpmsrIyNC6deu0du1abd26VT/8\n8IP7PfckYWFKS0tzb0LSsWNHhYeH+9c5AAAAagyHI00Pe1PQqTkrZQgZXoe2Q4cO6euvv9batWu1\nfv16uVwu93vngpphGGrdurU7pHXp0kUxMTGB6xoAAAA1CqtlwKV5FNpWrFihr7/+Wl9//bWysrLc\nX6+4mta4cWN3SOvRo4eSkpIC3y0AAAAAhBiPQtvIkSMv2Dykdu3a6tGjh3r06KGePXuqcePGldYk\nAAAAAIQqr26PtNvtuvHGG/XAAw+oXbt2ldUTAAAAAOA/vApt5eXlWrFihT799FN16tTJvcqWlsZD\noAAAAABQGTwKbU8//bTWrVun9evX69SpUyouLtbXX3+tdevW6ZVXXlF8fLy6d+/ufqYtJSWlktsG\nAAAAgNDgUWi77777dN9996m8vFwZGRlau3at1q1bpy1btqi0tFT5+fn65JNP9Mknn0iSGjZsqB49\neqhXr17q2bOnateuXanfBAAAQKDlHd7v5di27v+dm+V57X/Hp3pVAyB0eHV7pM1mU4cOHdShQwc9\n8sgjKioq0jfffOPeWXLPnj2SpMOHD2vp0qVaunSpJKlVq1bq1auXevXqpa5duyo6Ojrw3wkAAEAF\neUf2+zDeIensmWHj7vWmuq37zDCHI02j+3s1taRUzhwDcEl+Ha4dFRWlPn36qE+fPpKknJwcd4Bb\nt26djh07Jknas2eP9u7dqwULFshut6t9+/buVbjOnTmPAwAABJbDkaYJ93ld5Q5O/pwZxnljAALN\nr9D2Y3Xq1FHfvn3Vt29fSdJ3332ndevWaePGjdq0aZOOHz+u0tJSbdmyRVu2bNGsWbO0Y8eOQLYA\nAABAcAJQowQ0tP1Yy5Yt1bJlSw0cOFCZmZlatWqV3n77bWVlZZ135hsAAAAA4OIqJbTl5uZq69at\n2rZtm7Zv364dO3bI5XK53z8X2GJjYytjegAAAACoMfwObWVlZdq5c6e2bt3qDmqZmZnu9yuuqMXE\nxKhz587q1q2bunfvLofD4e/0AAAAAFCjeR3ajh07pm3btmnLli3atm2bduzYoTNnzrjfrxjSoqKi\n3CGtR48ecjgcstvtgekcAAAAAEKAR6HtzTffdK+indsR8pwfh7ROnTq5V9LS0tIIaQAABMCpYwe9\nHNup8poBAFQpj0LbtGnTZBiGpPNDWmRkpNLT090hrX379goLq9S9TQAACDkOR5qm/cabik6c+QUA\nNYjHCcs0TV111VXq2LGjO6R16NBB4eHhldkfAAAhj+3rASC0eRTaRowY4Q5pERERld0TAACWdCrb\ni1sUsw9K6lZ5zQAAQobHoQ0AgFDmcKTp5eHeVHTjFkUAQEDwABoAAB7gFkUAQLDYgt0AAAAAAODS\nWGkDAISM08cPVep4AAAqA6FN0t69e7VgwQJ98803Onr0qCSpfv366t69uwYPHqxWrVoFuUMAgL8c\njjS9/IhvdQAABFPIh7aFCxdq2rRpKi0tdZ9FJ0kHDx7UgQMH9I9//EMTJkxQ//79g9glAMBfPJMG\nAKiuQvqZtjVr1mjy5MkqKytTamqqXnvtNa1du1arV6/Wyy+/rEaNGqm0tFTPP/+8vvjii2C3CwAA\nACAEhfRK25/+9CcZhqHmzZtr8eLFioqKcr/XqFEj/fSnP9Udd9yhrKwsvfTSS+rdu3cQuwUAAAAQ\nikI2tH333Xfau3evDMPQsGHDzgts58THx2vo0KF6/vnntXfvXh05ckQNGzYMQrcAYC0FOYd9HluQ\nk+XlXN6NBwCgpgnZ0JaZmam4uDgVFBSoffv2lxzXrFkz9+vs7GxCG4CQ53Ck6ZWR/8/rmnP//aff\nDfJpTgAAQlXIhrY+ffpow4YNKioqUmRk5CXHHThwwP06Pj6+KloDAEvzZ0MPNgMBAMB7IRvazrnY\nbZHnmKapJUuWSJJq166t5s2bV1VbAHBFp3OPVMpYAABgLSEf2i5n7ty52rVrlwzDYMt/AJbicKRp\n+lMPeV0DAACqn2od2l5//XW9+uqrXtX069dPU6ZMueK4lStXavr06ZKk5s2b64EHHvCpRwCoDNxm\nCABA6KjWoU3SeQdiB2r88uXLNWrUKJWVlSkuLk4zZsy47G2UAAAAAFBZqnVoGzBggG6++WavauLi\n4i77/qJFi/TCCy+ovLxcsbGxeuONN9SyZUuf+rPZDNnt3p9fbrfbFBZm86m2Yr0/qvPcwbzm/swd\nqqrzzxoAAEBVqNahLSEhQQkJCQH5LNM0NXnyZC1atEiGYSgxMVFz5sxRu3btfP7MpKQYxcd7v0IX\nHx+lxETfaivW+6M6zx3Ma+7P3KGqOv+sAQAAVIVqHdoCpbi4WI8//rg+/fRTGYahpk2bas6cOWra\ntKlfn5ubWyCXq8jrOperSHl5vtVWrPdHdZ47mNfcn7lDVXX+WQMAAPCUP3/hG/KhraCgQPfff7+2\nb98uwzDUoUMHzZo1S0lJSX5/dnm5qbKycq/rysrKVVpa7lNtxXp/VOe5g3nN/Zk7VFXnnzUAAICq\nENIPZZSUlOjBBx90B7af//znWrBgQUACGwAAAAAEQkiHthdffFGbN2+WYRi66aabNGPGDEVERAS7\nLQAAAABwC9nbI3fv3q233nrL/QzbxIkTVVxcfNmayMhI2WwhnXMBAAAAVLGQDW3z58+XaZqSpAMH\nDqhXr15XrFm4cKG6du1a2a0BqEIFedmVOh4AAMBfIRvazj3H5ilvD/EGYH0OR5r+PP4xn+oAAACq\nSsiGto8++ijYLQAIsoiICKWndw52GwAAAJfFA1oAAAAAYGGENgAAAACwMEIbAAAAAFgYoQ0AAAAA\nLIzQBgAAAAAWRmgDAAAAAAsL2S3/AVhHYV5OpY4HAACozghtAILK4UjTnyeO8qkOAAAgFBDaAAQV\nB1wDAABcHs+0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAALAwQhsAAAAAWBihDQAAAAAsjNAG\nAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAALAwQhsAAAAAWBihDQAA\nAAAsjNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAALAwQhsAAAAA\nWBihDQAAAAAsjNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMLCgt0AUNMUuU5WylgAAACE\nJkIbEEAOR5pem/oHr2sAAACASyG0AQEUERGh9PTOwW4DAAAANQjPtAEAAACAhbHSBvxI0an8Sh0P\nAAAAeIPQBlTgcKTptRen+FQHAAAAVAZCG2qkwtMun8byTBoAAACshtCGGsfhSNOsP77odQ0AAABg\nRYS2S3jyySf18ccfq1u3blqwYEGw24EXWC0DAABATcLukRfx8ccf6+OPP5ZhGMFuBQAAAECII7T9\nyNGjR/X8888T2AAAAABYAqHtR8aOHav8fLZwBwAAAGANhLYK5s2bp3//+99q1aqVOnToINM0g90S\nAAAAgBBHaPuPPXv26JVXXlFYWJhefPFFhYeHB7slAAAAACC0SdIPP/ygUaNGqaSkRI888ojatm0b\n7JYAAAAAQBKhTZI0ffp07dq1S+3bt9fw4cOD3Q4AAAAAuIV8aNuwYYPefPNNRUVFadq0abLZQv6S\nAAAAALCQan249uuvv65XX33Vq5p+/fppypQpkqTTp09rzJgxMk1TTz75pFJSUiqhSwAAAADwXbUO\nbZK8Pk+t4vhJkybp8OHD6tWrlwYOHBjo1gAAAADAb9U6tA0YMEA333yzVzVxcXGSpBUrVuiDDz5Q\nQkKCe+UNAAAAAKymWoe2hIQEJSQkeF13/PhxPfPMMzIMQ+PGjVP9+vUroTvJZjNkt3v/jJzdblNY\nmM2n2or1/gjVuQEAAACrqdahzVdfffWV8vPzJUljx47V2LFjLzn2m2++UWpqqiRp6tSpuv322z2e\nJykpRvHxUV73Fx8fpcRE32or1vsjVOcGAAAArCYkQ5vk2bNwpmm6x3n77Jwk5eYWyOUq8rrO5SpS\nXp5vtRXr/RGqcwMAAACVwZ/FhZAMbbfddtsVn4X7zW9+o02bNqlz586aO3euTNPUVVdd5dU85eWm\nysrKve6vrKxcpaXlPtVWrPdHqM4NAAAAWE1IhjabzaaoqMvfgnfuvDabzabIyMiqaAsAAAAALsCu\nDZfhyy2RAAAAABBIhLbLME0z2C0AAAAACHGEtsswDIPVNgAAAABBFZLPtHli4cKFwW4BAAAAAAht\nsKbC065KHQ8AAABUF4Q2WI7DkabX//Qnn+oAAACAmobQBsuJiIhQenrnYLcBAAAAWAIbkQAAAACA\nhRHaAAAAAMDCCG0AAAAAYGGENgAAAACwMEIbAAAAAFgYoQ0AAAAALIzQBgAAAAAWRmgDAAAAAAsj\ntAEAAACAhRHaAAAAAMDCCG0AAAAAYGGENgAAAACwsLBgNwDrKio4XanjAQAAAFwZoQ0X5XCkafaf\nZ/pUBwAAACBwCG24qIiICKWndw52GwAAAEDII7RZXHFhYaWOBwAAAGBthDYLczjSNHvWX3yqAwAA\nAFAzENosjFsUAQAAALDlPwAAAABYGKENAAAAACyM0AYAAAAAFkZoAwAAAAALI7QBAAAAgIWxe2QV\nKCry/Ow0b8YCAAAAqPkM0zTNYDdRUx0/fkolJSVyOjO8qnM40hQREVFJXQEAAACoanXrxvlcS2ir\nRMePnwp2CwAAAAAswJ/QxjNtAAAAAGBhhDYAAAAAsDBCGwAAAABYGKENAAAAACyM0AYAAAAAFkZo\nAwAAAAALI7QBAAAAgIUR2gAAAADAwghtAAAAAGBhhDYAAAAAsDBCGwAAAABYGKENAAAAACyM0AYA\nAAAAFkZoAwAAAAALI7QBAAAAgIWFBbsBKzBNU0uXLtVHH32kb7/9Vi6XS0lJSeratauGDh0qh8MR\n7BYBAAAAhCjDNE0z2E0Ek8vl0rBhw7RlyxYZhnHee6Zpym63a+LEibrnnnu8/uzjx08Fqk0AAAAA\n1VjdunE+14Z8aBswYIA2b94sm82mIUOG6K677lJsbKy2bt2qadOmKSsrS3a7Xe+++67atWvn1WcT\n2gAAAABI/oW2kH6m7d1339XmzZtlGIaee+45jRkzRi1atFC9evV04403avHixYqNjVV5ebnmzp0b\n7HYBAAAAhKCQDm2LFi2SYRi69tprddddd13wfr169XTLLbfIZrNp9+7dQegQAAAAQKgL2dsj9+7d\nq1/96lcyDEPz589Xt27dLjqutLRUdrv9gufdPMHtkQAAAAAkbo/0yfbt2yVJ4eHh6tSp03nvlZaW\nul+HhYX5FNgAAAAAIBBCdsv/PXv2SJKSk5MVFhamXbt2ae7cuVq7dq3y8vIUGxurHj16aNiwYUpL\nSwtytwAAAABCVciutGVnZ0uSatWqpaVLl+quu+7Sxx9/rJMnT8owDBUUFGj16tXq37+/Fi9eHORu\nAQAAAISqar3S9vrrr+vVV1/1qqZfv36aMmWKCgoKJEkHDx7U008/rfr162v06NH6yU9+orCwMK1b\nt05Tp07VgQMHNGnSJDVr1ky9evWqjG8DAAAAAC6p2q+0GYbh9X8kqbi4WJKUm5urWrVq6Z133tFN\nN92k2NhYRUZG6rrrrtPixYtVr149maapF198MZjfJgAAAIAQVa1X2gYMGKCbb77Zq5q4uLO7tkRG\nRko6G/oeeugh1a1b94KxSUlJGjp0qKZOnapvv/1Whw4dUpMmTfxvHAAAAAA8VK1DW0JCghISEnyq\njYmJcb++1Hb/ktS1a1f3671793oV2mw2QzYbO08CAAAA8F21Dm3+aNy4sfv1VVdddclxsbGx7tfn\nbqn0VO3asVceBAAAAACXUe2fafNVmzZt3K8PHTp0yXE5OTnu1/Xr16/UngAAAADgx0I2tPXq1Uvh\n4eGSpJUrV15y3FdffSXp7DNwqampVdIbAAAAAJwTsqEtPj5eN998s0zT1AcffKCNGzdeMObgwYNa\ntGiRDMPQTTfdpOjo6CB0CgAAACCUGaZpmsFuIlhycnL061//Wnl5eYqMjNQjjzyim2++WbGxsVq7\ndq1eeuklZWdnKyEhQR999JHq1asX7JYBAAAAhJiQDm2StGfPHg0bNkxHjhzRjy+FYRhKTEzUjBkz\n1Llz5yB1CAAAACCUhXxok87uCrlw4UKtWrVK+/fvV1lZmRo1aqTrr79e991330XPcAMAAACAqkBo\nAwAAAAALC9mNSAAAAACgOiC0AQAAAICFEdoAAAAAwMIIbahShw8f1uHDh4PdBgAAAFBtsBFJFSgv\nL5fL5dKZM2ckSZGRkUpISAj4PNnZ2XrjjTf02WefKTs7W/Hx8ercubMGDhyorl27Xra2sLBQnTp1\nks1m044dOy479uTJk8rMzFRkZKRSUlIUFvb/2zvzuCrK74+/5wLKIu654IKauwjmkuZeaioKbuW+\nVGqSae7mkpZ+TdP8irtlWgrhgpqoX3cUNZdKQcS1XBFXEhRENoH5/cFrpnvhAhewX2rn/XrxEu/M\nmfPMMPcz58zzPOextriNNWvWxGAwEBwcjJ2dncV2jx8/5ty5c0RHR2NnZ0elSpWoUqWKxfYAT548\nISkpieLFiwNw8uRJHBwcqF27dq6OkxeSkpK4efMmycnJODs7U6hQoSzbeP/+feLi4nj69Ck2NjY4\nODjwyiuvULhw4b+9nYKQE48fP+bChQvcunUrk64VLVoUJycnatas+Uzv15SUFEJDQ3Vdq1evXpbf\nIWNSU1PZsWMHAF27djW7z/Xr1zl06BC3bt2iYMGCuLi48NZbb2Fra5urNi5duhQALy+vHDUxOjqa\nXbt2cebMGaKjo7G3t6dSpUq0bNkyk1YnJCSY1crk5GSCg4O5evUqiYmJlC5dmv3791OmTBk++eQT\ni65Pfnjy5Am7du3i2rVrPH36lCpVqtCuXTu92rL2N/v999+5d++eiabZ29vzyiuvULlyZVxdXSlW\nrNjf2lZByI6XTdPg2ehabjQNLNe13GhavXr1WL58OY6Ojn+7ruWkafDP65okbX8D8fHx7Nu3jwMH\nDnD+/Hnu3buXaQ04KysrSpUqRe3atWnRogVdunTJdZBgTGhoKF5eXsTExJj4UhQFAA8PD2bMmJFl\noqQlbQDbtm3D2tqaypUrYzD81RkbGhrKvHnzOH36tP6Zg4MD3bp1Y+TIkRYJWs2aNVEUhZCQEOzs\n7PDz8wOgd+/eWFlZZdr/9u3bzJs3j8DAQNLS0ky2lStXjsGDB9OlSxcCAgK4cOECs2bNMtnnwYMH\nrFy5kn379nH//n0ArK2tcXNz49SpUyiKwocffsiYMWNybHtWREZGEhYWhpWVFXXr1qVkyZL6tujo\naBYsWEBAQACpqalA+t++devWTJgwAWdnZ27evMmaNWs4cuQIt2/fztJP8eLFcXV15e2336ZTp04U\nKFAgz20WhNyyc+dO/P39OXXqVKbvYkYURcHV1ZX333+f9u3b58vvxo0b8fb2JiYmRv/MysoKDw8P\nxo4dm+2SLHFxcTRo0ABFURgyZAjNmjXjjTfe0LfPnj0bPz+/TOdTsmRJZsyYwVtvvWVxOzVtq1Wr\nFlZWVvj5+Zn9jvr4+ODt7U1iYqLZ49StW5cvv/yS8PBwvv32W27dusWJEydM9tm8eTMLFy4kKirK\n5OkmSeIAACAASURBVHPtPCpWrMg333zDq6++anH7jYmNjWXDhg2cOXMGKysr6tevT+/evfVn1P79\n+/nss8+IjY01sStYsCDDhw8nJSWFtWvXZtpuDoPBQP369Rk8eDCtW7c22SbBtHkkmH42wfSLqGnx\n8fG89tprKIrCe++9h7W19d+ma8bx2oABA1AUJV+61rlzZ3bs2JErTYN0XTMYDLz66qssWrQoT7qW\nH00bOXIkAwcO5LvvvnsmupYfJGl7xqxbt44lS5bw6NEjgEzJWka0pKpYsWKMHDmSPn365NpndHQ0\nHh4eREVFYW1tTdu2bXF2diY8PJygoCCSkpJQFIUaNWqwevVqSpQokekYmhAAeqJWrlw5ZsyYQbNm\nzQgODmbIkCEkJibq56T9qygKRYoUoWvXrjg6Ombb1qVLl+qJko2NDUuWLEFRFIYNG5YpcTpz5gwf\nfvghsbGx2V5HGxsbUlJSsLa25uzZs/rnoaGhfPzxx0RHR5u11z4zGAw0btyYuXPnUrp06Wzbb0xy\ncjIzZ87kp59+0o9lY2PD8OHD8fLyIjo6moEDB3L16lWzC7c7OjrSoUMHtm3bRnJyco73imYHULp0\naWbMmEGrVq1MtkuQYx4JcvIe5JQrV46pU6cSFhZm0T1qjKIouLm5sWLFijy9dVy0aBHffPONWb+K\nolCsWDEWLFhAkyZNMm2PiIhg2LBhXL16FfhL17p27crs2bP55ptvWLRoUZa+rays+Prrr3F3d7eo\nrVqAo6qqyYup7M7H2tqaYsWK8fTpU/2ZoX2ekpKit/vcuXN6+729vVm5cmW2mgZQoEABPv30U/r3\n729R+zXCwsL46KOPiI6OznR+Pj4+XLp0iffff19vX9GiRYH0ERjGzwRzKIpC4cKFcXBw4OHDhyQk\nJJhs69ixI1999RX79++XYDobJJjOXzDt4uJCTEwM4eHhL5SmAVy+fJnOnTvr56Lxd+iadp+dPn2a\nevXq5UvXjLUhN5qW0dbOzo5x48blStfyo2kaxYoVM9E4YyzVtWfxol2StmfI7Nmz8fX1RVVVDAYD\ntWrVonbt2jg5OeHo6EjBggWB9KFysbGx3L17l/Pnz3Pp0iXS0tJQFIX333+fiRMn5srvokWLWLFi\nBfb29vj4+ODi4qJvi4yMZNq0aRw+fBhFUahatSo+Pj6ZxGbq1Kls3rwZMH3gFihQgB9//JHPP/+c\nixcvUrBgQTw9PalTpw6ff/55prYYi4g5Mj7UtYeXoihcunRJ3+/Ro0e4u7vrX7LWrVvTpk0bnJyc\nePr0KVeuXCEgIIDLly/rNpUrV2b79u0UKFCAyMhIPD09efToEQaDgVatWvH6669TqFAhHjx4wLFj\nxzh58qRJux0cHBg3bhy9e/fOMugwPo8hQ4Zw/PhxswnZ3LlzCQkJYcOGDdjZ2dG7d28aN24MwKlT\np1i3bh1PnjzR9y9fvjxNmzalWLFixMbG8ttvv3H16lXKlCnD1KlTSUlJ4dKlSxw7doxz584B6eI7\nZ84cPD095Y1hDkiQk7cgR1VVk+9s06ZNadOmDbVq1aJcuXIUKlRI95uYmMjjx4+5c+cOFy5c4ODB\ngxw/fhxFUahSpQqbN2/O1ZDo0NBQ/bvo6urK8OHD9ZdR69ev59ChQ0D6ixJvb2/atm2r2yYnJ9Ol\nSxeuX7+ut79QoUI8efIERVEYO3Ysq1atIiYmhtdff53Ro0fj4uJCYmIiR44cYeLEiaSmpqIoCmXK\nlDE7CiAjt2/fRlEU/V51cnLCYDCgKAqBgYGcPn2aPn366N/3CRMm0KpVK/25EB0dzfbt21m0aBHx\n8fH6Mfr06cPgwYOxsrLi2LFjDB48GIDq1aszcuRIGjVqRKFChYiKiqJVq1YmemQwGHBzc+Ozzz4z\neS5kRVRUFB4eHrruVqxYEWtra65fvw5A//79OX/+PCEhITRu3JjPPvuMatWqAfDHH3/Qt29fHj9+\nDECvXr3o1q0bxYsXJyYmhl9++YU1a9aQmJjI4sWLad68OeHh4Rw9epQtW7bow/KLFCmS44s6c0gw\nLcF0RswF0xn3e+ONN2jXrt1zr2mQrmuenp7699HBwQFFUSzStfbt2xMTE5MrXdM0rWzZsvooICcn\nJ6ysrAgMDASwSNeWLFnCunXrgPTvxkcffcTHH39skab9/PPPTJ06Vf97av9aqmv50bSrV6/y5Zdf\ncuzYMQDs7e354IMPaN68ea50TVEU2rdvz8KFC7NtqyVI0vaM+Pnnnxk6dCgAHTp0YNKkSZQpU8Yi\n23v37jFnzhz27t2LoigsX76cN99802Lf3bt35+LFi4wfP16/+TMye/ZsfHx8UBQFFxcXfHx8dLH5\n5ZdfeO+993Qx0x4sfn5+nDx5EicnJ+7cuUOxYsXw8fHRb+j27dsTHh4OZE7GLMX49vv999/13//7\n3//y3XffYW1tjbe3N+3atctkO2fOHNasWaP7XbBggf7AmzFjBuvXr8fBwYFvv/2Whg0bZrKvWbOm\n/lbczs6OhIQEvUdy3LhxtGjRIst2BwQEMGnSJBRFoVOnTvTp0wcbGxs2b96Mv78/Tk5OPHjwgIIF\nC+Lr60vNmjVN7Hfu3MnYsWMBaNmyJStXrsx07fz9/fniiy9wc3Nj3bp1+vZLly4xffp0wsLCKFiw\nIJUrV+b333+XICcbJMjJW5CjJQ/aNnd3d4vfGA4cOJBHjx5x+fJl0tLSKF++POXKlbP4XK9cuUJU\nVBT29va4uLjg6+trsn337t1MmTKFhIQErK2tWb58OS1btgTA19eXL7/8EgcHB+Li4lAUhYsXL7Jp\n0yY+//xzvUesUaNG/PDDD5mCF00bjM/dUjLaab5HjRrF3r17qVChAv7+/ll+5wYNGsQvv/wCpPcM\nG49AGDx4MMeOHaNu3br4+vpm6m3W7vPy5ctz8+ZNAD1x7NChA8OGDaNGjRpZtn3+/PmsWrUKR0dH\nFi1aRNOmTQEICQlh+PDhxMXFkZqaipubGz/++KNJr/WmTZuYNm0aVlZWpKam8s4772Qarn7//n36\n9OnDkydP2L59u8nIhlWrVvH111/r1+1FeUEAEky/SMH03LlzOXDggN7eDh065CqY9vT0fCaaVqdO\nHaysrFi7dq2+PTtNg790TYtbLl68CGCRrmnaYPwCNK+6ZjAYdN+W6Nrw4cM5ePAgBoOBtLQ0RowY\nwYgRI4CcNU1ru3bOlSpV4saNG7q25qRr+dE0SH8xPX36dAA6duxo9l7JTtfWrFnDV199haIorFix\nIt9DJSVpe0Z4eXlx6NAh2rVrx5IlS/J0jBEjRhAYGEjz5s1ZtWqVxXYNGjQgPj6eHTt2ULVq1Sz3\nmzNnDmvXrkVRFFq2bMmKFSswGAyMHTuWXbt26T2E2pcxJSWFHj168Pvvv6MoCrNmzaJHjx768RIS\nEpgzZw7+/v5A+pe6SZMmJiKUkYxz2jL+X8Pd3Z3r169nO9+sQ4cOhIeH4+rqypkzZ2jRogXfffcd\nAC1atODBgwdMmzaNvn37ZtkWrd0uLi6UKFGCI0eO6EJWu3Zthg0bxttvv53J9r333uPXX3+lc+fO\neqChMW3aNDZt2oSiKHz22Wf069cvk/348eP1oYFubm76NczI/PnzWb16NTNmzKBnz57650lJSbz7\n7rv63waQICcbJMjJW5DTqVMnrl69SqlSpYiMjMzVG8PatWvrPXV5eamTVZBgTEhICB9++CFxcXHY\n2dmxdu1aXF1d6dOnD6GhoYwdO5b//ve/JgHOhAkT2LFjB4qi8OOPP9KgQYNMx9WSby3AefPNN3N8\nsbF161aToMjT01MPAObMmUPz5s2Jiopi3rx5eHh4ZHmcZs2aERUVhaqq1K5dm61bt+rb6tWrR1JS\nEmvXruX111/PZKvpqbe3N6NHj+aVV15BVVUePHigX/tWrVoxbNgwfTi8MR4eHly5csWsbmlJmaIo\nfP/99yY94pB+/wUHBzNo0CDWrFlDxYoV2bdvXyYfO3bsYMKECQwaNIjJkyfrn3/33XfMnz8fyF4T\ns0KCaQmmM2IumNZecrdu3ZqgoKBcB9O1a9cmLS0tX5pmrP8ZdS0rTQN0XdNGbBjb5qRr3t7erFq1\nitTUVFRVxcHBIceRNpqmde7cme3btwN/6dqcOXMALNK1Zs2aER0dTd++ffHz86NWrVq6ruWkaWAa\nq1WpUoVPPvmEL7/80iJdy4+mQbqunTp1ClVVcXZ2NqtpkLWuAUyfPh1/f3/eeustli9fbtbeUiRp\ne0ZoN+7mzZupU6dOno5x4cIFunXrhr29vdmhh1kxdepUUlNTmT59Ovb29ibbMs4VMv5i9+zZkxkz\nZvDmm29y7949s0KwdetWJk+ejKIoHD9+3KzwHzp0iEmTJvHw4UMMBgO+vr5me7bA8qTNzc2N5OTk\nbBNRV1dXnj59yooVK/Dy8qJkyZIcPXqUlJQUXFxcsm2zcVvS0tIoWrQov/76K7t27WL+/PncuXNH\nFwNnZ2e6d+9Ox44dqVChAgCNGzcmNjaWLVu2ZKo+eenSJbp27YqiKBw5csTsEMFWrVoRGRlJWloa\nRYoU4bfffjPbxmvXruHu7k69evXYsGGDybZJkybpovrtt99mmt+WEz169ODChQukpaXh7OyMs7Oz\nxbaXLl0iMjISBwcHXnvtNaysrFi5cqW+XYKclyPIcXd3Jz4+nqCgIPbs2ZOrN4Znz55lwoQJ3Lhx\nQz/nnKrYGnPy5ElUVaVevXoUKFAgU0+b8X5DhgzRK8Nu3LiRd999l5iYGAICAujSpYvJPfbrr78y\naNAgFEXhzJkzWfYaBgYG8vHHHwPwyiuvMHPmzGyH4+Y0p83FxYXU1FQOHz5MqVKlsjyOtl9aWhqO\njo6cOnUKSJ8DqiX2WbVba0NQUBCtW7fG1taWo0ePsnz5cn788UeSk5NNdK1z58507NhRH6b72muv\nkZiYyP79+ylfvrzJse/cucNbb72l91hnvL8bNmzIkydP+N///kenTp2wtbUlNDQ0UxsfPHhA8+bN\nMyV1WjCdlpZGyZIl9RcMliLBtATT5sgYTGsvuYOCgli+fHmug+mzZ88yduxYvSe7XLlyFr8gyKhp\ngFldM6dpFSpUoEmTJsTExJi9zyzRteDgYMaNG8fdu3f1UV2WaFpISIg+lSEvuqbts3XrVrp27Uqh\nQoU4deqURZpm3I60tDTs7OwIDQ0lLi7OIl3Lj6bBX7pm7NscWeka/BUTlihRIte6lhHLa7UL2aIN\nP8p4U+SGsmXLAulzfTJm6tmhBa8zZ840eVApipIpaZs9ezZ3797l1KlTJsP4skKrKAlkWTihdevW\nrF+/ng4dOpCWlsbAgQMZNGgQY8aMyfPESxsbG5KTk7OdE1WwYEGePn2qd0Vr86qsra2xs7MjMTER\nBwcHi/wlJycD6T18bdu2xc/Pj7Vr13Lv3j1u3LiBt7c33t7e1K1bl7Zt2xIXFwdgdgissXBllTAa\nz3cynrSaEa0SpVZMwRhtDog2Zy+3XLx4UQ9WwsPDuXnzpsWBjnbPxcfHc+zYsUx2HTt2pHTp0nqQ\nM2rUKJMgZ9euXSYBrmbfs2dPTp48qQc5o0aNytSLNmzYMFatWqX34OQ3yNEIDg5GURQ++eSTLP9u\nZ86cQVEU+vTpg5+fHwcOHNCTNs1+woQJ2RZJMT5vb29vPcjZvXs3u3fvzjLI0ealjh49Wk/YIP07\nOm7cOD3IGTVqlNliK9o1VVU1y2U9SpcuzZgxY5gwYQLff/+9ScXT9957j2vXruHv74+/v3+OSVvd\nunVZv349AwYM0Oeezps3T9e5nKhfvz4JCQksWbIk2ySnUaNGfP3114waNYqHDx/y4Ycf6sM6tV5S\nY4yXCklOTs5So7SXb1ZWVjx48ICPP/6Y7t27M2XKFIt1xZgSJUoQGRmZ47zfokWL6vqgDXPV2lGy\nZEkePHhAfHx8ttqq2RcsWJBChQoxceJE3nvvPXx8fPD39yc2NpYbN26wbNkyli1bRqVKlXBzc+Pp\n06eoqsqlS5d4+vQplStX1o+Z01xZTUO1a5+Vlmifa9V8NbSh9oDJHFlL2bhxo0kw7eTklOtg2s3N\nLcvrWr9+fVasWMGQIUNISEjAy8tLD6a13m5zvPPOO/qoirp162baPmbMGFq2bKkH0/Hx8bRr1y7b\nYFpLrGbOnKl/r2fOnGkSTGsxiTaX2hzadX733Xfx8/MjIiICSH9BoBWxqlevXpb28Jee3b17l44d\nO9KiRQuTYPrw4cMcPnw4UzB969YtALPPrmbNmum/m+sRhvRAWPMdGRmZZfu0hC8oKIjJkyebaFrf\nvn3x9/fnzJkz2Z6jMXXr1mXZsmV6IpyUlGSxruVH09avX28yXD0jluhagwYNWL16Ne7u7qiqmm9N\nA8t0TdM07e+k6VpuNE1D03RLdS0pKQlVVTl16hTR0dE4OjrqupaTpsFfugbZvwjKSteATDFqfpDF\ntZ8RWkVG48IYuSVjIGU8tCi7n+z2z4iNjQ3Lli3D2dkZVVVZuHBhttX0SpUqRYMGDUyGlZnj4cOH\nKIqiD8lbs2YNPXr0MDukyRK0N3jZ+dR6vbZt2wZgUhFRe9CcP38+Wz/aNTJOvgoUKMD777/PgQMH\nmDdvHnXq1NGvZ1hYGN7e3qSkpJCWlkaHDh1wd3end+/eur3xPaA9BDNSuHBh3bc278gcN27cANAf\nNMZox7axscn2HLPC19fX5EFTpkwZXF1dLfoxHkLq5uamJ2PGaEFOwYIF9SBHa3NOQY5GVkGOj4+P\n/jfTgpw5c+Zk+aOhvdgwGAzMnDnTZFtugxwgz0EOoAc5e/bs4YMPPsDGxgZVVTl8+DB9+/alQ4cO\nLF26VE/Yn1WQA1gc5FSsWBGAgwcPAuhDjS0NcooVK0aHDh2A9O+aNjzUErSAO6teaGPefvttxo4d\ni6qqes8eYFJN1rhNX375JcOHD9eLAZlDWxKkYsWKLFmyhCJFivDTTz/RpUsXvfcrOzI+4LVexrCw\nsGzt6tatq7c/YzVbba6zNqQ3K7QXE9WrV9c/K1WqFOPHj+fQoUN89tln+n2qqirXr19n27ZtetI2\nYsQIOnXqZHJM4zfEwcHBmXxqbdWWcckqiP3111+BzC8BtZ4mIMcqxObQgmkNLZj29fXN8cfe3h6D\nwcCSJUv0z8yhBdOKoujB9KNHj3IVTJtDC6YBPZieOnVqtvdnTmgxSU7BNJBlMA1ke27GZAymAwMD\nGTJkCI6Ojvr3ctmyZXriZhxMh4WFmTwT/s5g2ljT8hpMa98Fa2troqOjLda1/Gial5dXtomepbqm\nFcYoVapUrjUN8qZr2nN8xYoVgKmuWappmjYYaxrkrGuarkyaNIlevXqZ6FpOmqa1VfOdXWKela7B\nX3FCXnQtI5K0PSNef/11VFXl66+/zrbnJCvi4uKYO3euXn7e2toaRUkvGrJ//34OHDiQ5c+cOXP0\nQLRdu3asX7+eAwcOZPklKFKkCN999x3FixdHVVXi4+OzFEltLbWDBw9SqVKlLNv/3Xff6cOfAgIC\ncHNz4/Lly7z77rssX748RxHevn07ly9f1r8cXbp0QVVVNm3alKVN27ZtUVUVHx8fwDTA79+/P6qq\nsmDBArMJj4bW42E8dE/DysoKT09PtmzZwp49exg7dmymeUcxMTFcvXpVD2KfPn1qMqfxxx9/NOvX\nODDLbi7T999/D6DPTTJGe2hpD6Hc0qBBA5MgJzU1lcWLF7Nx48Ycf7Qg55tvvtE/M4cEOVnzIgQ5\n7du313Xt2LFjuQ5yDh8+zKpVq/Te1BMnTrB7926LbJs1a6Z/h7MbDaAxdOhQevbsiaqqJCcnk5aW\nxsKFCzO9vLK2tqZHjx6MHDkyyyU+oqKi8Pb2RlEUmjdvTrt27fjf//5HixYtuHXrFgMHDmTu3LlZ\n3p+QPlx27ty57Nq1i1u3bjFgwABUVWX58uUmPWgZadGihd5mBwcHk7/tsGHDsLOzY/78+Vy5csWs\nvaqq+Pr6oiiK2SI99vb29O/fnw0bNnD48GGmTZtG69atTV56qapq4jc4OFi/HlZWVixYsEB/SaHR\ntGlTVFXVX6KZG9L26NEjFi5ciKIomYYJVqxYUddjNze3LK9Pdkgw/RcSTKeTMZg21rT//e9/QO6C\n6cOHD7No0SIMBgPdunXLla7lR9POnDljdskljdzqWvv27XOtaZA3XevRoweqqhISEoKqqibaYImm\naeeblaZB1rqmPWc1TdOumyWaBunfI80m41QYjex0LTU1leXLl+dL14yRpO0ZMXToUKytrQkLC6Nr\n164EBASYVGzLCm09pXfeeYc//vgDKysrpk2bxqJFi1AUhfPnz7Njxw593LS5n+7du9O5c2dUVSUw\nMJC+ffvSu3fvbHtwKlasyNq1a00Wgob04O/atWsWn/eff/7JpEmTCAoKAtJ7ICpWrMi6dev45JNP\nAFiyZAl9+vTJtnfliy++wNPTkwYNGujDqWxsbNi4caP+1jgjLVu2xMbGRhf/IkWK6GXa27Rpow+1\nGzJkiMlyAvHx8Wzbtk3/Itra2vL+++9ne56VKlXiww8/ZPPmzRw/flw/N82+SJEifPvtt3Tv3p3g\n4GCcnZ2pVasW69atY/Xq1SYC+/TpU5Mhf/fu3cvUpZ6cnMycOXPYs2cPiqLQpUsXk/avWbNGT0Zz\nMxctI9oDTRsCNm3aNIvsJMj5dwQ5H3zwAVWqVCEuLo4hQ4YwePBgVFXF1taWe/fu6S980tLSSEhI\nIDIyktDQUNatW8eQIUPw8vIiMTGRihUr4uHhgaqq2VYENWbgwIHY2dlx9+5dunTpwrJlyzh69Gi2\nL2G++OILk2FlWu9kWlpatr2LGhEREaxevZouXbpw584dChYsyKBBg4D0ocorV65k+vTpFCxYMNvR\nBKqqEhwczJo1axg3bhzt2rXDy8sLGxsbzp8/z8cff5wp0T558iTz5883KWx08eJF/Xly9+5dypUr\nx+LFi0lOTubdd99lzpw5HDhwgKNHj7J+/Xp9REBqairVq1c3KV5kjlKlStGvXz+++eYbfv31VzZs\n2KAXBQLo3Lkz7du3Z8CAAcTExNC2bVs6duzI+fPn6devHydOnCApKYnHjx/r97MWGBUsWJCIiAhS\nU1OJjY1l9+7d9OzZUx+GrRXtefr0KZs2beLhw4f6tcupt9ocEkxLMJ0Rc8G0sabNmjULVVUpXrw4\np06dypWmVahQgalTp+ovmC3RtfxomqqmFxQyvs8WLFiQL13LjaZpPvOia6GhoSYvQ3/55ReLNc24\nsnm1atVy1DQw1bX9+/dTuHBh/cVhsWLFLNa0vXv36pV8Ib13dtWqVbnStZ49e3L48GEAs0XpcosU\nInmGHDhwgHHjxpGYmKjfIE5OTpQvX57ChQvr81ySkpKIi4vj9u3b3Lp1Sw/GDAYDX375Jd26dQNg\n8eLFLF++HBsbG7Zv324yvyAjqampzJ8/H19fX1JSUrCzs+P06dM5tjkiIoLRo0fra39BegD/ww8/\nZDtMDGDkyJEEBQXp7X/77bdZvHixyT7nzp1jwoQJXL9+HVtbW/3aaJNZZ82axYULF7h06VKm8uKQ\nLhJWVlacOXPGZBhnu3btuHXrlskwUIPBgK2tLa6urjg7O1O0aFG2bt2qP4QdHR0pUKAADx8+1EUZ\nYO7cudku7pwVc+fO5YcffjAJ/rX2LlmyhLi4OCZOnIiipFct1IqrBAcH65OJtXZbW1vj6uqKk5MT\nT548ISQkhJiYGFRV5bXXXuPHH3/EysqKmJgYWrZsqfckaOe1aNEikyFylnD48GFGjRpFUlIS3bp1\n0+dJLFmyJFO1x4x89dVXrFmzBicnJ/z9/TMl/+bQKigpikKJEiX0B5CimK7RZwlRUVG8++673L17\nl379+uHl5cWUKVM4cuQIBoMh05xKcxOq69evj6urK3Xr1sXV1ZWoqCh69eqFi4sLGzZsMDtsODAw\nkBEjRuj3XJ8+ffjiiy+A9KG8Hh4e+tqG5groGBci+fzzz+nTp0+25xkZGcn+/fv5+eefOX78uEnw\nok1EDw4O5uOPPyYmJgYrKytq1KjBunXrMs3nmjJlClu2bAHSiwBolfqMefToET179iQiIoJ27dqx\nePFiHj16hJeXF6GhoSYBqaVrMtauXZulS5diZWWlFz8ZPny4Prw5O/bu3cu4ceNISUnRNTU0NDTb\nuQ8pKSmMHz8+U7C+adMms8N4jdEq0mp6/NVXX+Hp6Zlpv+vXrzNx4kTOnj2LtbU1H330EUuWLEFR\nFNatW8eVK1e4cOEC58+f548//si05p+5Ih1169YlJSVFvz/q1q2rv0DQNMbGxoYiRYoQHx+vV1o1\nRtMEZ2dnfH19s0wSsuPUqVP6/WRMuXLlWLduHY8fP6ZXr15me5SNAzZz94d2T4wZM4Zhw4YB6aNM\ntMJVxlresGFD2rRpg4uLi9lnaMZquMeOHUNVVSpWrMi2bduYOXMmW7dupVKlSuzZsyfbc75z5w6d\nOnUiMTGR4sWL07dvX9zc3HjjjTeyrEyrFSLShg4bfzeGDRtG//79s305BenP33379vHDDz/w4MED\nbG1t2bFjh/7dWLduHV9//TWJiYlUrVqVefPmUatWrUx6pmF8PxQtWpS4uDhSUlJMqkVrnDx5ksOH\nD5vMXa1cuTJeXl40btyYsmXLcvToUT755BNUVaVnz568/vrrejK+d+9efY3K6tWrExAQYNF6hhr3\n79+nc+fO+rp+xYsXx9HRkYiICFRVpW3btvr1cHFxYdy4cdSvX5/k5GSOHz/O3Llz9ekTDg4ODB8+\nnPbt2+vP0GPHjuHt7c3NmzcxGAysX79en7e5bt06Fi5caDL/0pL53Bk1zcnJifv37+dK1/Kjadp9\nbPw92bhx4zPRtew0LSQkhBs3bnDu3Lk865q2FrGGpZoGf+nKvn378vSSOj+apsWYxkWKzO0Dh0iT\nIwAAG6ZJREFU5nVNm3c5ePBgJkyYkOu2Z0SStmfMxYsXWbhwoZ5Za2T8Q2e87A0aNGDy5MkmQ+VU\nVcXT05MrV67w9ttvW/QmJzIyksDAQCIjIxk9erRFbU5JSWHdunUsXryYx48fYzAYOHToUI4P/H79\n+ulv9bt27crMmTPNCk9SUhJz587VS6Wbq0CkqirXrl3jwoULXLhwgXPnznHx4kXi4uIoW7as3pOn\n0aRJE70ns23btlhbW7N//3794ZPT9dY+06oG5abcvTGbNm3iu+++0ye/Ozs7M378eH1duVmzZulD\nJI0TUUgfUluiRAmT4DLjPm+88Qbe3t56r2laWpo+x6558+ZEREQQHh6Ooij5DnKmTZvG//73P159\n9VV27tyZ7XlLkPPvCnK2bt3KypUr9bH5OQU42pvtrl270r179xwTvOw4f/48Cxcu5MSJExQqVMjk\nzWd2rFmzxmSR9NOnT2eqrpuRIUOGcPToUapWrcrUqVPNDvHTSE1NZdmyZXz77bd6T4E5bUtLS+PK\nlSucP39e/0lJSck09Ltly5ZERkZSuXJlpkyZQosWLTh69Ci+vr4cO3Ys2yGVGlobTpw4kae1FzWi\no6PZuHEjYWFhGAwGXF1d6du3rz6M7LfffmPy5MmZ5hwXK1aMbt26ERQUZHZkRalSpRg3bpzJyAFI\nnwdatWpV+vTpw6ZNmwgNDbW4KBJIMC3BdO6DaW17qVKlTHqwsuJ50bRFixbp18PGxobffvvtmema\npZoGedc1RVFypWklS5bkzz//xGAwmG2HpeRH0z799FNeeeUVZs2alSddGzJkiD63O79I0vY3ce3a\nNY4cOcKlS5e4ffs2Dx8+JCkpCYPBgL29PY6OjlSqVIkaNWrQsmXLLB8o2qLdBoOB3bt352sonCVc\nvnyZkJAQevXqleO+K1eu5M8//8TDwyPHhxPA0aNH9WRg5syZFhXQCA8P5/79+5lKDo8fP57ChQvj\n4eGhB+FRUVHs2bOHs2fP8scff/Dnn3/y5MkTEhMTsbW1xcHBgfLly1OrVi1atWrFrl279IIUeS3m\noRETE4PBYDA7Nv748eNs2rSJGzdu6BXZ3N3d6dixI5C+5tm2bds4f/48MTExODg4UL16dTp27Gi2\n6MSmTZt47bXXqFq1qkkvSH6DnLt37zJv3jwURWHMmDES5EiQA2R+Y9i/f3/atWtnomtWVlbY2dlR\nuHBhKlWqRNWqVbOsNptX4uLiuHXrVqaF6rMjOjqaDRs2cPr0aX0Nx+zQyk7XqlXLYh+hoaFMnDhR\nHx6T18Bi//79lClTxmzxncePH3PhwgUuX76s61pCQgJ2dna6rtWsWZMnT55gMBho1KhRrvQgL6Sk\npHD8+HETXWvatCm2traoqsrZs2czaVr9+vXNam18fLweeKqqyt69e/nhhx8ICwuTYBoJpv/uYDom\nJiZTrPa8a1pYWBgLFizI8R6D3Ovas9I0yFrXLNW0OnXq6FMe/m5dy07TgHzp2rNCkjZBeMGRICcz\nEuQ8/28MXyYSEhL0SpX/HwnTvwUJpk2RYPqfCabv3LkDpC8jkRfyY/9P+U5ISDCZU5+Xv++LeN7/\ntO+ckKRNEF4iJMgxRYKcZxPkhIeH4+vry6FDh4iMjKRw4cI0bNiQfv365bhgdnh4OG+//TaQXjGz\ncOHCNGjQgP79++doGx8fr89BLF++vO7bUvvn0Xe/fv2yXKw4J98v6jW3tN3x8fHUr18fg8GQ5VqC\nGo8ePeLWrVvY2tpSqVKlbJeuedb2/6TvO3fusHv3bmxtbenZs2euR4m8qOf9T/quWbMmBoOB4ODg\nPD0/8mMvvv9dvnNCkjZBEF5qpBckf4SGhuLl5aUXxtHQrqOHhwczZsww+3AKDQ1l2LBh+vzTjEMz\ns7OF9CpjWvVGc0NSxffL5VtL2iB9/U1ra2sqV65sMhogNDSUefPmmRTacnBwoFu3bowcOZLChQuT\nnJzM9evX82Rva2ubZ1vx/eL5Nl7qIiuM50TnNYjPq734/nf5zglJ2gRBEASzREdH4+HhQVRUFNbW\n1rRt2xZnZ2fCw8MJCgoiKSkJRVGoUaMGq1ev1te6y2irPWa8vLwsstXsO3fuTFRUFAAdO3YU3y+x\nb/irlw/+qj5Zrlw5ZsyYQbNmzQgODmbIkCEmJfY1FEXB2dmZNm3asHnzZmJjY3NtX6RIEVJTU4mL\nixPfL6lv7V/Nd9euXXNcp23p0qUoisKHH36YqSp3Tr3mxvb169fPVHwqJ3vx/eL6/vDDDzP1hI8Y\nMSJH++yQpE0QBEEwy6JFi1ixYgX29vb4+PiYVLeNjIxk2rRpHD58GEVRqFq1Kj4+PnrVQmNbrUCG\ntv5PTrbG9uaWhRDfL59vgKlTp7J582bAtJdPW0bj888/5+LFixQsWBBPT0/q1KlDYmIiP//8s14N\nN6OtpfZHjx7V9xffL6/vzz//nIxYunyJoiiZ1iGzZE54Vmv4ie+X27e5UT1ZrYFnKZK0CYIgCGbp\n3r07Fy9eZPz48fqioRmZPXs2Pj4+KIqCi4sLPj4+2NnZ6bajRo3SF7jN+MDKytbYd1pamkkCIL5f\nTt+//PKLyUK62hI3fn5+nDx5EicnJ+7cuUOxYsXw8fGhWrVqJsdeuHChvuh9rVq18PLystg+o+8+\nffrQpEkT8f0S+m7fvj3h4eFA9sF1Vpjr8currfh+uX2bI7dr0mYk72XjBEEQhJcaLbgxt/SExpQp\nUxg0aBCqqnLu3DlGjx5NWlqabpvdou9Z2Rr7zg7x/fL49vf31/czGAx06NCBDh068MMPP1CjRg3u\n3LmDoiiMHz8+UwAP6GtlQvoahrmx13xXrlwZRVG4efOm+H5JfQcEBNCzZ0/grwC8cePGXLp0Kcsf\nbd/Tp08TGhpKr169UBQFg8FA9+7dCQ4Otsj+xIkTJrY9evSw2FZ8v3i+T58+bXZbfpCeNkF4QQkI\nCMiXvbYwukaDBg3ybJtfe/H9fPqeOnUqqampTJ8+PVN1z65du5r8f8KECezYsQNFUejZsyc//fQT\nKSkpBAUF0bp1a7M9L1nZzpgxw2RdvKx6fcT3y+P7zTff5N69e2Z9b926lcmTJ6MoCsePHze7cLix\nffHixfWF7C2x12wXLFjAmDFjKFasmG4vvl8+3wCHDh1i0qRJPHz4EIPBgK+vr77odkbMFZY4dOgQ\nn332GVFRUZQrV46vvvrKYvv82IrvF8/3syR3NVMFQXhumDRpUr666jOO1dbmkuTFNr/24vv59K3Z\nzJw50+ReUxQlU9I2e/Zs7t69y6lTp/D398fe3p6UlBRu3LiRo5+Mtk5OThQvXpzIyEgLzkx8vwy+\nHzx4kOX+WkVJIMvlSoztHz9+nCt7zVZbssTYXny/fL4BWrduzfr16+nQoQNpaWkMHDiQQYMGMWbM\nGAoUKGDWJqP99u3b+eyzzzh48GCu7PNjK75fPN/PEhkeKQgvKP3799cDaVVVc/2TkfzY5tdefD+f\nvrPbNyM2NjYsW7YMZ2dnVFUlLi4OVVVZu3at2bZnZ7tw4UKzb8cttRffL57v7NbNKlWqFA0aNKBs\n2bKZFo3XcHBw0O/LIkWK5MrewcEBQF9H0dhefL98vjUePnyIoigUKlQIW1tb1qxZQ48ePSwuFlG8\neHGWL1/Of/7zn1zb58dWfL94vp8VMjxSEF5gAgMDGTNmDCkpKdSpUwdvb2+LqhtpHDt2jJkzZ5Ka\nmppre2PbatWqsWzZMvH9kvn+9ddfmTJlCoqi0LZtWz744ANKlSoFpJfWNsfNmzfp3bu3XjZeI2M1\nwuxso6OjAdNJ4IcOHaJs2bIW2YvvF8+3sd+chmaaY+jQoRw5cgRIHzr3zTff5Mr26NGjlCxZkgcP\nHtCqVatc24vvF8e3xkcffcShQ4do1aoVU6ZMYeLEiYSGhmJtbc3w4cPx8vLCYDBYNNzt5s2bebbP\nj634fvF85wtVEIQXmgMHDqi1atVSa9asqS5btuz/1V58v/y+x40bp9aoUUOtWbOmWrNmTbV58+Zq\nXFxctjZ//PGH2qxZM7V69eomP7mxrVGjhomt+H65fWe0vXr1arZ2xkRGRqr9+/fXbfv165cr+02b\nNpn49vPzE98vse/IyEj1008/1XUtMDBQVVVVTU1NVZctW6bWqVNHrVmzptqzZ0/12rVr+n7x8fHZ\nHjc/9uL73+U7r0hPmyC8BCxevJjly5djY2PD9u3bqVy58v+bvfh+uX2npqYyf/58fH19SUlJwc7O\nLtOCo+aIiIhg1KhRnD9/Xv/M3t7eYtvRo0dz7tw5/TNFUcT3v8i3lZUVP/zwA40bN87WduTIkQQF\nBZGamqrPwTQYDCiKkiv7p0+fiu9/ke/U1FRUVeXtt99m8eLFJvucO3eOCRMmcP36dWxtbUlMTMxV\nz0l+7MX3v8t3bpE5bYLwEjBy5EiqVatGSkoKCxcu/H+1F98vt28rKys+/fRTDh48yPTp0xk0aJBF\nPipUqIC/vz/Tpk2jXLlyKIqSK9uNGzcybdo0KlasiKIo4vtf4Hvq1Kk4OjoC6cM0K1WqlKNtdHQ0\nKSkpqKpKly5dGDhwIFZWVrm2B6hatSo2Njbi+1/gW1VVunbtyvz58zPt4+LiQkBAAH379iUxMTHH\nYz5Le/H97/KdW6SnTRBeEn7++WeGDh2KwWBg9+7dODs7/7/Zi+9/l++88PDhw1wVunhWtuL7xfN9\n+fJlQkJC6NWrV477rly5kj///BMPDw9cXV0BiIyMJCgoKE/2+bEV3y+e75w4evQoO3fuBNKr6NrY\n2ORo86zsxfe/y7clSNImCIIgCIIgCILwHCPDIwVBEARBEARBEJ5jJGkTBEEQBEEQBEF4jpGkTRAE\nQRAEQRAE4TlGkjZBEARBEARBEITnGEnaBEEQBEEQBEEQnmOs/+kGCIIgCP9eli5dytKlS/Nk6+vr\nS6NGjZ5xi/JPdHQ0u3bton///v90UwRBEISXBOlpEwRBEP5xFEXJ9c/zyPbt23F3d2ffvn3/dFME\nQRCElwjpaRMEQRCeC/r370+TJk0s3r9atWp/Y2vyxsKFC4mJifmnmyEIgiC8ZEjSJgiCIDwX1KlT\nhzZt2vzTzRAEQRCE5w4ZHikIgiAIgiAIgvAcI0mbIAiCIAiCIAjCc4wMjxQEQRBeGiIjI/H19eXn\nn3/m1q1bpKSkUKpUKRo3bky/fv2oWbNmjsc4evQoe/bsISQkhAcPHhAfH4+joyPlypWjWbNm9O/f\nn1deecXE5q233uLOnTv6/3/77Tfd14gRIxgxYoTJfuXKlePAgQNZtmHAgAGcPHkSRVG4ePGi2W1N\nmzZl5cqVLFy4kICAAB4/fkzp0qXp0KEDY8eONbG5ceMGP/74I8ePH+fu3bsAODk50axZMwYMGECF\nChWyvSZ79+5l27ZtnD17locPH+Lg4ECZMmVo2rQpvXv3xtnZOYerKgiCIOQHSdoEQRCEl4KAgABm\nzJhBQkKCSXXJiIgIbt68yZYtWxg6dChjxowxax8TE8OIESM4efIkgMkxHj16xMOHDzl37hw+Pj4s\nX76cN954w8Re219V1WyrWz6LypfaMT799FN27typ/z8iIoK0tDSTfVeuXMnixYtJSUkx8X3t2jWu\nXr3K+vXrmTRpEv369cvkJzk5mVGjRhEUFGTiNzY2ltjYWH7//Xd8fX2ZPHmyWXtBEATh2SBJmyAI\ngvDCs23bNiZPngxAgQIF8PDwoFGjRhQoUIDff/+dLVu2EBUVxbfffouqqpl6ogA++ugjQkJCUBSF\nV199FU9PT5ycnEhOTubGjRts2bKF6OhoEhISmDBhAgcPHqRAgQIAzJo1i4SEBKZNm8bDhw+pWrUq\no0ePBqBKlSomflRVzff5qqpKcHAwSUlJVK5cmUGDBmFjY8P+/fvp1q2bvt+KFStYtGgRiqLg4OBA\nt27dcHNzQ1EUzp49y5YtW3jy5AmzZs3C2tqaXr16mfhZtmwZQUFBKIpCrVq19GsSGxtLcHAwO3bs\nICUlhVmzZuHm5oaLi0u+z00QBEHIjCRtgiAIwgvN/fv3mTFjBgAlSpTg+++/p3r16vp2d3d3hgwZ\nwtChQwkNDWXVqlW0bdsWV1dXfZ+DBw/qCVvbtm1ZsmRJJj9eXl706tWLy5cvExUVxYkTJ2jVqhUA\nTZs2BeDLL78EoFixYn97JcykpCTKli2Lv78/jo6OAPTo0UPffuHCBZYuXYqiKFSuXJnVq1dTtmxZ\nfXvnzp15//33GTRoEOHh4cyZM4eWLVvq+6iqyoYNG/SEbePGjdjY2Oj277zzDi1bttR7Lv38/Jgz\nZ87fes6CIAj/VqQQiSAIgvBcMGnSJGrWrJnjj9ajpuHn50d8fDyQnjQZJ2wajo6OzJ07F2tra1RV\nZdWqVSbb9+3bZzLk0Bz29vYMGDBA///169fzdb75RVEUevXqpSdsGVm9ejWpqakoisLChQtNEjaN\nMmXKMGvWLCA9CfTx8dG3RUdH62vONWnSxCRh0+jYsSP16tWjbt26FCtW7FmcliAIgmAGSdoEQRCE\n5wJFUSz6ycjevXuB9F42refLHM7OzjRs2BBVVTl69KjJ3K8ZM2awfft2Vq9eTfny5bM8hvG2xMTE\nvJzmM6Vhw4ZmP09NTeXgwYMoikKdOnXMJrIajRo1okKFCqiqyqFDh/TPHR0dsbKyAmDPnj3cvn3b\nrP2GDRvw9/dn4sSJeT8RQRAEIVtkeKQgCILwXNC/f3+aNGmS435OTk76748ePSI8PFyfsxUYGJit\nra2tLQAJCQlcu3aNqlWrAlCwYEGqVatGtWrVMtmkpaVx48YNwsLC2LNnj/55amqqRef1d5JxvpzG\n77//rhdksbGxyfG6FC1alIiICG7cuEF8fDz29vYUKFCAN998k8DAQO7cuYO7uzutWrWidevWNG/e\nnFKlSv0dpyQIgiCYQZI2QRAE4bmgTp06uZ4HFhkZqf8eHh6ul9a3hKioKD1p03j69ClHjhwhJCSE\na9eucfPmTSIiIkhOTgZMKz8+i4Ii+SWroZH379/Xfw8JCSEkJMTiY0ZHR2Nvbw/AtGnTuHTpErdv\n3yY5OZl9+/axb98+AGrWrMlbb71Fp06dePXVV/NxFoIgCEJOSNImCIIgvLDExcXpv+emlL6iKDx5\n8sTks8OHD/P5559z7969TMczGAxUr16dV199lZ07d+az1c8Oc/PM4Nldl9KlS7Nt2zZWrlxJQECA\nSZJ86dIlLl26xPLly2nbti3/+c9/ZF6bIAjC34QkbYIgCMILi52dnf67u7s7//3vf/N0nJ9//pnh\nw4eTlpaGoihUqVKFhg0bUqNGDapVq0atWrUoVKgQJ06c+H9J2rSevbxifF2GDh1qdokDS3FwcGDM\nmDGMGTOGsLAwjhw5wvHjxwkLC9OHiAYGBvLgwQM2bNiQr3YLgiAI5pGkTRAEQXhhKV68uP67cS9Q\nbpk1a5aesM2ZM4cuXbqY3e/x48d59gHpPXaQ83y4/Poxvi5//vlnvo5ljKurK66urowYMYLY2Fh2\n7tzJ/PnzefLkCWfOnOHEiROZFh0XBEEQ8o8kbYIgCMILS+nSpSlVqhSRkZGcO3eOxMREvdiIOby9\nvYmKiqJ8+fL069cPR0dHbty4oRczadSoUZYJG8DFixfz1V5tMW7j4YsZSUpKIiIiIl9+ateujbW1\nNampqZw8eTLH/adPn46iKJQvX57BgwdjMBi4fv06J06c4Nq1awwaNIgKFSqY2BQuXJg+ffqgqioz\nZ84E0gugSNImCILw7JGS/4IgCMILjVa8JDExkXXr1mW5340bN1i1ahWbN2/Gx8cHBwcHIL0CpYZW\ngMMccXFx/PTTT/r/nz59mmkfrSctqyIlJUqUAODJkydZJmaBgYFmj50bbG1tadq0Kaqqcvv2bX1Z\nBHOcOHECf39/Nm7cyK5du/RzCAsLY+bMmfj5+WVbfbJo0aL679ldP0EQBCHvSNImCIIgvNAMGjQI\nGxsbVFVl0aJFBAUFZdonNjaWTz75RF9seuDAgXpyUq5cOX2/3377zWwyFR0dzfDhw02qMpqbd2Zn\nZ4eqqvqi1BlxcXHRf1+2bFmm7X/88QdfffVVroqHZMWQIUOA9ARy+vTphIWFZdrnzp07TJo0CUgv\nQvLBBx/o21q3bq33Wq5YscLsYuLJycn6gtyKotCgQYN8t1sQBEHIjAyPFARBEF5oKlWqxMSJE5k9\nezZJSUl89NFHtGnThtatW2NnZ8eVK1fw9/cnOjoaRVGoVauWSXLyyiuv0KxZM44dO8aTJ0945513\n6N27N9WqVSMhIYHz58+zc+dOHj9+jKIoei+auXlnpUuX5vLly1y+fBlvb29q165N2bJlcXV1BaB7\n9+6sWbMGVVUJCAjg3r17uLu7U6BAAUJCQti+fTtJSUnUrVvXbJKVG15//XXef/991qxZQ0xMDH37\n9qVTp040adIEg8HAxYsX8ff3Jz4+HkVRaNmyJR4eHrp9kSJFGDx4MMuWLSM2NpauXbvSrVs3ateu\njZ2dHbdu3WLLli3cunULRVHo3LmzlP4XBEH4m1DU52GhGUEQBOFfydKlS1m6dKleAKRr1655Ppaf\nnx/z5s0jOTk50/BEreeqXr16LFu2zKRQB6T3OA0YMIA7d+4AmYc3KopCkSJFmD17NlOmTOHRo0fU\nrVuXTZs2mey3detWJk+ebJLcubu7s2DBAn0fHx8f5s6dS1paWiY/1tbWjB8/nuTkZBYsWICiKJnm\n0Q0YMICTJ0+a3WYOb29vVq1aZdafdl3efPNNFixYkGk+YFpaGlOnTiUgICDL6wLw1ltv4e3trc/Z\nEwRBEJ4t0tMmCIIg/KMoivJMhgP269ePNm3a4Ofnx7Fjx7h16xbx8fEULVqUOnXq4Onpibu7u1lf\nTk5OBAQE8P3333Pw4EFu3rxJSkoKhQsXpkqVKrRs2ZJ3332XokWL0qRJE/bu3cvFixeJiIgwKdDR\nrVs3kpKS8PPzIyIiAkVRSExMNPE1cOBAGjZsyNq1a/ntt9+IioqiePHiNGzYkPfeew8XFxdWrlyZ\n7XXJzTUbM2YMnp6erF+/nl9++YV79+6RnJxM8eLFcXV1pUePHrRq1cqsrcFgYM6cOXh4eLBlyxbO\nnj3Ln3/+SVpaGiVLlqRevXp4enpmaS8IgiA8G6SnTRAEQRAEQRAE4TlGCpEIgiAIgiAIgiA8x0jS\nJgiCIAiCIAiC8BwjSZsgCIIgCIIgCMJzjCRtgiAIgiAIgiAIzzGStAmCIAiCIAiCIDzHSNImCIIg\nCIIgCILwHCNJmyAIgiAIgiAIwnOMJG2CIAiCIAiCIAjPMZK0CYIgCIIgCIIgPMdI0iYIgiAIgiAI\ngvAcI0mbIAiCIAiCIAjCc4wkbYIgCIIgCIIgCM8xkrQJgiAIgiAIgiA8x0jSJgiCIAiCIAiC8Bwj\nSZsgCIIgCIIgCMJzzP8BC/bz+/r7VM4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110917978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close()\n",
    "sns.set(font_scale=2)\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "fig = sns.barplot(x = wts.index,\n",
    "            y='Weight',\n",
    "            data=wts.loc[abs(wts).sort_values('Weight',ascending = False).index],palette='Blues_d')\n",
    "for item in fig.get_xticklabels():\n",
    "    item.set_rotation(90)\n",
    "sns.plt.xlabel('Features')\n",
    "sns.plt.ylabel('Weight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with a random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_scl, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78365384615384615"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test_scl, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model for fold 1 of 3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-29dbf05fd103>\u001b[0m in \u001b[0;36mkfold_feature_learning\u001b[0;34m(train, test, y, t_y, clf, problem, folds, scale, verbose, search, p_cutoff, regcols, regdf, keep_cols, out_dir, output, save_int)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mall_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msig_mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'coef_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-496a4b2389bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m rfoutput = kfold_feature_learning(X_train, X_test, y_train, y_test, clf = RandomForestClassifier(), search = False,\n\u001b[1;32m      2\u001b[0m                                 \u001b[0mp_cutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'classification'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'light'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                 scale=True, regcols = None, regdf = None, keep_cols = None, save_int = True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-104-29dbf05fd103>\u001b[0m in \u001b[0;36mkfold_feature_learning\u001b[0;34m(train, test, y, t_y, clf, problem, folds, scale, verbose, search, p_cutoff, regcols, regdf, keep_cols, out_dir, output, save_int)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mall_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msig_mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mall_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msig_mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# save predicted values for this validation fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         [predicted.append(x) for x in model.predict(train.loc[train.index[te_ix]][\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "rfoutput = kfold_feature_learning(X_train, X_test, y_train, y_test, clf = RandomForestClassifier(), search = False,\n",
    "                                p_cutoff=None, problem = 'classification', folds = 3, output='light', \n",
    "                                scale=True, regcols = None, regdf = None, keep_cols = None, save_int = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03712264,  0.00710063,  0.01312643,  0.00460981,  0.01729333,\n",
       "        0.0092553 ,  0.02312061,  0.03222434,  0.00331026,  0.01451003,\n",
       "        0.02402957,  0.01224223,  0.01878242,  0.00515767,  0.00771483,\n",
       "        0.00975133,  0.00893427,  0.0525303 ,  0.00453729,  0.00525046,\n",
       "        0.02393181,  0.0053919 ,  0.0175715 ,  0.01269398,  0.01534041,\n",
       "        0.00374715,  0.01486216,  0.01655151,  0.07342547,  0.01145565,\n",
       "        0.00254374,  0.02623145,  0.00674962,  0.01559161,  0.16134851,\n",
       "        0.03068611,  0.00998341,  0.00648514,  0.00611011,  0.01024847,\n",
       "        0.0095914 ,  0.10286029,  0.01048456,  0.01020354,  0.02940663,\n",
       "        0.02546873,  0.00851094,  0.0053377 ,  0.00635158,  0.01023115])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  0. ,  0.2,  0. ,  0.1,  0. ,  0.2,  0.2,  0.1,  0. ,  0. ,\n",
       "        0.1,  0. ,  0. ,  0. ,  0.5,  0. ,  0. ,  0. ,  0.1,  0.1,  0. ,\n",
       "        0. ,  0.2,  0.2,  0. ,  0. ,  1. ,  0. ,  0. ,  0.1,  0. ,  0.6,\n",
       "        0.2,  0.3,  0.9,  0. ,  0.2,  0.1,  0. ,  0. ,  0.2,  0.1,  0. ,\n",
       "        0. ,  0.1,  0.1,  0.2,  0.9,  0. ,  0.2,  0. ,  0.8,  0. ,  0. ,\n",
       "        0. ,  0.9,  0.7,  0. ,  0.8,  0.8,  0. ,  0.1,  0.4,  0.9,  0.1,\n",
       "        0.1,  0.8,  0. ,  0.6,  0. ,  0. ,  0. ,  0.3,  0.1,  0. ,  0. ,\n",
       "        0. ,  1. ,  0.1,  0. ,  0.1,  0. ,  0.1,  0. ,  0.4,  0. ,  0. ,\n",
       "        0. ,  0.2,  0.1,  0.1,  0. ,  0. ,  0.1,  0.1,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0.2,  0. ,  0. ,  0. ,  0. ,  0.1,  0.5,  1. ,  0. ,\n",
       "        0. ,  0.1,  0.1,  0. ,  0.9,  0.2,  0. ,  0.1,  0. ,  0.9,  0. ,\n",
       "        0.5,  0.6,  0.2,  0.1,  0.2,  0. ,  0.2,  0.2,  0. ,  0. ,  0.2,\n",
       "        1. ,  0.2,  0.1,  0. ,  0.1,  0.1,  0.1,  1. ,  0. ,  0. ,  0.9,\n",
       "        0. ,  0. ,  0.7,  0. ,  1. ,  0.6,  0.3,  1. ,  1. ,  1. ,  1. ,\n",
       "        0.8,  0.8,  0. ,  1. ,  0.1,  0.9,  0.9,  0.9,  0.8,  0.1,  1. ,\n",
       "        0.7,  0.1,  0. ,  1. ,  0.8,  0.2,  0.8,  0.9,  0. ,  0.8,  0.8,\n",
       "        0.8,  0.6,  0.8,  0.4,  0.5,  1. ,  1. ,  0.9,  0.9,  1. ,  0.9,\n",
       "        0.7,  0.9,  0.6,  1. ,  0.9,  0.8,  0.2,  0.9,  0.6,  0.7,  0.7,\n",
       "        1. ,  0.8,  0.7,  0. ,  0. ,  0.7,  0.8,  0.4,  0. ,  0. ,  0.9,\n",
       "        0.8,  0.3,  0.8,  0. ,  0.7,  0.2,  0. ,  0. ,  0.1,  0.2,  0.8,\n",
       "        0. ,  0.1,  0. ,  0. ,  0. ,  0.1,  0.9,  0. ,  0.2,  0. ,  0. ,\n",
       "        0.1,  0. ,  0. ,  0.1,  0.1,  0. ,  0. ,  1. ,  0.4,  0.9,  0.1,\n",
       "        0. ,  0.8,  0. ,  1. ,  0.2,  0.7,  0.9,  0.1,  0.1,  0.2,  0.6,\n",
       "        0. ,  0.3,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0.1,  0.6,  0. ,\n",
       "        0.1,  0. ,  0. ,  0.1,  0. ])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_train_scl)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.294350\n",
       "1     0.194540\n",
       "2     0.223654\n",
       "3     0.095454\n",
       "4     0.044072\n",
       "5     0.179285\n",
       "6     0.225659\n",
       "7     0.325395\n",
       "8     0.317057\n",
       "9     0.173201\n",
       "10    0.220247\n",
       "11   -0.057982\n",
       "12    0.325205\n",
       "13    0.185030\n",
       "14    0.267216\n",
       "15    0.220668\n",
       "16    0.168340\n",
       "17    0.240047\n",
       "18    0.171923\n",
       "19    0.256769\n",
       "20    0.108450\n",
       "21    0.277150\n",
       "22    0.144265\n",
       "23    0.258184\n",
       "24    0.269643\n",
       "25   -0.073784\n",
       "26    0.141556\n",
       "27    0.109919\n",
       "28    0.231701\n",
       "29    0.268874\n",
       "30    0.295304\n",
       "31    0.207377\n",
       "32    0.146039\n",
       "33    0.075175\n",
       "34    0.202870\n",
       "35    0.229928\n",
       "36    0.181375\n",
       "37   -0.033769\n",
       "38    0.073831\n",
       "39    0.103174\n",
       "40    0.017915\n",
       "41    0.177165\n",
       "42    0.239264\n",
       "43    0.331518\n",
       "44    0.033400\n",
       "45    0.298015\n",
       "46    0.151211\n",
       "47    0.166851\n",
       "48    0.047869\n",
       "49    0.162520\n",
       "dtype: float64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(X_test).mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64232,)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.ravel().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64232,)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy.ravel().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.30173745,  0.06802498],\n",
       "       [-2.28173745,  0.06802498],\n",
       "       [-2.26173745,  0.06802498],\n",
       "       ..., \n",
       "       [ 3.55826255,  4.38802498],\n",
       "       [ 3.57826255,  4.38802498],\n",
       "       [ 3.59826255,  4.38802498]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "query data dimension must match training data dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-f0d630c27595>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 delayed(self._tree.query, check_pickle=False)(\n\u001b[1;32m    380\u001b[0m                     X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 381\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m             )\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/neighbors/binary_tree.pxi\u001b[0m in \u001b[0;36msklearn.neighbors.kd_tree.BinaryTree.query (sklearn/neighbors/kd_tree.c:11337)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: query data dimension must match training data dimension"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
