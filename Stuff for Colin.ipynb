{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "import nibabel as ni\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(image_dir, beta_dir, spreadsheet, outdir, sdres_img = '', beta_str = 'beta',\n",
    "                           intercept='first', res_str = 'Res_', \n",
    "                          cols_to_use = [], img_mask = None, subject_col = ''\n",
    "                          ):\n",
    "    '''This script will create W-SCORE images from a set of input images, and a\n",
    "    spreadsheet. This script makes several assumptions about the inputs:\n",
    "    \n",
    "    1) The \"image_dir\" path must ONLY contain input images, and no other files or \n",
    "        directories\n",
    "    2) The rows of your spreadsheet MUST be in the exact same order as the images \n",
    "        in the \"image_dir directory. So subject 1 should be row 1 of the spreadsheet \n",
    "        (not including headers)\n",
    "    3) The values in the dataframe should all be of a numeric type (int or float)\n",
    "    4) The script assumes you have run an SPM model for the variables included in \n",
    "        the W-SCORE, and that you thus have BETA images for each of those variables\n",
    "    5) The number of BETA images (not including the intercept) should be in the exact \n",
    "        same order as either the columns of your spreadsheet, or the columns in the\n",
    "        cols_to_use argument.\n",
    "    6) If cols_to_use is not passed, script assumes that spreadsheet only includes \n",
    "        columns for which BETA images exist, as well as a subject column (but only\n",
    "        if the subject_col argument is passed)\n",
    "    7) The script assumes you either have an image representing the Standard\n",
    "        Deviation of the Residuals, or you have asked SPM to create the residuals in \n",
    "        the model described in 3)\n",
    "    \n",
    "    If all of these assumptions have been met, you may proceed.\n",
    "    \n",
    "    image_dir = an directory containing ONLY raw images to be W-transformed (REQUIRED)\n",
    "    beta_dir = a directory containing beta images generated from an SPM model (REQUIRED)\n",
    "    spreadsheet = a spreadsheet with one row for each subject in image_dir (same order),\n",
    "        and columns indicating values for variables to be accounted for (e.g. age, sex),\n",
    "        which correspond to, and are in the same order as, beta maps in beta_dir. (REQUIRED)\n",
    "    outdir = a directory to store the transformed output files (does not have to exist) (REQUIRED)\n",
    "    sdres_img = a path to an image representing the Standard Deviation of the Residuals (of the \n",
    "        normative model). Or, leave blank and script will create one for you using residual\n",
    "        images created by the SPM model (Res_str must be passed)\n",
    "    beta_str = string labeling beta images from the SPM model (the text in front of the image \n",
    "        names)\n",
    "    intercept = SPM puts the intercept as the first or last image, depending on the version.\n",
    "        Enter \"first\" if its first, or \"last\" if its last. If you did not include the\n",
    "        intercept in the model, pass \"none\". (WARNING, \"none\" is in beta and will crash)\n",
    "    res_str = if you did not pass an option for sdres_img, you must an argument here. This\n",
    "        is the string labels of Residual images created by the SPM model.\n",
    "        **WARNING** This may crash your computer if you don't have sufficient memory\n",
    "    cols_to_use = a list of columns from df to use can be specified here. If your df has \n",
    "        columns you do not wish to use in the w-scoring, you can specify the names of the\n",
    "        columns you do wish to use (be sure they are in the exact same order as the beta\n",
    "        images in the beta_dir)\n",
    "    img_mask = path to a binarized mask image in the same dimensions as your input images. If\n",
    "        passed, the w-score images will be masked (RECOMMENDED)\n",
    "    subject_col = name of a column in df with the subject IDs. This will automatically label\n",
    "        the w-score images with the subject IDs from this columns\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # check inputs\n",
    "    print('initating and checking inputs')\n",
    "    for cdir in [image_dir, beta_dir]:\n",
    "        if type(cdir) != str:\n",
    "            raise TypeError('%s must be a path pointing to a valid directory, you passed a %s object'%(cdir,\n",
    "                                                                                                    type(cdir)))\n",
    "        if not os.path.isdir(image_dir):\n",
    "            raise IOError('could not find the directory specified in argument \"image_dir\"')\n",
    "    if type(outdir) != str:\n",
    "        raise TypeError('%s must be a path pointing to a valid directory, you passed a %s object'%(outdir,\n",
    "                                                                                                type(cdir)))\n",
    "    if not os.path.isdir(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    \n",
    "    if intercept not in ['first','last', 'none']:\n",
    "        raise IOError('intercept must be set to \"first\", \"last\" or \"none\". See docstring for more info')\n",
    "    \n",
    "    # load inputs\n",
    "    raw_paths = glob(os.path.join(image_dir,'*.ni*'))\n",
    "    print('found %s images to transform'%len(raw_paths))\n",
    "    \n",
    "    beta_paths = glob(os.path.join(beta_dir,'%s*'%beta_str))\n",
    "    if len(beta_paths) == 0:\n",
    "        raise IOError('No beta images found in specified directory. Please revise beta_dir or beta_str arguments')\n",
    "    if intercept == 'none':\n",
    "        n_betas = len(beta_paths)\n",
    "    else:\n",
    "        n_betas = len(beta_paths) - 1\n",
    "    if len(cols_to_use) > 0:\n",
    "        if len(cols_to_use) != n_betas:\n",
    "            raise IOError('# of columns in cols_to_use (%s) must match number of non-intercept beta maps (%s)'%(\n",
    "                                                                                            len(cols_to_use),\n",
    "                                                                                            n_betas))\n",
    "\n",
    "    print('preparing spreadsheet')\n",
    "    if type(spreadsheet) == str:\n",
    "        if '.csv' in spreadsheet:\n",
    "            df = pandas.read_csv(spreadsheet)\n",
    "        elif 'xl' in spreadsheet[-4:]:\n",
    "            try:\n",
    "                jnk = pandas.ExcelFile(spreadsheet)\n",
    "                df = pandas.ExcelFile(jnk).parse(jnk.sheet_names[0])\n",
    "            except:\n",
    "                raise IOError('could not load excel file. Please convert to csv')\n",
    "        else:\n",
    "            try:\n",
    "                df = pandas.read_table(spreadsheet)\n",
    "            except:\n",
    "                raise IOError('could not read spreadsheet. Try loading the df yourself with pandas and inputting that')\n",
    "    else:\n",
    "        df = pandas.DataFrame(spreadsheet,copy=True)\n",
    "    if subject_col:\n",
    "        if type(subject_col) == int:\n",
    "            subject_col = df.columns[subject_col]\n",
    "            subject_IDs = df[subject_col].values\n",
    "            print('using %s for subject IDs'%subject_col)\n",
    "        else:\n",
    "            if subject_col not in df.columns:\n",
    "                raise IOError('could not find %s in any of the columns of your dataframe: %s'%(subject_col,\n",
    "                                                                                   df.columns))\n",
    "            else:\n",
    "                subject_IDs = df[subject_col].values\n",
    "        df.drop(subject_col, axis=1, inplace=True)\n",
    "    else:\n",
    "        subject_IDs = []\n",
    "    if len(cols_to_use) > 0:\n",
    "        df = df[cols_to_use]\n",
    "    if df.shape[0] != len(raw_paths):\n",
    "        raise IOError('number of scans (n=%s) does not match number of rows in spreadsheet (n=%s)'%(len(raw_paths),\n",
    "                                                                                               df.shape[0]))\n",
    "    \n",
    "    print('loading beta images')\n",
    "    if intercept == 'first':\n",
    "        int_img = ni.load(beta_paths[0]).get_data()\n",
    "        beta_paths.remove(beta_paths[0])\n",
    "    elif intercept == 'last':\n",
    "        int_img = ni.load(beta_paths[-1]).get_data()\n",
    "        beta_paths.remove(beta_paths[-1])\n",
    "    else:\n",
    "        int_img = None\n",
    "    jnk = ni.concat_images(beta_paths)\n",
    "    beta_imgs = jnk.get_data()\n",
    "    aff = jnk.affine\n",
    "    if len(beta_imgs.shape) > 4:\n",
    "        try:\n",
    "            x,y,z = beta_imgs.shape[:3]\n",
    "            s = beta_imgs.shape[-1]\n",
    "            beta_imgs.reshape(x,y,z,s)\n",
    "        except:\n",
    "            raise IOError('shape of beta images is %s, expecting a set of 3D images (so 4d)'%beta_imags.shape)\n",
    "    \n",
    "    if beta_imgs[:,:,:,0].shape != ni.load(raw_paths[0]).shape:\n",
    "        raise IOError('inconsistent dimensions between betas and raw images')\n",
    "    \n",
    "    if sdres_img:\n",
    "        if os.path.isfile(sdres_img):\n",
    "            sdres_img = ni.load(sdres_img).get_data()\n",
    "        else:\n",
    "            raise IOError('could not find any SD of residual images at path %s'%sdres)\n",
    "    else:\n",
    "        sdres_img = create_sdres_img(res_str, beta_dir)\n",
    "    \n",
    "    if type(img_mask) != type(None):\n",
    "        try:\n",
    "            mask = ni.load(img_mask).get_data()\n",
    "        except:\n",
    "            raise IOError('could not load mask. Please ensure the path points to an existing nifti image')\n",
    "        if mask.shape != ni.load(raw_paths[0]).shape:\n",
    "            raise IOError('dimensions of mask (%s) do not match the dimensions of input images (%s)'%(mask.shape,\n",
    "                                                                                                   ni.load(raw_paths[0]).shape))\n",
    "    else:\n",
    "        mask = None\n",
    "    \n",
    "    w_transform(beta_imgs, int_img, raw_paths,  sdres_img, \n",
    "                df, subject_IDs, aff, mask, outdir)\n",
    "    \n",
    "    print('FINISHED! W-SCORE images written to %s'%outdir)\n",
    "    \n",
    "def create_sdres_img(res_str, beta_dir):\n",
    "    \n",
    "    res_paths = glob(os.path.join(beta_dir,'%s*'%res_str))\n",
    "    print('calculating standard deviation of the residuals')\n",
    "    print('loading res images...')\n",
    "    res_imgs = ni.concat_images(res_paths).get_data()\n",
    "    print('calculating...')\n",
    "    sdres_img = res_imgs.std(ddof=1,axis=3)\n",
    "    \n",
    "    return sdres_img\n",
    "    \n",
    "def w_transform(beta_imgs, int_img, raw_paths, sdres_img, \n",
    "                df, subject_IDs, aff, mask, outdir):\n",
    "        \n",
    "    print('performing w-score transformations...')\n",
    "    x,y,z = ni.load(raw_paths[0]).shape\n",
    "    for i,scan in enumerate(raw_paths):\n",
    "        if len(subject_IDs) > 0:\n",
    "            sid = subject_IDs[i]\n",
    "        else:\n",
    "            sid = os.path.split(scan).split('.')[0]\n",
    "        coefs = []\n",
    "        if type(int_img) != type(None):\n",
    "            coefs.append(int_img.reshape(x,y,z,1))\n",
    "        for j,col in enumerate(df.columns):\n",
    "            val = df.loc[df.index[i],col]\n",
    "            val_img = np.full_like(beta_imgs[:,:,:,j],val) \n",
    "            coef = beta_imgs[:,:,:,j] * val_img\n",
    "            #coef = np.multiply(beta_imgs[:,:,:,j],val)\n",
    "            coefs.append(coef.reshape(x,y,z,1))\n",
    "        jnk = np.concatenate(coefs,axis=3)\n",
    "        predicted = jnk.sum(axis=3)\n",
    "        observed = ni.load(scan).get_data()\n",
    "        wscr_mat = (observed - predicted) / sdres_img\n",
    "        if type(mask) != type(None):\n",
    "            wscr_mat[mask==0] = 0\n",
    "        wscr_img = ni.Nifti1Image(wscr_mat,aff)\n",
    "        flnm = os.path.join(outdir,'WSCORE_%s'%(sid))\n",
    "        wscr_img.to_filename(flnm)\n",
    "        print('finished %s, %s of %s'%(sid,i+1,len(raw_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_by_LDA_factor(image_dir, LDA_dir, LDA_str = 'factor',\n",
    "                            mask_image = None, outdir = './', outname = 'LDA_scores',\n",
    "                           save_results = True, return_results = False):\n",
    "    \n",
    "    scans = glob(os.path.join(image_dir, '*.ni*'))\n",
    "    print('found %s scans to transform'%len(scans))\n",
    "    factor_paths = glob(os.path.join(LDA_dir,'%s*.ni*'%LDA_str))\n",
    "    print('found %s LDA factors'%len(factor_paths))\n",
    "    \n",
    "    ids = [os.path.split(x)[-1].split('.')[0] for x in scans]\n",
    "    fac_ids = [os.path.split(x)[-1].split('.')[0] for x in factor_paths]\n",
    "    results = pandas.DataFrame(index = ids, columns = fac_ids)\n",
    "    \n",
    "    factors = ni.concat_images(factor_paths).get_data()\n",
    "    if mask_image and mask_image != 'auto':\n",
    "        mask = ni.load(mask_image).get_data()\n",
    "        for j in range(factors.shape[-1]):\n",
    "            factors[:,:,:,j][mask==0] = 0\n",
    "    elif mask_image == 'auto':\n",
    "        mcoords = np.where(factors[:,:,:,0]==0)\n",
    "        mask = np.ones_like(factors[:,:,:,0])\n",
    "        mask[mcoords] = 0\n",
    "    \n",
    "    for i,scan in enumerate(scans):\n",
    "        sid = ids[i]\n",
    "        print('transforming %s, %s of %s'%(sid, (i+1), len(scans)))\n",
    "        dat = ni.load(scan).get_data()\n",
    "        if mask_image:\n",
    "            dat[mask==0] = 0\n",
    "        for j in range(factors.shape[-1]):\n",
    "            score = np.dot(dat.flat, factors[:,:,:,j].flat)\n",
    "            results.loc[sid, fac_ids[j]] = score\n",
    "    \n",
    "    if save_results:\n",
    "        flnm = os.path.join(outdir,'%.csv'%outname)\n",
    "        results.to_csv(flnm)\n",
    "        print('results written to %s'%flnm)\n",
    "    \n",
    "    if return_results:\n",
    "        return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 8 scans to transform\n",
      "found 2 LDA factors\n",
      "transforming nan_snorm_002-S-4229_18F-AV1451_2016-02-10_P4_I635352, 1 of 8\n",
      "transforming nan_snorm_002-S-4262_18F-AV1451_2016-02-25_P4_I651320, 2 of 8\n",
      "transforming nan_snorm_002-S-4521_18F-AV1451_2016-04-05_P4_I730844, 3 of 8\n",
      "transforming nan_snorm_002-S-4654_18F-AV1451_2016-04-21_P4_I699996, 4 of 8\n",
      "transforming nan_snorm_002-S-4799_18F-AV1451_2016-07-27_P4_I767572, 5 of 8\n",
      "transforming nan_snorm_007-S-2394_18F-AV1451_2016-07-19_P4_I762869, 6 of 8\n",
      "transforming nan_snorm_007-S-4620_18F-AV1451_2016-07-15_P4_I761155, 7 of 8\n",
      "transforming nan_snorm_007-S-4637_18F-AV1451_2016-07-26_P4_I764202, 8 of 8\n"
     ]
    }
   ],
   "source": [
    "image_dir = '/Users/jakevogel/Science/tau/tmp/tmp_in/'\n",
    "LDA_dir = '/Users/jakevogel/Science/tau/tmp/tmp_fax/'\n",
    "LDA_str = 'msk'\n",
    "outdir = '/Users/jakevogel/Science/tau/tmp/'\n",
    "return_results = True\n",
    "mask_image = '/Users/jakevogel/Science/tau/ADNI_GM_mask_1mm_nocereb.nii.gz'\n",
    "res_df = transform_by_LDA_factor(image_dir, LDA_dir, LDA_str, \n",
    "                                 mask_image = 'auto', save_results=False, return_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
