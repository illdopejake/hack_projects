{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##NOTES TO SELF\n",
    "The ECDF reference region thing works.\n",
    "On reduced data, if my calculations are right, a voxelwise ECDF shouldn't be too time-consuming (1-10 minutes).\n",
    "Try this out before bothering with vectorizing it. Use map with a lambda function like this ECDF(array)(array)\n",
    "Afterwards, add the ref sample stuff\n",
    "And then eventually the inputs and outputs etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas\n",
    "from nilearn import image, input_data\n",
    "import nibabel as ni\n",
    "import scipy.stats as stats\n",
    "from scipy.io import savemat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "from sklearn.feature_extraction.image import grid_to_graph\n",
    "import statsmodels.distributions.empirical_distribution as ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_PET_data(files_in, atlas, ref = None, msk = None, dimension_reduction = False,\n",
    "                     ECDF_in = None, output_type = 'py', out_dir = './', out_name = 'PET_data', \n",
    "                     save_matrix = False, save_ECDF = False, save_images = False, ref_index = []):\n",
    "    ''' This is a function that will take several PET images and an atlas and will\n",
    "    return a subject X region matrix. If specified, the function will also calculate \n",
    "    probabilities (via ECDF) either voxelwise, or using a specified reference region\n",
    "    \n",
    "    files_in = input can either be \n",
    "        - a path to a directory full of (only) nifti images OR\n",
    "        - a \"search string\" using wildcards\n",
    "        - a list of subject paths OR\n",
    "        - a subject X image matrix\n",
    "        \n",
    "    altas = a path to a labeled regional atlas in the same space as the PET data\n",
    "    \n",
    "    ref = multiple options:\n",
    "        - If None, no probabilities will be calculated, and script will simply extract\n",
    "        regional PET data using the atlas.\n",
    "        - If a path to a reference region mask, will calculate voxelwise probabilities\n",
    "        based on values within the reference region. Mask must be in the same space as \n",
    "        as PET data and atlas\n",
    "        - If a list of integers, will combine these atlas labels with these integers to \n",
    "        make reference region \n",
    "        - if 'voxelwise', voxelwise (or atom-wise from dimension reduction) probabilities\n",
    "        will be estimated. In other words, each voxel or atom will use serve as its own\n",
    "        reference.\n",
    "        \n",
    "    msk = A path to a binary mask file in the same space as PET data and atlas. If None,\n",
    "        mask will be computed as a binary mask of the atlas.\n",
    "        ** PLEASE NOTE: The mask will be used to mask the reference region! **\n",
    "    \n",
    "    dimension_reduction = whether or not to first reduce dimensions of data using\n",
    "    hierarchical clustering. This results in an initial step that will be very slow, but \n",
    "    will may result in an overall speedup for the script, but perhaps only if ref is set \n",
    "    to 'voxelwise'.\n",
    "        - If None, do not perform dimension reduction\n",
    "        - If integer, the number of atoms (clusters) to reduce to\n",
    "    \n",
    "    ECDF_in = If the user wishes to apply an existing ECDF to the PET data instead of\n",
    "        generating one de novo, that can be done here. This crucial if the user wishes to\n",
    "        use multiple datasets. Think of it like scaling in machine learning.\n",
    "        - If None, will generate ECDF de novo.\n",
    "        - If np.array, will use this array to generate the ECDF.\n",
    "        - If statsmodel ECDF object, will use this as ECDF\n",
    "        - If a path, will use the\n",
    "    \n",
    "    output_type = type of file to save final subject x region matrix into. multiple options:\n",
    "        -- 'py' will save matrix into a csv\n",
    "        -- 'mat' will save matrix into a matfile\n",
    "    \n",
    "    out_dir = location to save output files. Defaults to current directory\n",
    "    \n",
    "    out_name = the prefix for all output files\n",
    "    \n",
    "    save_matrix = Whether to save or return subject x image matrix. Useful if running multiple \n",
    "        times, as this matrix can be set as files_in, bypassing the costly data import\n",
    "        -- if 'return', will return subject x image matrix to python environment\n",
    "        -- if 'save', will write subject x image matrix to file. \n",
    "        -- if None, matrix will not be stored\n",
    "    \n",
    "    save_ECDF = whether to save the ECDF used to create the probabilities. This is crucial if \n",
    "        using multiple datasets. The resulting output can be used as input for the ECDF argument.\n",
    "        -- if 'return, will return np.array to python environment\n",
    "        -- if 'save', will write array to file\n",
    "        -- if None, array will not be stored\n",
    "    \n",
    "    '''\n",
    "    # Check input arguments\n",
    "    print('initiating...')\n",
    "    if output_type != 'py' and output_type != 'mat':\n",
    "        raise IOError('output_type must be set to py or mat')\n",
    "    \n",
    "    \n",
    "    # Initialize variables\n",
    "    \n",
    "    # Load data\n",
    "    print('loading data...')\n",
    "    i4d = load_data(files_in) # load PET data\n",
    "    if save_matrix == 'save':\n",
    "        otpt = os.path.join(out_dir,'%s_4d_data'%out_name)\n",
    "        print('saving 4d subject x scan to nifti image: \\n',otpt)\n",
    "        i4d.to_filename(otpt)\n",
    "    \n",
    "    # load atlas\n",
    "    atlas = ni.load(atlas).get_data().astype(int) \n",
    "    if atlas.shape != i4d.shape[:3]:\n",
    "        raise ValueError('atlas dimensions do not match PET data dimensions')\n",
    "    \n",
    "    # load reference region\n",
    "    if type(ref) == str and ref != 'voxelwise': \n",
    "        print('looking for reference image...')\n",
    "        if not os.path.isdir(ref):\n",
    "            raise IOError('Please enter a valid path for ref, or select a different option for this argument')\n",
    "        else:\n",
    "            ref_msk = ni.load(ref).get_data()\n",
    "            if ref_msk.shape != i4d.shape[:3]:\n",
    "                raise ValueError('ref region image dimensions do not match PET data dimensions')\n",
    "    elif type(ref) == list:\n",
    "        ref_msk = np.zeros_like(atlas)\n",
    "        for i in ref:\n",
    "            ref_msk[atlas == i] = 1\n",
    "    else:\n",
    "        ref_msk = None\n",
    "    \n",
    "    \n",
    "    # Mask data\n",
    "    print('masking data...')\n",
    "    if type(msk) == type(None):\n",
    "        img_mask = atlas[:,:,:]\n",
    "        img_mask[img_mask<1] = 0\n",
    "        img_mask[img_mask>0] = 1\n",
    "    else:\n",
    "        img_mask = ni.load(msk).get_data()\n",
    "        atlas[img_mask < 1] = 0\n",
    "    \n",
    "    if type(ref_msk) != type(None):\n",
    "        ref_msk[img_mask < 1] = 0\n",
    "    \n",
    "    mask_tfm = input_data.NiftiMasker(ni.Nifti1Image(img_mask,i4d.affine))\n",
    "    mi4d = mask_tfm.fit_transform(i4d)\n",
    "    \n",
    "    # dimension reduction (IN BETA!)\n",
    "    if dimension_reduction:\n",
    "        print('reducing dimensions...')\n",
    "        shape = img_mask.shape\n",
    "        connectivity = grid_to_graph(n_x=shape[0], n_y=shape[1],\n",
    "                                   n_z=shape[2], mask=img_mask)\n",
    "    # main ECDF calculation\n",
    "    skip = False\n",
    "    if ref != 'voxelwise':\n",
    "        if type(ECDF_in) != type(none): \n",
    "            print('generating ECDF...')\n",
    "            print('using user-supplied data...')\n",
    "            if type(ECDF_in) == ed.ECDF:\n",
    "                mi4d_ecdf, ecref = ecdf_simple(mi4d, ECDF_in)\n",
    "                input_distribution = 'not generated'\n",
    "            elif type(ECDF_in) == np.ndarray:\n",
    "                mi4d_ecdf, ecref = ecdf_simple(mi4d, ECDF_in)\n",
    "                input_distribution = ECDF_in\n",
    "    #       elif # add later an option for importing an external object \n",
    "            else:\n",
    "                try:\n",
    "                    mi4d_ecdf, ecref = ecdf_simple(mi4d, ECDF_in)\n",
    "                    print('Could not understand ECDF input, but ECDF successful')\n",
    "                    input_distribution = 'not generated'\n",
    "                except:\n",
    "                    raise IOError(\n",
    "                            'Invalid argument for ECDF in. Please enter an ndarray, an ECDF object, or a valid path')\n",
    "        else:\n",
    "            if type(ref_msk) != type(None):\n",
    "                print('generating ECDF...')\n",
    "                ref_tfm = input_data.NiftiMasker(ni.Nifti1Image(ref_msk,i4d.affine))\n",
    "                refz = ref_tfm.fit_transform(i4d)\n",
    "                mi4d_ecdf, ecref = ecdf_simple(mi4d, refz)\n",
    "                input_distribution = refz.flat\n",
    "            else:\n",
    "                print('skipping ECDF...')\n",
    "                skip = True\n",
    "    \n",
    "    else:\n",
    "        print('generating voxelwise ECDF...')\n",
    "        mi4d_ecdf, ECDF_array = ecdf_voxelwise(mi4d, ref_index, save_ECDF)\n",
    "        input_distribution = 'not generated'\n",
    "        \n",
    "    if not skip:\n",
    "#       if save_ECDF:\n",
    "#           create an array and somehow write it to a file\n",
    "        \n",
    "    # transform back to image-space\n",
    "        print('transforming back into image space')\n",
    "        f_images = mask_tfm.reverse_transform(mi4d_ecdf)\n",
    "    \n",
    "    else:\n",
    "        if type(ECDF)\n",
    "        print('transforming back into image space')\n",
    "        f_images = mask_tfm.reverse_transform(mi4d)\n",
    "    \n",
    "    # generate output matrix\n",
    "    print('generating final subject x region matrix')\n",
    "    f_mat = generate_matrix_from_atlas(f_images, atlas)\n",
    "    \n",
    "    # compile (and save) outputs\n",
    "    print('preparing outputs')\n",
    "    output = {}\n",
    "    if output_type = 'py':\n",
    "        f_mat.to_csv(os.path.join(out_dir, '%s_roi_data.csv'%out_name))\n",
    "        output.update({'roi_matrix': f_mat})\n",
    "    else:\n",
    "        output.update({'roi_matrix': fmat.values})\n",
    "        output.update({'roi_matrix_columns': fmat.columns})\n",
    "    if save_matrix == 'return':\n",
    "        output.update({'4d_image_matrix': i4d})\n",
    "    if save_ECDF == 'return':\n",
    "        if output_type == 'py':\n",
    "            output.update({'ECDF_function': ECDF_array})\n",
    "        else:\n",
    "            output.update({'input_distribution': input_distribution})\n",
    "    \n",
    "def load_data(files_in):\n",
    "    \n",
    "    fail = False\n",
    "    \n",
    "    if type(files_in) == str:\n",
    "        if os.path.isdir(files_in):\n",
    "            print('It seems you passed a directory')\n",
    "            search = os.path.join(files_in,'*')\n",
    "            num_f = len(glob(search))\n",
    "            if num_f == 0:\n",
    "                raise IOError('specified directory did not contain any files')\n",
    "            else:\n",
    "                print('found %s images!'%num_f)\n",
    "            i4d = image.load_img(search)\n",
    "        elif '*' in files_in:\n",
    "            print('It seems you passed a search string')\n",
    "            num_f = len(glob(files_in))\n",
    "            if num_f == 0:\n",
    "                raise IOError('specified search string did not result in any files')\n",
    "            else:\n",
    "                print('found %s images'%num_f)\n",
    "            i4d = image.load_img(files_in)\n",
    "        else:\n",
    "            fail = True\n",
    "    elif type(files_in) == list:\n",
    "        print('processing %s subjects'%len(files_in))\n",
    "        i4d = ni.concat_images(files_in)\n",
    "    elif type(files_in) == ni.nifti1.Nifti1Image:\n",
    "        print('processing %s subjects'%files_in.shape[-1])\n",
    "        i4d = files_in\n",
    "    else:\n",
    "        fail = True\n",
    "        \n",
    "    if fail:\n",
    "        print('files_in not recognized.', \n",
    "                    'Please enter a search string, valid directory, list of subjects, or matrix')\n",
    "        raise ValueError('I do not recognize the files_in input.')\n",
    "    \n",
    "    return i4d\n",
    "\n",
    "def dim_reduction(mi4d, connectivity, dimension_reduction):\n",
    "    ward = FeatureAgglomeration(n_clusters=dimension_reduction/2,\n",
    "            connectivity=connectivity, linkage='ward', memory='nilearn_cache')\n",
    "    ward.fit(mi4d)\n",
    "    ward = FeatureAgglomeration(n_clusters=dimension_reduction,\n",
    "            connectivity=connectivity, linkage='ward', memory='nilearn_cache')\n",
    "    ward.fit(mi4d)                                                         \n",
    "    mi4d = ward.transform(mi4d)\n",
    "\n",
    "    return mi4d\n",
    "\n",
    "def ecdf_simple(mi4d, refz):\n",
    "\n",
    "    if type(refz) == ed.ECDF:\n",
    "        ecref = refz\n",
    "    else:\n",
    "        if len(refz.shape) > 1:\n",
    "            ecref = ed.ECDF(refz.flat)\n",
    "        else:\n",
    "            ecref = ed.ECDF(refz)\n",
    "    print('transforming images...')\n",
    "    mi4d_ecdf = ecref(mi4d.flat).reshape(mi4d.shape[0],mi4d.shape[1])\n",
    "\n",
    "    return mi4d_ecdf, ecref   \n",
    "\n",
    "def ecdf_voxelwise(mi4d, ref_index, save_ECDF):\n",
    "    \n",
    "    X,y = mi4d.shape\n",
    "\n",
    "    if len(ref_index) == 0:\n",
    "        if not save_ECDF:\n",
    "            mi4d_ecdf = np.array([ed.ECDF(mi4d[:,x])(mi4d[:,x]) for x in range(y)]).reshape(X,y)\n",
    "            ECDF_array = None\n",
    "        else:\n",
    "            ECDF_array = np.array([ed.ECDF(mi4d[:,x]) for x in range(y)]).reshape(X,y)\n",
    "            print('transforming data...')\n",
    "            mi4d_ecdf = np.array([ECDF_matrix[x](mi4d[:,x]) for x in range(y)]\n",
    "                                     ).reshape(X,y)\n",
    "    else:\n",
    "        good_ind = [x for x in list(range(X)) if x not in ref_index]\n",
    "        if not save_ECDF:    \n",
    "            mi4d_ecdf = np.array([ed.ECDF(mi4d[ref_index,x])(mi4d[good_ind,x]) for x in range(y)]\n",
    "                                ).reshape(X,y)\n",
    "            ECDF_array = None\n",
    "        else:\n",
    "            ECDF_array = [ed.ECDF(mi4d[ref_index,x]) for x in range(y)]\n",
    "            print('transforming data...')\n",
    "            mi4d_ecdf = ecdf_voxelwise = np.array([ECDF_matrix[x](mi4d[good_ind,x]) for x in range(y)]\n",
    "                                     ).reshape(X,y)\n",
    "    \n",
    "    return mi4d_ecdf, ECDF_array\n",
    "\n",
    "def generate_matrix_from_atlas(files_in, atlas):\n",
    "    \n",
    "    atlas = atlas.astype(int)\n",
    "    f_mat = pandas.DataFrame(index = range(files_in.shape[-1]),\n",
    "                             columns = ['roi_%s'%x for x in np.unique(atlas) if x != 0])\n",
    "    tot = np.bincount(atlas.flat)\n",
    "    for sub in range(files_in.shape[-1]):\n",
    "        mtx = f_mat[:,:,:,sub]\n",
    "        sums = np.bincount(atlas.flat, weights = mtx.flat)\n",
    "        rois = (sums/tot)[1:]\n",
    "        f_mat.loc[fmat.index[sub]] = rois\n",
    "        \n",
    "    return f_mat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 6 subjects\n"
     ]
    }
   ],
   "source": [
    "scans = sorted(glob('/Users/jakevogel/Science/tau/nan_snorm_*002*'))\n",
    "i4d = load_data(scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masking data...\n"
     ]
    }
   ],
   "source": [
    "atlas = '/Users/jakevogel/Science/tau/dkt_atlas_1mm.nii.gz'\n",
    "ref = [79,80]\n",
    "msk = '/Users/jakevogel/Science/tau/thr_ADNI_GM_mask_1mm.nii.gz'\n",
    "\n",
    "# load atlas\n",
    "atlas = ni.load(atlas).get_data().astype(int) \n",
    "if atlas.shape != i4d.shape[:3]:\n",
    "    raise ValueError('atlas dimensions do not match PET data dimensions')\n",
    "\n",
    "# load reference region\n",
    "if type(ref) == str and ref != 'voxelwise': \n",
    "    print('looking for reference image...')\n",
    "    if not os.path.isdir(ref):\n",
    "        raise IOError('Please enter a valid path for ref, or select a different option for this argument')\n",
    "    else:\n",
    "        ref_msk = ni.load(ref).get_data()\n",
    "        if ref_msk.shape != i4d.shape[:3]:\n",
    "            raise ValueError('ref region image dimensions do not match PET data dimensions')\n",
    "elif type(ref) == list:\n",
    "    ref_msk = np.zeros_like(atlas)\n",
    "    for i in ref:\n",
    "        ref_msk[atlas == i] = 1\n",
    "else:\n",
    "    ref_msk = None\n",
    "\n",
    "\n",
    "# Mask data\n",
    "print('masking data...')\n",
    "if msk == None:\n",
    "    img_mask = atlas[:,:,:]\n",
    "    img_mask[img_mask<1] = 0\n",
    "    img_mask[img_mask>0] = 1\n",
    "else:\n",
    "    img_mask = ni.load(msk).get_data()\n",
    "    atlas[img_mask < 1] = 0\n",
    "\n",
    "if type(ref_msk) != type(None):\n",
    "    ref_msk[img_mask < 1] = 0\n",
    "\n",
    "mask_tfm = input_data.NiftiMasker(ni.Nifti1Image(img_mask,i4d.affine))\n",
    "mi4d = mask_tfm.fit_transform(i4d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ECDF...\n",
      "transforming images...\n"
     ]
    }
   ],
   "source": [
    "ECDF_in = None\n",
    "skip = False\n",
    "if ref != 'voxelwise':\n",
    "    if ECDF_in: \n",
    "        print('generating ECDF...')\n",
    "        print('using user-supplied data...')\n",
    "        if type(ECDF_in) == ed.ECDF:\n",
    "            mi4d_ecdf, ecref = ecdf_simple(mi4d, ECDF_in)\n",
    "        elif type(ECDF_in) == np.ndarray:\n",
    "            mi4d_ecdf, ecref = ecdf_simple(mi4d, ECDF_in)\n",
    "#       elif # add later an option for importing an external object \n",
    "        else:\n",
    "            try:\n",
    "                mi4d_ecdf, ecref = ecdf_simple(mi4d, ECDF_in)\n",
    "            except:\n",
    "                raise IOError(\n",
    "                        'Invalid argument for ECDF in. Please enter an ndarray, an ECDF object, or a valid path')\n",
    "    else:\n",
    "        if type(ref_msk) != type(None):\n",
    "            print('generating ECDF...')\n",
    "            ref_tfm = input_data.NiftiMasker(ni.Nifti1Image(ref_msk,i4d.affine))\n",
    "            refz = ref_tfm.fit_transform(i4d)\n",
    "            mi4d_ecdf, ecref = ecdf_simple(mi4d, refz)\n",
    "        else:\n",
    "            print('skipping ECDF...')\n",
    "            skip = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "total size of new array must be unchanged",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-48a5fe00ef2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmi4d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mecdf_voxelwise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mECDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi4d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: total size of new array must be unchanged"
     ]
    }
   ],
   "source": [
    "X,y = mi4d.shape\n",
    "ecdf_voxelwise = np.array(map(lambda x: ed.ECDF(mi4d[:,x]),range(y))).reshape(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,y = mi4d.shape\n",
    "ecdf_voxelwise = [ed.ECDF(mi4d[:,x])(mi4d[:,x]) for x in range(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst = np.array(ecdf_voxelwise).reshape(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.23515558,  0.81288999])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnk_ind = [2,3]\n",
    "mi4d[jnk_ind,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnk1 = list(range(X)[2:])\n",
    "print(jnk1)\n",
    "good_ind = [x for x in range(X) if x not in jnk1]\n",
    "good_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ecdf_voxelwise = [ed.ECDF(mi4d[jnk1,x])(mi4d[good_ind,x]) for x in range(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ECDF_matrix = [ed.ECDF(mi4d[:,x]) for x in range(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ecdf_voxelwise = [ECDF_matrix[x](mi4d[good_ind,x]) for x in range(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 939852)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi4d_ecdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ecdf_voxelwise = [ed.ECDF(mi4d[:,x])(mi4d[:,x]) for x in range(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nimg = mask_tfm.inverse_transform(mi4d_ecdf[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nimg.to_filename('/Users/jakevogel/Science/tau/ecdf_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "atlas_tfm = input_data.NiftiLabelsMasker(atlas, mask_img=img_mask, resampling_target=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_img = mask_tfm.inverse_transform(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nibabel.nifti1.Nifti1Image"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tst_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Data given cannot be loaded because it is not compatible with nibabel format:\n0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-66a6adefe1db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtst_atl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matlas_tfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/nilearn/input_data/nifti_labels_masker.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, imgs, confounds)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\" Prepare and perform signal extraction from regions.\n\u001b[1;32m    190\u001b[0m         \"\"\"\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/nilearn/input_data/nifti_labels_masker.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_niimgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                    verbose=self.verbose)\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_img_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_niimg_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             logger.log(\"loading data from %s\" %\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg_3d\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0mIts\u001b[0m \u001b[0mapplication\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0midempotent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    266\u001b[0m             return _iter_check_niimg(niimg, ensure_ndim=ensure_ndim,\n\u001b[1;32m    267\u001b[0m                                      dtype=dtype)\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat_niimgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mconcat_niimgs\u001b[0;34m(niimgs, dtype, ensure_ndim, memory, memory_level, auto_resample, verbose)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfirst_niimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot concatenate empty objects'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    266\u001b[0m             return _iter_check_niimg(niimg, ensure_ndim=ensure_ndim,\n\u001b[1;32m    267\u001b[0m                                      dtype=dtype)\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat_niimgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mconcat_niimgs\u001b[0;34m(niimgs, dtype, ensure_ndim, memory, memory_level, auto_resample, verbose)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfirst_niimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot concatenate empty objects'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    266\u001b[0m             return _iter_check_niimg(niimg, ensure_ndim=ensure_ndim,\n\u001b[1;32m    267\u001b[0m                                      dtype=dtype)\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat_niimgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mconcat_niimgs\u001b[0;34m(niimgs, dtype, ensure_ndim, memory, memory_level, auto_resample, verbose)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfirst_niimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot concatenate empty objects'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mniimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_ndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py3/lib/python3.5/site-packages/nilearn/_utils/niimg.py\u001b[0m in \u001b[0;36mload_niimg\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    102\u001b[0m         raise TypeError(\"Data given cannot be loaded because it is\"\n\u001b[1;32m    103\u001b[0m                         \u001b[0;34m\" not compatible with nibabel format:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                         + short_repr(niimg))\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_target_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_data_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Data given cannot be loaded because it is not compatible with nibabel format:\n0"
     ]
    }
   ],
   "source": [
    "tst_atl = atlas_tfm.fit_transform(tst_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mi4d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 218, 182)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_mask = ni.load(msk).get_data()\n",
    "img_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 218, 182)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4169090"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_mask[img_mask<1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scans = sorted(glob('/home/users/jvogel/Science/datasets/ADNI_AV1451_template_space/*_S_*/*'))\n",
    "len(scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i4d = ni.concat_images(scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 145, 121)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i4d.shape[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nibabel.nifti1.Nifti1Image"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(i4d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 145, 121)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlas = ni.load('/home/users/jvogel/Science/templates/atlases/HarvardOxford-sub-maxprob-thr0-1p5mm.nii.gz').get_data()\n",
    "atlas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlas = atlas.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4464"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = np.zeros_like(atlas)\n",
    "for i in jnk:\n",
    "    ref[atlas==i] = 1\n",
    "len(ref[ref > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_mask = atlas[:,:,:]\n",
    "img_mask[img_mask<1] = 0\n",
    "img_mask[img_mask>0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_tfm = input_data.NiftiMasker(ni.Nifti1Image(img_mask,i4d.affine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 732986)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi4d = mask_tfm.fit_transform(i4d)\n",
    "mi4d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jnk = np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ejnk = ECDF(abs(jnk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.  ,  0.97,  0.87,  0.99])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejnk([3, 2, 1.5, 2.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ejnk = ECDF([1,1.2,1,1.2,1,1.2,1.5,1,1.2,1,1.2,1.5,1,1.2,1.8,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33333333,  0.33333333,  0.33333333,  0.33333333,  0.66666667,\n",
       "        0.83333333])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnk([1,1.2,1.5,1.8,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jnk = np.random.randn(91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 7.58 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 78.9 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "r = ECDF(jnk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = ECDF(jnk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 10.61 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "100000 loops, best of 3: 7.22 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "r(jnk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.12"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "78.9 + 7.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.12"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(86.12 * 1000000) / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.033333333333333"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "602/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.46153846,  0.85714286,  0.86813187,  0.53846154,  0.61538462,\n",
       "        0.89010989,  0.37362637,  0.69230769,  0.35164835,  0.24175824,\n",
       "        0.32967033,  0.95604396,  0.16483516,  0.1978022 ,  0.93406593,\n",
       "        0.92307692,  0.08791209,  0.05494505,  0.57142857,  0.91208791,\n",
       "        0.41758242,  0.6043956 ,  0.43956044,  0.83516484,  0.0989011 ,\n",
       "        0.48351648,  0.45054945,  0.03296703,  0.30769231,  0.9010989 ,\n",
       "        0.12087912,  0.47252747,  0.42857143,  0.59340659,  0.98901099,\n",
       "        0.3956044 ,  0.54945055,  0.49450549,  0.67032967,  0.73626374,\n",
       "        0.01098901,  0.56043956,  0.8021978 ,  0.38461538,  0.96703297,\n",
       "        1.        ,  0.04395604,  0.81318681,  0.17582418,  0.28571429,\n",
       "        0.7032967 ,  0.10989011,  0.15384615,  0.18681319,  0.20879121,\n",
       "        0.02197802,  0.25274725,  0.34065934,  0.87912088,  0.97802198,\n",
       "        0.07692308,  0.27472527,  0.2967033 ,  0.79120879,  0.58241758,\n",
       "        0.50549451,  0.74725275,  0.71428571,  0.13186813,  0.76923077,\n",
       "        0.94505495,  0.26373626,  0.64835165,  0.84615385,  0.36263736,\n",
       "        0.40659341,  0.21978022,  0.68131868,  0.75824176,  0.63736264,\n",
       "        0.14285714,  0.31868132,  0.51648352,  0.62637363,  0.65934066,\n",
       "        0.82417582,  0.52747253,  0.78021978,  0.72527473,  0.23076923,\n",
       "        0.06593407])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECDF(jnk)(jnk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
